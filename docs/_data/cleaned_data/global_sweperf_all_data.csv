3,status,instance_id,pull_request_link,workload,notes,mike_notes,num_covering_tests,base_docker_image,annotate_dockerhub_image,annotate_sample_docker_command,repo,created_at,base_commit,version
,APPROVED,pandas-dev__pandas-38248,https://github.com/pandas-dev/pandas/pull/38248,"import pandas as pd
import numpy as np
import timeit
import statistics

def setup():
    global arr1, arr2
    N = 10_000_000

    base = pd.date_range(""2000-01-01"", periods=N, freq=""s"")
    arr1 = base._data  # DatetimeArray
    arr2 = pd.date_range(""2000-01-01 00:00:01"", periods=N, freq=""s"")._data

def workload():
    global arr1, arr2
    arr1 < arr2

runtimes = timeit.repeat(workload, number=10, repeat=25, setup = setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","An error occurred:

An unknown error occurred. Please check the local files.",,81,docker.io/sweperf/sweperf:pandas-dev__pandas-38248,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38248,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38248 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-12-02 19:20:27,4c8d66ecfe2b13607afd254443979b1ff842b6c1,1.1
,APPROVED,pandas-dev__pandas-41861,https://github.com/pandas-dev/pandas/pull/41861,"import pandas as pd
import numpy as np
import timeit
import statistics
from pandas.core.common import is_bool_indexer

def setup():
    global key
    key = [True, False] * 500_000

def workload():
    global key
    is_bool_indexer(key)

runtimes = timeit.repeat(workload, number=10, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","An error occurred:

An unknown error occurred. Please check the local files.","Mean: 0.39078575020539574
Std Dev: 0.003979267847298631
Mean: 0.009874954487895594
Std Dev: 0.002735751326216655
Improvement:-97.47%",546,docker.io/sweperf/sweperf:pandas-dev__pandas-41861,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41861,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41861 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-06-08 0:53:14,b73c38e20518d874bceaaab6c3efdb034f36ad54,1.2
,APPROVED,pandas-dev__pandas-42293,https://github.com/pandas-dev/pandas/pull/42293,"import timeit
import statistics
import pandas as pd
import numpy as np

from pandas import IntervalIndex

params = [10**3, 10**5]

def setup():
    global left, right
    N = 100000
    left = IntervalIndex.from_breaks(np.arange(N))
    right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))

def workload():
    global left, right
    left.intersection(right)

runtimes = timeit.repeat(workload, number=1, repeat=100, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","An error occurred:

An unknown error occurred. Please check the local files.","Mean: 0.10116663295979379
Std Dev: 0.0038713468128095756
Mean: 0.007087590449373238
Std Dev: 0.0010262596783725494
Improvement:-92.99%",851,docker.io/sweperf/sweperf:pandas-dev__pandas-42293,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42293,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42293 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-06-29 4:38:51,b8c8aca6d22f0560b2bd5551f77f515f37377087,1.2
,APPROVED,pandas-dev__pandas-43115,https://github.com/pandas-dev/pandas/pull/43115,"import pandas as pd
import numpy as np
import timeit
import statistics

def setup():
    global df, grouped
    N = 1_000_000
    K = 1000
    df = pd.DataFrame({
        f""col{i}"": np.random.randn(N) for i in range(10)
    })
    df[""key""] = np.random.randint(0, K, size=N)
    grouped = df.groupby(""key"")

def workload():
    global grouped
    grouped.std()

runtimes = timeit.repeat(workload, number=10, repeat=10, setup=setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","An error occurred:

An unknown error occurred. Please check the local files.","Mean: 0.27562972920713946
Std Dev: 0.013675353056581427
Mean: 0.1985029833042063
Std Dev: 0.010133006246079743
Improvement:-27.98%",861,docker.io/sweperf/sweperf:pandas-dev__pandas-43115,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43115,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43115 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-19 22:58:09,2617bfc43304dbdae3aab75160ef9a776afadd7a,1.3
,APPROVED,pandas-dev__pandas-45434,https://github.com/pandas-dev/pandas/pull/45434,"import pandas as pd
import numpy as np
import timeit
import statistics

N = 1_000_000

def setup():
    global arr
    arr = pd.array(np.random.randint(0, 100, size=N), dtype=""Int64"")
    arr._mask[:N//10] = True

def workload():
    global arr
    arr._values_for_argsort()

runtimes = timeit.repeat(workload, number=10, repeat=100, setup=setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","An error occurred:

An unknown error occurred. Please check the local files.","Mean: 0.10586357252998141
Std Dev: 0.00156297539133545
Mean: 1.9781249989136995e-05
Std Dev: 5.82690919544289e-06
Improvement: -99.98%",878,docker.io/sweperf/sweperf:pandas-dev__pandas-45434,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45434,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45434 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-01-17 23:36:03,b8cce91ee7bcc86877d4679cd8a9454b5995c2c6,1.3
,APPROVED,pandas-dev__pandas-46745,https://github.com/pandas-dev/pandas/pull/46745,"import numpy as np
import pandas as pd
import timeit
import statistics

def setup():
    global df, groupby_result
    N, M = 20000, 30
    arr = np.random.randint(0, 2, (N, M), dtype=np.int8)
    df = pd.DataFrame(arr)
    df[""name""] = np.random.choice(
        [""lion"", ""bird"", ""dog"", ""cat"", ""python"", ""monkey"", ""fish"", ""frog"", ""tiger"", ""bear""], size=N
    )

def workload():
    global df, groupby_result
    groupby_result = df.groupby(""name"").max()
    
runtimes = timeit.repeat(workload, number=100, repeat=100, setup = setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Mean: 0.26242977183002947
Std Dev: 0.006051763399057207
Mean: 0.21541409426006794
Std Dev: 0.006151848998020621
Improvement:-17.91%","Mean: 0.26242977183002947
Std Dev: 0.006051763399057207
Mean: 0.21541409426006794
Std Dev: 0.006151848998020621
Improvement:-17.91%",891,docker.io/sweperf/sweperf:pandas-dev__pandas-46745,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46745,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46745 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-04-11 22:34:13,32999a1a45f2c4171b8ac5e97f5aa34b1956686c,1.4
,APPROVED,pandas-dev__pandas-47916,https://github.com/pandas-dev/pandas/pull/47916,"import pandas as pd
import numpy as np
import pickle
import timeit
import statistics

def setup():
    global pickled_data

    n = 1_000_000
    level_0 = np.repeat(np.arange(1000), 1000)
    level_1 = np.tile(np.arange(1000), 1000)

    mi = pd.MultiIndex.from_arrays([level_0, level_1])
    pickled_data = pickle.dumps(mi)

def workload():
    global pickled_data
    _ = pickle.loads(pickled_data)

runtimes = timeit.repeat(workload, number=10, repeat=100, setup = setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","An error occurred:

An unknown error occurred. Please check the local files.","Mean: 0.0032989404414547605
Std Dev: 0.00044924897179374
Mean: 0.0014843200467294082
Std Dev: 0.00016532076144763994
Improvement:-55.01%",18,docker.io/sweperf/sweperf:pandas-dev__pandas-47916,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-47916,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-47916 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-08-01 19:05:55,d36138b116a9fa214506160711d8bebb335a3c33,1.4
,APPROVED,pandas-dev__pandas-48620,https://github.com/pandas-dev/pandas/pull/48620,"import pandas as pd
import numpy as np
import timeit
import statistics

from pandas import (
    DataFrame,
    Index,
    MultiIndex,
    Series,
    date_range,
    period_range,
)

def setup():
    global df_nan, inplace
    
    N = 10000
    K = 10
    key1 = Index([f""i-{i}"" for i in range(N)], dtype=object).values.repeat(K)
    key2 = Index([f""i-{i}"" for i in range(N)], dtype=object).values.repeat(K)
    df = DataFrame(
        {""key1"": key1, ""key2"": key2, ""value"": np.random.randn(N * K)}
    )
    df_nan = df.copy()
    df_nan.iloc[:10000, :] = np.nan
    inplace = True

def workload():
    global df_nan, inplace
    df_nan.drop_duplicates([""key1"", ""key2""], inplace=inplace)

runtimes = timeit.repeat(workload, number=100, repeat=100, setup = setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Mean: 0.3943281996897713
Std Dev: 0.004631698892185727
Mean: 0.2457366318200002
Std Dev: 0.004188024143330044
Improvement:-37.68%","Mean: 0.3943281996897713
Std Dev: 0.004631698892185727
Mean: 0.2457366318200002
Std Dev: 0.004188024143330044
Improvement:-37.68%",905,docker.io/sweperf/sweperf:pandas-dev__pandas-48620,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48620,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48620 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-09-18 13:10:18,71fc89cd515c3c19230fbab64e979118858b808a,1.4
,APPROVED,pandas-dev__pandas-51517,https://github.com/pandas-dev/pandas/pull/51517,"import pandas as pd
import numpy as np
import timeit
import statistics

np.random.seed(1234)

def setup():
    global series
    
    max_list_length = 10**4
    n_rows = 10**3
    data = [np.arange(np.random.randint(max_list_length)) for _ in range (n_rows)]
    series = pd.Series(data)
    print(""finish one"")

def workload():
    global series
    
    series.explode()

runtimes = timeit.repeat(workload, number=1, repeat=10, setup = setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Mean: 9.936046879299829
Std Dev: 0.1402164384775779
Mean: 0.31310581700054174
Std Dev: 0.01088208503807285
Improvement:-96.85%","Mean: 9.936046879299829
Std Dev: 0.1402164384775779
Mean: 0.31310581700054174
Std Dev: 0.01088208503807285
Improvement:-96.85%",908,docker.io/sweperf/sweperf:pandas-dev__pandas-51517,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51517,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51517 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-02-20 22:28:03,a80ffdb19988d175f3e54a9c6e472e4ff6b8cbc0,1.5
,APPROVED,pandas-dev__pandas-51873,https://github.com/pandas-dev/pandas/pull/51873,"import pandas as pd
import numpy as np
import timeit
import statistics

def setup():
    global mi, new_levels, levels_to_set
    n_levels = 10
    n_labels = 100_000
    n_rows = 1_000_000
    arrays = [
        np.random.randint(0, n_labels, size=n_rows)
        for _ in range(n_levels)
    ]
    mi = pd.MultiIndex.from_arrays(arrays)

    levels_to_set = [0, 1, 2]
    new_levels = [np.arange(n_labels, n_labels * 2) for _ in levels_to_set]

def workload():
    global mi, new_levels, levels_to_set
    _ = mi.set_levels(new_levels, level=levels_to_set, verify_integrity=True)
    
runtimes = timeit.repeat(workload, number=10, repeat=50, setup = setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","An error occurred:

An unknown error occurred. Please check the local files.","Mean: 0.10833288924070075
Std Dev: 0.00872848453800413
Mean: 0.0932918742595939
Std Dev: 0.009019986951226012
Improvement:-13.88%",909,docker.io/sweperf/sweperf:pandas-dev__pandas-51873,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51873,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51873 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-09 22:33:40,7888cf47e509bc61871c599ee1b636c0f98c9076,1.5
,APPROVED,pandas-dev__pandas-51921,https://github.com/pandas-dev/pandas/pull/51921,"import pandas as pd
import numpy as np
import timeit
import statistics

def setup():
    global arr
    N = 1_000_000
    n_nonstr = 100_000
    arr = np.empty(N, dtype=object)
    arr[:n_nonstr] = np.arange(n_nonstr)
    arr[n_nonstr:] = ""abc""

def workload():
    global arr
    try:
        pd.factorize(arr)
    except TypeError:
        pass

runtimes = timeit.repeat(workload, number=1, repeat=100, setup=setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","An error occurred:

An unknown error occurred. Please check the local files.","Mean: 0.06612869712014799
Std Dev: 0.0015784169963907722
Mean: 0.04141965970033198
Std Dev: 0.0018163238040919609
Improvement:-37.37%",908,docker.io/sweperf/sweperf:pandas-dev__pandas-51921,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51921,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51921 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-13 0:27:22,6169cba72dbe8c7e9c7f17ab38af15a256f083da,1.5
,APPROVED,pandas-dev__pandas-52941,https://github.com/pandas-dev/pandas/pull/52941,"import pandas as pd
import numpy as np
import timeit
import statistics

def setup():
    global df, items
    n_cols = 100_000
    n_rows = 1000
    df = pd.DataFrame(np.random.randn(n_rows, n_cols),
                      columns=[f""col_{i}"" for i in range(n_cols)])

    items = np.random.choice(df.columns, size=int(n_cols * 0.6), replace=False)
    items = items.tolist()
    np.random.shuffle(items)

def workload():
    global df, items
    df.filter(items=items, axis=1)

runtimes = timeit.repeat(workload, number=5, repeat=20, setup=setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Mean: 0.7584849825203855
Std Dev: 0.024497581045177817
Mean: 0.3317004263797571
Std Dev: 0.040228375249816095
Improvement:-56.27%","Mean: 0.7584849825203855
Std Dev: 0.024497581045177817
Mean: 0.3317004263797571
Std Dev: 0.040228375249816095
Improvement:-56.27%",2,docker.io/sweperf/sweperf:pandas-dev__pandas-52941,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52941,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52941 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-26 19:06:34,103d3b2bb8912c87f3ec11c1048e7e0a19225fef,2
,APPROVED,pandas-dev__pandas-53772,https://github.com/pandas-dev/pandas/pull/53772,"import pandas as pd
import timeit
import statistics
import numpy as np

def setup():
    global frame_c
    frame_c = pd.DataFrame(np.zeros((10000, 200), dtype=np.float32, order=""C""))

def workload():
    global frame_c
    pd.concat([frame_c] * 20, axis=0, ignore_index=False)

runtimes = timeit.repeat(workload, number=10, repeat=100, setup=setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Mean: 0.40137035182000547
Std Dev: 0.014534566141506267
Mean: 0.09666506047964503
Std Dev: 0.0477338958277939
Improvement:-75.92%","Mean: 0.40137035182000547
Std Dev: 0.014534566141506267
Mean: 0.09666506047964503
Std Dev: 0.0477338958277939
Improvement:-75.92%",35,docker.io/sweperf/sweperf:pandas-dev__pandas-53772,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53772,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53772 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-06-21 15:24:15,012575a82f4a80c1b87b6f3390ef8de757aeabec,2
,APPROVED,pandas-dev__pandas-54510,https://github.com/pandas-dev/pandas/pull/54510,"import pandas as pd
import numpy as np
import timeit
import statistics

def setup():
    global left, right
    N = 500_000

    keys = pd.Series([f""key_{i}"" for i in range(N)], dtype=""string[pyarrow]"")

    left = pd.DataFrame({""key"": keys, ""val"": np.random.randn(N)})
    right = pd.DataFrame({""key"": keys.sample(frac=0.8, random_state=42).reset_index(drop=True)})

def workload():
    global left, right
    
    _ = left.merge(right, on=""key"", how=""inner"")

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Mean: 0.31490139169836767
Std Dev: 0.021255957258046118
Mean: 0.1377519874004065
Std Dev: 0.016394287152663913
Improvement:-56.26%","Mean: 0.31490139169836767
Std Dev: 0.021255957258046118
Mean: 0.1377519874004065
Std Dev: 0.016394287152663913
Improvement:-56.26%",41,docker.io/sweperf/sweperf:pandas-dev__pandas-54510,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54510,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54510 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-08-12 7:35:54,62227895d26bfccfc78260ce0dddaebeab0672fe,2
,APPROVED,pandas-dev__pandas-57478,https://github.com/pandas-dev/pandas/pull/57478,"import numpy as np
import timeit
import statistics
from pandas.core.dtypes.astype import astype_is_view

def setup():
    global pairs
    pairs = [
        (np.dtype(""int64""), np.dtype(""int64"")),
        (np.dtype(""float32""), np.dtype(""float64"")),
        (np.dtype(""uint8""), np.dtype(""uint8"")),
        (np.dtype(""int64""), np.dtype(""int32"")),
    ]

def workload():
    global pairs
    for d1, d2 in pairs:
        _ = astype_is_view(d1, d2)
        _ = astype_is_view(d2, d1)

runtimes = timeit.repeat(workload, number=1000, repeat=1000, setup=setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Mean: 0.004009195620000924
Std Dev: 4.581171247642226e-05
Mean: 0.003218159492999007
Std Dev: 7.299954092138448e-05
Improvement:-19.73%","Mean: 0.004009195620000924
Std Dev: 4.581171247642226e-05
Mean: 0.003218159492999007
Std Dev: 7.299954092138448e-05
Improvement:-19.73%",464,docker.io/sweperf/sweperf:pandas-dev__pandas-57478,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57478,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57478 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-02-17 23:16:27,9eb15535662ac80bef1522b483fc2a6a42e0e192,2.2
,APPROVED,pandas-dev__pandas-57479,https://github.com/pandas-dev/pandas/pull/57479,"import pandas as pd
import numpy as np
import timeit
import statistics

def setup():
    global df, values
    N = 10**5
    dt_ns = pd.date_range(""2022-01-01"", periods=N, freq=""min"").to_numpy().copy()
    dt_ms = dt_ns.astype(""datetime64[ms]"").copy()
    dt_ns[::2] = np.datetime64('NaT')  # now works!
    dt_ms[1::2] = np.datetime64('NaT')
    df = pd.DataFrame({
        ""ns_col"": dt_ns,
        ""ms_col"": dt_ms,
        ""other"": np.random.randn(N)
    })
    values = {
        ""ns_col"": pd.Timestamp(""2022-01-02""),
        ""ms_col"": pd.Timestamp(""2022-01-03"").to_datetime64()
    }

def workload():
    global df, values
    d = df.copy()
    d.fillna(value=values, inplace=True)

runtimes = timeit.repeat(workload, number=100, repeat=100, setup=setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Mean: 0.125603107609993
Std Dev: 0.00472524567272216
Mean: 0.08469125963999431
Std Dev: 0.002833652464994697
Improvement:-32.57%","Mean: 0.125603107609993
Std Dev: 0.00472524567272216
Mean: 0.08469125963999431
Std Dev: 0.002833652464994697
Improvement:-32.57%",948,docker.io/sweperf/sweperf:pandas-dev__pandas-57479,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57479,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57479 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-02-18 0:21:26,1f622e2b5303650fa5e497e4552d0554e51049cb,2.2
,APPROVED,astropy__astropy-10814,https://github.com/astropy/astropy/pull/10814,"import timeit
import statistics

from astropy.coordinates import SkyCoord, CIRS
import numpy as np
import astropy.units as u
from astropy.time import Time

def setup():
    global t, icrs 
    t = Time('2020-10-01T20:00') + np.random.uniform(0, 1, size=100000) * u.min
    icrs = SkyCoord.from_name('Crab')

def workload():
    icrs.transform_to(CIRS(obstime=t))

runtimes = timeit.repeat(workload, number=1, repeat=3, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 10.003757067985134
Before SD: 0.003030103921639977
After Mean: 7.072388758475427
After SD: 0.00737353912196478
Improvement: -29.30%",,9,docker.io/sweperf/sweperf:astropy__astropy-10814,docker.io/sweperf/sweperf_annotate:astropy__astropy-10814,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-10814 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2020-10-08 16:56:57,ff57f89ef5307a91d1d4fe6e82eb87d29668b27a,3.2
,APPROVED,astropy__astropy-12699,https://github.com/astropy/astropy/pull/12699,"import timeit
import statistics
import astropy.units as u
    
def workload():
    u.Unit('km/s', format='fits')

runtimes = timeit.repeat(workload, number=1, repeat=2000)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 0.0006736569721251726
Before SD: 7.619754380439925e-06
After Mean: 4.1917914466466755e-05
After SD: 1.4388061346487691e-06
Improvement: -93.78%",,24,docker.io/sweperf/sweperf:astropy__astropy-12699,docker.io/sweperf/sweperf_annotate:astropy__astropy-12699,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-12699 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2022-01-08 20:28:18,dd8ccdde27858d076b8dbb676364e520ca06f987,4.3
,APPROVED,astropy__astropy-12701,https://github.com/astropy/astropy/pull/12701,"import timeit
import statistics
from astropy.time import Time, TimeDelta
import astropy.units as u
import numpy as np

def setup():
    global t0, t1, dt
    dt = TimeDelta(1 * u.hour)
    t0 = Time('2021-01-01')
    t1 = Time('2022-01-01')
    
def workload():
    global t0, t1, dt
    Time(np.arange(t0, t1, dt))

runtimes = timeit.repeat(workload, number=1, repeat=20, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10:]))","Before Mean: 0.9766846747952513
Before SD: 0.00554909211630871
After Mean: 0.8277796211943496
After SD: 0.004935394021512362
Improvement: -15.25%",,21,docker.io/sweperf/sweperf:astropy__astropy-12701,docker.io/sweperf/sweperf_annotate:astropy__astropy-12701,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-12701 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2022-01-09 18:33:11,dd5b594334c43ff504e035d94f3e5ed017ff1d14,4.3
,APPROVED,astropy__astropy-13471,https://github.com/astropy/astropy/pull/13471,"import timeit
import statistics
import astropy.io.fits
import astropy.units as u
from astropy.coordinates import (
    EarthLocation, AltAz, SkyCoord, CoordinateAttribute, BaseCoordinateFrame,
    UnitSphericalRepresentation, RepresentationMapping,
)
from astropy.time import Time

def setup():
    global ExampleFrame, coord_attr, coord
    class ExampleFrame(BaseCoordinateFrame):
        frame_specific_representation_info = {
            UnitSphericalRepresentation: [
                RepresentationMapping(""lon"", ""fov_lon""),
                RepresentationMapping(""lat"", ""fov_lat""),
            ]
        }
        default_representation = UnitSphericalRepresentation
        coord_attr = CoordinateAttribute(default=None, frame=AltAz)

    loc = EarthLocation.of_site(""Roque de los Muchachos"")
    t = Time.now()
    frame = AltAz(location=loc, obstime=t)
    coord = SkyCoord(0 * u.deg, 0 * u.deg, frame=frame)

def workload():
    global ExampleFrame, coord
    ExampleFrame(coord_attr=coord)

runtimes = timeit.repeat(workload, number=10, repeat=2000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 0.006661600690858904
Before SD: 7.498147441639642e-05
After Mean: 0.0001905392372282222
After SD: 4.710246969806216e-06
Improvement: -97.14%",,6,docker.io/sweperf/sweperf:astropy__astropy-13471,docker.io/sweperf/sweperf_annotate:astropy__astropy-13471,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-13471 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2022-07-21 16:33:37,31c6b608ec26b27fe61146699f2ffe8775474b43,5
,APPROVED,astropy__astropy-13497,https://github.com/astropy/astropy/pull/13497,"import timeit
import statistics
import astropy.units as u
from astropy.units import Quantity
import numpy as np
from astropy.coordinates.angles import Longitude, Latitude, Angle

def setup():
    global values1, values2
    values1 = np.random.uniform(-180, 180, 100)
    values2 = np.random.uniform(0, 359, 100)
    
def workload():
    global values1, values2
    Longitude(values1, u.deg)
    Longitude(values2, u.deg)

runtimes = timeit.repeat(workload, number=10, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 0.000842729610967217
Before SD: 1.1829718617998603e-05
After Mean: 0.0005994128172111232
After SD: 1.0923964204189495e-05
Improvement: -28.87%",,46,docker.io/sweperf/sweperf:astropy__astropy-13497,docker.io/sweperf/sweperf_annotate:astropy__astropy-13497,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-13497 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2022-07-25 13:57:44,1efaab7bb3c117a14d3f6accf77239a44e59e0df,5
,APPROVED,astropy__astropy-13898,https://github.com/astropy/astropy/pull/13898,"import timeit
import statistics
import astropy.io.fits
import numpy as np
from astropy.visualization.interval import ManualInterval

np.random.seed(0)

def setup():
    global interval, data
    
    interval = ManualInterval(vmin=0.1, vmax=0.9)
    data = np.random.uniform(0, 1, size=10000)
    
def workload():
    global interval, data
    interval.get_limits(data)

runtimes = timeit.repeat(workload, number=10, repeat=2000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 8.98653628595639e-05
Before SD: 1.6250181478220107e-06
After Mean: 1.8566172395367175e-06
After SD: 2.1095603641820587e-07
Improvement: -97.93%",,8,docker.io/sweperf/sweperf:astropy__astropy-13898,docker.io/sweperf/sweperf_annotate:astropy__astropy-13898,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-13898 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2022-10-25 22:41:15,cdf311e0714e611d48b0a31eb1f0e2cbffab7f23,5.1
,APPROVED,astropy__astropy-13899,https://github.com/astropy/astropy/pull/13899,"import timeit
import statistics
import astropy.io.fits
import numpy as np
from astropy.visualization.interval import ManualInterval

np.random.seed(0)

def setup():
    global interval, data
    
    interval = ManualInterval(vmin=0.1, vmax=0.9)
    data = np.random.uniform(0, 1, size=10000)
    
def workload():
    global interval, data
    interval.get_limits(data)

runtimes = timeit.repeat(workload, number=10, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 9.082150810863823e-05
Before SD: 2.7540190624031772e-06
After Mean: 1.9214993459172547e-06
After SD: 2.377328138641357e-07
Improvement: -97.88%",,8,docker.io/sweperf/sweperf:astropy__astropy-13899,docker.io/sweperf/sweperf_annotate:astropy__astropy-13899,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-13899 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2022-10-25 23:17:37,e262c71045449433040980555074d0941dd6230f,5.1
,APPROVED,astropy__astropy-15900,https://github.com/astropy/astropy/pull/15900,"import timeit
import statistics
import numpy as np
import astropy.units as u
from astropy.coordinates import Distance

def setup():
    global parallax_scalar
    parallax_scalar = 2 * u.mas
    
def workload():
    global parallax_scalar
    Distance(parallax=parallax_scalar)

runtimes = timeit.repeat(workload, number=1, repeat=2000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 8.722483686869964e-05
Before SD: 2.1475789131444615e-06
After Mean: 7.923439342994243e-05
After SD: 2.0276648133629018e-06
Improvement: -9.16%",,25,docker.io/sweperf/sweperf:astropy__astropy-15900,docker.io/sweperf/sweperf_annotate:astropy__astropy-15900,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-15900 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-01-16 21:01:00,0da28efef20e0c2acb59d8e22048c1d92e496610,v5.3
,APPROVED,astropy__astropy-16088,https://github.com/astropy/astropy/pull/16088,"import timeit
import statistics
import astropy.units as u
from astropy.units import Quantity
import numpy as np
from astropy.coordinates.angles import Longitude, Latitude, Angle

def setup():
    global values
    values = np.random.uniform(-89, 89, 100)
    
def workload():
    global hdu_non_zero
    Angle(values, u.deg)

runtimes = timeit.repeat(workload, number=10, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 0.0001602864873188082
Before SD: 4.251285532619667e-06
After Mean: 4.5033314154716205e-05
After SD: 8.963363465792805e-06
Improvement: -71.90%",,49,docker.io/sweperf/sweperf:astropy__astropy-16088,docker.io/sweperf/sweperf_annotate:astropy__astropy-16088,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-16088 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-02-21 15:55:32,ea875472867f296eee3ed75989ed402d55587940,v5.3
,APPROVED,astropy__astropy-16096,https://github.com/astropy/astropy/pull/16096,"import timeit
import statistics
import astropy.units as u
from astropy.units import Quantity
import numpy as np
from astropy.coordinates.angles import Longitude, Latitude, Angle

def setup():
    global values
    values = np.random.uniform(-89, 89, 100)
    
def workload():
    global hdu_non_zero
    Latitude(values, u.deg)

runtimes = timeit.repeat(workload, number=10, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 0.0001395109969540499
Before SD: 2.9367365909135036e-06
After Mean: 0.00010383209302090109
After SD: 1.0323850077678013e-05
Improvement: -25.57%",,49,docker.io/sweperf/sweperf:astropy__astropy-16096,docker.io/sweperf/sweperf_annotate:astropy__astropy-16096,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-16096 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-02-23 8:59:11,7ddf5ee8f3939db79cabebd627fad724c4d8e872,v5.3
,APPROVED,astropy__astropy-16222,https://github.com/astropy/astropy/pull/16222,"import timeit
import statistics
import numpy as np
from astropy.coordinates import SkyCoord, UnitSphericalRepresentation
import astropy.units as u

class SkyCoordBenchmarks:
    def setup(self):
        self.coord_scalar = SkyCoord(1, 2, unit=""deg"", frame=""icrs"")
        lon, lat = np.ones((2, 1000))
        self.coord_array_1e3 = SkyCoord(lon, lat, unit=""deg"", frame=""icrs"")
        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))
        self.coord_array_1e6 = SkyCoord(
            self.lon_1e6, self.lat_1e6, unit=""deg"", frame=""icrs""
        )
        
        self.scalar_q_ra = 1 * u.deg
        self.scalar_q_dec = 2 * u.deg
        
        np.random.seed(12345)
        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg
        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg
        
        self.scalar_repr = UnitSphericalRepresentation(
            lon=self.scalar_q_ra, lat=self.scalar_q_dec
        )
        self.array_repr = UnitSphericalRepresentation(
            lon=self.array_q_ra, lat=self.array_q_dec
        )

    def time_init_repr_array_noframe(self):
        SkyCoord(self.array_repr)

def setup():
    global bench
    bench = SkyCoordBenchmarks()
    bench.setup()
    print(""finishone"")

def workload():
    global bench
    bench.time_init_repr_array_noframe()

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.03463494285766501
Before SD: 0.00045883767021412825
After Mean: 0.012496425629942678
After SD: 0.0003645408977370976
Improvement: -63.92%",,49,docker.io/sweperf/sweperf:astropy__astropy-16222,docker.io/sweperf/sweperf_annotate:astropy__astropy-16222,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-16222 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-03-19 22:19:41,96cc7fbefd59e79d096802efe9f75b2f1d042487,v5.3
,APPROVED,astropy__astropy-16243,https://github.com/astropy/astropy/pull/16243,"import timeit
import statistics
import numpy as np
from astropy.coordinates.angles import Angle

def setup():
    global values
    values = np.random.uniform(-89, 89, 100)

def workload():
    global values
    Angle(values, ""deg"")

runtimes = timeit.repeat(workload, number=10, repeat=2000, setup=setup)
print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 6.999238702701405e-05
Before SD: 2.864686669887966e-06
After Mean: 4.150382021907717e-05
After SD: 1.7857869226392834e-06
Improvement: -40.70%",,49,docker.io/sweperf/sweperf:astropy__astropy-16243,docker.io/sweperf/sweperf_annotate:astropy__astropy-16243,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-16243 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-03-26 18:53:51,33265f16ebb00d3c6c5812911df0d9b4e1bbb8e0,v5.3
,APPROVED,astropy__astropy-16295,https://github.com/astropy/astropy/pull/16295,"import timeit
import statistics
import astropy.io.fits
import numpy as np
from astropy.coordinates.angles.formats import _check_hour_range

def workload():
    _check_hour_range(15)

runtimes = timeit.repeat(workload, number=10, repeat=2000)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 0.00010237395804142579
Before SD: 2.067405181604873e-06
After Mean: 8.958095568232238e-07
After SD: 1.733790140865312e-07
Improvement: -99.12%",,13,docker.io/sweperf/sweperf:astropy__astropy-16295,docker.io/sweperf/sweperf_annotate:astropy__astropy-16295,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-16295 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-04-16 16:29:28,769ad41652038d7d2aba9657a28f0ce8aaac982d,v5.3
,APPROVED,astropy__astropy-16670,https://github.com/astropy/astropy/pull/16670,"import timeit
import statistics
import numpy as np
from astropy.modeling.models import Gaussian1D

def setup():
    global g, x
    g = Gaussian1D()
    x = np.linspace(-10, 10, 100)

def workload():
    global g, x
    g(x)

runtimes = timeit.repeat(workload, number=10000, repeat=20, setup= setup)

print(""Mean:"", statistics.mean(runtimes[-10:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10:]))","Before Mean: 0.32920104659860955
Before SD: 0.003313816684569556
After Mean: 0.25523713920847513
After SD: 0.004299023613522338
Improvement: -22.47%",,30,docker.io/sweperf/sweperf:astropy__astropy-16670,docker.io/sweperf/sweperf_annotate:astropy__astropy-16670,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-16670 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-07-04 9:43:48,f5126c765a6a8db8abc7504275d9c2e90ffbd526,v5.3
,APPROVED,astropy__astropy-16673,https://github.com/astropy/astropy/pull/16673,"import timeit
import statistics
from astropy.modeling.models import Gaussian1D
from astropy.modeling.fitting import TRFLSQFitter
import numpy as np

def setup():
    global fitter, g, x, y
    g = Gaussian1D() + Gaussian1D()
    fitter = TRFLSQFitter()
    np.random.seed(12345)
    x = np.linspace(-10, 10, 100)
    y = np.exp(-(x - 1.1) ** 2 / 3) + np.random.uniform(-0.2, 0.2, 100)
    
def workload():
    global fitter, g, x, y
    _ = fitter(g, x, y)

runtimes = timeit.repeat(workload, number=100, repeat=25, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-5:]))
print(""Std Dev:"", statistics.stdev(runtimes[-5:]))","Before Mean: 25.067452037602198
Before SD: 0.05884822295142155
After Mean: 8.741871681204065
After SD: 0.02553888311271721
Improvement: -65.13%",,30,docker.io/sweperf/sweperf:astropy__astropy-16673,docker.io/sweperf/sweperf_annotate:astropy__astropy-16673,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-16673 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-07-04 13:31:06,ff59e9cffcd7145f0c8c68be3d4e8426348c055e,v5.3
,APPROVED,astropy__astropy-16742,https://github.com/astropy/astropy/pull/16742,"import timeit
import statistics
import numpy as np
import astropy.units as u
   
@u.quantity_input
def wrapped_function(x: u.m, y: u.m, a, b):
    return x * y
    
def workload():
    wrapped_function(1*u.m, 2*u.m, 1, 2)

runtimes = timeit.repeat(workload, number=1000, repeat=20)

print(""Mean:"", statistics.mean(runtimes[-10:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10:]))","Before Mean: 0.18759116379078478
Before SD: 0.0005686242509979776
After Mean: 0.06054019438452087
After SD: 0.00012766096581163003
Improvement: -67.73%",,25,docker.io/sweperf/sweperf:astropy__astropy-16742,docker.io/sweperf/sweperf_annotate:astropy__astropy-16742,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-16742 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-07-17 20:12:44,6aca9bf6909c364984403e194891e592666fe198,v5.3
,APPROVED,astropy__astropy-16813,https://github.com/astropy/astropy/pull/16813,"import timeit
import statistics
import numpy as np
from astropy import units as u
    
def workload():
    u.Unit(""1000m"", format=""cds"")

runtimes = timeit.repeat(workload, number=1000, repeat=200)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.03324703732039779
Before SD: 0.00010629072662667214
After Mean: 0.018633269396959803
After SD: 8.119988103876848e-05
Improvement: -43.96%",,25,docker.io/sweperf/sweperf:astropy__astropy-16813,docker.io/sweperf/sweperf_annotate:astropy__astropy-16813,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-16813 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-08-09 17:48:58,f788114c8a01a966cebdc8710674f88f9f1cdb7c,v5.3
,APPROVED,astropy__astropy-17004,https://github.com/astropy/astropy/pull/17004,"import timeit
import statistics
import numpy as np
from astropy import units as u
from astropy.units.format import Generic, CDS, FITS, OGIP, VOUnit

def setup():
    global formatter
    formatter = None

def workload():
    global formatter
    u.Unit(""m"", format=None)
    u.Unit(""m"", format=FITS)

runtimes = timeit.repeat(workload, number=1000, repeat=200, setup = setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.004403801605221815
Before SD: 2.8029927449616538e-05
After Mean: 0.003413316035293974
After SD: 2.1089192149886925e-05
Improvement: -22.49%",,25,docker.io/sweperf/sweperf:astropy__astropy-17004,docker.io/sweperf/sweperf_annotate:astropy__astropy-17004,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-17004 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-09-12 17:50:05,3ff2463d061e933eaf5c1a1c110edf412c784d4b,v5.3
,APPROVED,astropy__astropy-17032,https://github.com/astropy/astropy/pull/17032,"from astropy.modeling import models, fitting
from astropy.modeling.fitting import parallel_fit_dask
import numpy as np
from astropy.utils import NumpyRNGContext
import timeit
import statistics

N = 1000
x = np.linspace(-5, 5, 100)
y_true = models.Gaussian1D(amplitude=2.5, mean=0.0, stddev=1.2)(x)

ys = []
with NumpyRNGContext(42):
    for _ in range(N):
        noise = np.random.normal(0, 0.1, size=x.size)
        ys.append(y_true + noise)

data = np.stack(ys)

init_model = models.Gaussian1D(amplitude=1.0, mean=0.0, stddev=1.0)
fitter = fitting.LevMarLSQFitter()

def setup():
    pass

def workload():
    fitted_model = parallel_fit_dask(
        model=init_model,
        fitter=fitter,
        data=data,
        fitting_axes=(1,),
        scheduler=""threads"",
    )

runtimes = timeit.repeat(workload, number=1, repeat=20, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.5771934229967883
Before SD: 0.06410829228592804
After Mean: 1.4533495544543258
After SD: 0.046250705164684575
Improvement: -7.85%",,1,docker.io/sweperf/sweperf:astropy__astropy-17032,docker.io/sweperf/sweperf_annotate:astropy__astropy-17032,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-17032 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-09-18 12:04:51,766c3c53899833652730f90c2b705cb420f371b0,v5.3
,APPROVED,astropy__astropy-17043,https://github.com/astropy/astropy/pull/17043,"import timeit
import statistics
import numpy as np
from astropy import units as u
from astropy.units.format import Generic, CDS, FITS, OGIP, VOUnit

def setup():
    global unit, formatter
    unit = u.m / u.s
    formatter = ""cds""

def workload():
    global unit, formatter
    unit.to_string(formatter)

runtimes = timeit.repeat(workload, number=1000, repeat=200, setup = setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.016324892848497256
Before SD: 6.834992916222224e-05
After Mean: 0.006647844290710054
After SD: 7.200044227825848e-05
Improvement: -59.28%",,25,docker.io/sweperf/sweperf:astropy__astropy-17043,docker.io/sweperf/sweperf_annotate:astropy__astropy-17043,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-17043 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-09-19 17:42:51,d09ba92c28a0e22c27e7dfcdd2ed45d3bb7fa80d,v5.3
,APPROVED,astropy__astropy-17425,https://github.com/astropy/astropy/pull/17425,"import timeit
import statistics

from astropy import units as u

def workload():
    u.kg.compose(units=u.si)
    u.Pa.compose(units=u.si)

runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.01556969228334492
Before SD: 9.664176118403767e-05
After Mean: 0.011723632620298303
After SD: 7.884766437269049e-05
Improvement: -24.70%",,11,docker.io/sweperf/sweperf:astropy__astropy-17425,docker.io/sweperf/sweperf_annotate:astropy__astropy-17425,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-17425 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-11-21 18:37:33,157e90a7b1cc995ce7a4eb100167134904ca84fe,v5.3
,APPROVED,astropy__astropy-17461,https://github.com/astropy/astropy/pull/17461,"import timeit
import statistics
import numpy as np
from astropy.io import fits

def workload():
    fits.getdata(""astropy/io/fits/tests/data/tb.fits"")
    
runtimes = timeit.repeat(workload, number=100, repeat=20)

print(""Mean:"", statistics.mean(runtimes[-10:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10:]))","Before Mean: 0.18384283170453272
Before SD: 0.00022836309193570442
After Mean: 0.13931088289245963
After SD: 0.0007401042206871078
Improvement: -24.22%",,6,docker.io/sweperf/sweperf:astropy__astropy-17461,docker.io/sweperf/sweperf_annotate:astropy__astropy-17461,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-17461 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2024-11-26 20:49:34,9818492021c57ba2a879fd810c6e6cd1d1f3d8fe,v5.3
,APPROVED,astropy__astropy-6940,https://github.com/astropy/astropy/pull/6940,"import timeit
import statistics
import numpy as np
import astropy.units as u
from astropy.coordinates import ICRS

def setup():
    global c
    c = ICRS(np.arange(30.)*u.deg, np.arange(30.)*u.deg)

def workload():
    global c
    c[1:2]

runtimes = timeit.repeat(workload, number=1000, repeat=200, setup = setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.2703666665626224
Before SD: 0.0008328834311938307
After Mean: 0.08964820435619913
After SD: 0.00020716119189042765
Improvement: -66.84%",,37,docker.io/sweperf/sweperf:astropy__astropy-6940,docker.io/sweperf/sweperf_annotate:astropy__astropy-6940,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-6940 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2017-12-07 18:25:12,1b97e5cc28a027c7ff9a5361ae60d4b7034cbb1d,1.3
,APPROVED,astropy__astropy-6941,https://github.com/astropy/astropy/pull/6941,"import timeit
import statistics
import numpy as np
import astropy.units as u
from astropy.coordinates.sky_coordinate import SkyCoord

def setup():
    global c
    c = SkyCoord(np.arange(30.)*u.deg, np.arange(30.)*u.deg)

def workload():
    global c
    c[1:2]

runtimes = timeit.repeat(workload, number=100, repeat=200, setup = setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.0809170404280303
Before SD: 0.00016083230625747204
After Mean: 0.0025981506804237144
After SD: 2.10335365253292e-05
Improvement: -96.79%",,27,docker.io/sweperf/sweperf:astropy__astropy-6941,docker.io/sweperf/sweperf_annotate:astropy__astropy-6941,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-6941 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2017-12-07 18:47:54,1210dab3c0828e6ec5aee15fe11caec267a20b0a,1.3
,APPROVED,astropy__astropy-7010,https://github.com/astropy/astropy/pull/7010,"import timeit
import statistics
import numpy as np
import astropy.units as u
from astropy.coordinates import Angle

def setup():
    global a
    a = Angle(np.arange(10.), 'degree')

def workload():
    global a
    np.add.reduce(a)

runtimes = timeit.repeat(workload, number=1000, repeat=200, setup = setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.024238224618020467
Before SD: 8.547201023493127e-05
After Mean: 0.01670803081651684
After SD: 6.302233449021814e-05
Improvement: -31.07%",,15,docker.io/sweperf/sweperf:astropy__astropy-7010,docker.io/sweperf/sweperf_annotate:astropy__astropy-7010,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-7010 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2017-12-20 20:08:04,ee6d681a230cb9aac2eec4a5d056eaea9a44288f,1.3
,APPROVED,astropy__astropy-7422,https://github.com/astropy/astropy/pull/7422,"import timeit
import statistics
import numpy as np
from astropy.table.column import MaskedColumn

def setup():
    global dat
    dat = np.arange(1e7)

def workload():
    global dat
    _ = MaskedColumn(dat)
    
runtimes = timeit.repeat(workload, number=1, repeat=20, setup = setup)

print(""Mean:"", statistics.mean(runtimes[-10:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10:]))","Before Mean: 1.09245645669871
Before SD: 0.002370894998392344
After Mean: 0.0005724725080654026
After SD: 3.0400687844930164e-05
Improvement: -99.95%",,15,docker.io/sweperf/sweperf:astropy__astropy-7422,docker.io/sweperf/sweperf_annotate:astropy__astropy-7422,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-7422 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2018-05-03 1:49:15,09d963266765e3fb0bb907792e5a65d6dd42f925,1.3
,APPROVED,astropy__astropy-7549,https://github.com/astropy/astropy/pull/7549,"import timeit
import statistics
import numpy as np
import astropy.units as u

def setup():
    global a
    a = np.arange(10.) * u.m

def workload():
    global a
    _ = np.sqrt(a)

runtimes = timeit.repeat(workload, number=1000, repeat=200, setup = setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.018044526543235406
Before SD: 6.206973558718944e-05
After Mean: 0.012172909688088112
After SD: 5.836690170760844e-05
Improvement: -32.54%",,18,docker.io/sweperf/sweperf:astropy__astropy-7549,docker.io/sweperf/sweperf_annotate:astropy__astropy-7549,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-7549 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2018-06-07 15:15:37,05caa0d16a1905a292888a56829df2420bad92f9,1.3
,APPROVED,astropy__astropy-7616,https://github.com/astropy/astropy/pull/7616,"import timeit
import statistics
import numpy as np
import astropy.units as u
from astropy.coordinates.angles import Longitude

def setup():
    global ra
    ra = 3 * u.deg

def workload():
    global ra
    Longitude(ra)

runtimes = timeit.repeat(workload, number=1000, repeat=200, setup = setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.03592339604219887
Before SD: 7.998029795609665e-05
After Mean: 0.028232874040259048
After SD: 7.115665033513535e-05
Improvement: -21.41%",,38,docker.io/sweperf/sweperf:astropy__astropy-7616,docker.io/sweperf/sweperf_annotate:astropy__astropy-7616,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-7616 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2018-07-01 14:31:39,b5f7c4da726ef252d12b0c933bfbd5ba3d07818d,1.3
,APPROVED,astropy__astropy-7643,https://github.com/astropy/astropy/pull/7643,"import timeit
import statistics
import numpy as np
from astropy.units import deg

def workload():
    deg.to(deg)

runtimes = timeit.repeat(workload, number=100000, repeat=2000)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.08814924993261229
Before SD: 0.0002108123550369303
After Mean: 0.013869462111615575
After SD: 0.00010153347486963707
Improvement: -84.27%",,18,docker.io/sweperf/sweperf:astropy__astropy-7643,docker.io/sweperf/sweperf_annotate:astropy__astropy-7643,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-7643 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2018-07-12 17:24:00,d74d02fba817a647af5ff56ec874df0a1a39e9f4,1.3
,APPROVED,astropy__astropy-7649,https://github.com/astropy/astropy/pull/7649,"import timeit
import statistics
import numpy as np
import astropy.units as u

def workload():
    u.CompositeUnit(1.e-9, [u.m], [1], _error_check=False)

runtimes = timeit.repeat(workload, number=10000, repeat=2000)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 0.055400757041061295
Before SD: 0.00012024918229611868
After Mean: 0.009914387238037307
After SD: 3.668077230640713e-05
Improvement: -82.10%",,20,docker.io/sweperf/sweperf:astropy__astropy-7649,docker.io/sweperf/sweperf_annotate:astropy__astropy-7649,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-7649 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2018-07-12 23:23:58,999a3a44edcf43745e544c21d0d8c33a16db26f7,1.3
,APPROVED,astropy__astropy-7924,https://github.com/astropy/astropy/pull/7924,"import timeit
import statistics

from astropy import units as u
from astropy import coordinates as coord

def setup():
    global rep, dif
    rep = coord.CartesianRepresentation([1., 2, 3] * u.kpc)
    dif = coord.CartesianDifferential([1, 2, 3.] * u.km/u.s)

def workload():
    dif._get_deriv_key(rep)
    rep.with_differentials(dif)
    coord.ICRS(ra=1*u.deg, dec=2*u.deg, pm_ra_cosdec=1*u.mas/u.yr, pm_dec=2*u.mas/u.yr)

runtimes = timeit.repeat(workload, number=5, repeat=1000, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.05212223191530211
Before SD: 0.00016936242503051265
After Mean: 0.0035399773694807664
After SD: 5.789122999412517e-05
Improvement: -93.21%",,15,docker.io/sweperf/sweperf:astropy__astropy-7924,docker.io/sweperf/sweperf_annotate:astropy__astropy-7924,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-7924 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2018-10-19 3:21:27,1cb6af9ab04ae4208e3f02c0841fa7cec7b276c5,3
,APPROVED,astropy__astropy-8349,https://github.com/astropy/astropy/pull/8349,"import timeit
import statistics

from astropy.modeling import models, fitting
from astropy import units as u
import numpy as np

n = 22
x0 = np.random.rand(n) * 100
y0 = np.random.rand(n) * 100
xstd = np.random.rand(n) * 5
ystd = np.random.rand(n) * 5

def setup():
    global model, out
    model = None
    for x_mean, y_mean, x_stddev, y_stddev in zip(x0, y0, xstd, ystd):
        gauss = models.Gaussian2D(x_mean=x_mean, y_mean=y_mean, x_stddev=x_stddev, y_stddev=y_stddev)
        if model is None:
            model = gauss
        else:
            model += gauss

    out = np.zeros((100, 100))

def workload():
    global model, out
    model.render(out)

runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.3348988196835854
Before SD: 0.02035387990199112
After Mean: 0.005130455642938614
After SD: 9.148367751179334e-05
Improvement: -99.78%",,22,docker.io/sweperf/sweperf:astropy__astropy-8349,docker.io/sweperf/sweperf_annotate:astropy__astropy-8349,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-8349 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2019-01-15 16:27:36,998f666b8349cf758eceb1fc140d9b8e7258ff88,3
,APPROVED,astropy__astropy-8428,https://github.com/astropy/astropy/pull/8428,"import timeit
import statistics
import tempfile
import os

from astropy.io import fits

N_EXTENSIONS = 335          
CARDS_PER_KIND = 425      

def make_header(ncards=CARDS_PER_KIND):
    cards = {
        **{f""INT{i}"": i for i in range(ncards)},
        **{f""FLT{i}"": i + i / 10.0 for i in range(ncards)},
        **{f""STR{i}"": f""VALUE {i}"" for i in range(ncards)},
        **{f""HIERARCH FOO BAR {i}"": i for i in range(ncards)},
    }
    return fits.Header(cards)

hdr = make_header()
hdul = fits.HDUList(
    [fits.PrimaryHDU(header=hdr)] +
    [fits.ImageHDU(header=hdr) for _ in range(N_EXTENSIONS)]
)

temp_fits = tempfile.NamedTemporaryFile(suffix="".fits"", delete=False)
hdul.writeto(temp_fits.name, overwrite=True)

def workload():
    len(fits.open(temp_fits.name))

runtimes = timeit.repeat(workload, number=1, repeat=10)

os.remove(temp_fits.name)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.3748016394965816
Before SD: 0.04548551225521506
After Mean: 3.012188387301285
After SD: 0.04838260082221467
Improvement: -10.74%",,25,docker.io/sweperf/sweperf:astropy__astropy-8428,docker.io/sweperf/sweperf_annotate:astropy__astropy-8428,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-8428 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2019-02-15 23:16:00,8d97a4f9d62a76629ac9b86ebd1c22c340ea7a0e,3
,APPROVED,astropy__astropy-8493,https://github.com/astropy/astropy/pull/8493,"import timeit
import statistics

from astropy.table import Table
import numpy as np

def setup():
    global wide_tbl, narrow_tbl, slice_1, slice_2, fancy_idx, bool_mask

    n_rows = 100_000
    rng = np.random.default_rng(0)

    wide_tbl = Table({f""c{i}"": rng.random(n_rows) for i in range(25)})
    narrow_tbl = Table({f""c{i}"": rng.random(n_rows) for i in range(3)})

    slice_1   = slice(None)                
    slice_2   = slice(None, None, 2)      
    fancy_idx = np.arange(0, n_rows, 2) 
    bool_mask = (np.arange(n_rows) % 2) == 0


def workload():
    global wide_tbl, narrow_tbl, slice_1, slice_2, fancy_idx, bool_mask

    # --- wide table ---
    _ = wide_tbl[slice_1]
    _ = wide_tbl[slice_2]
    _ = wide_tbl[fancy_idx]
    _ = wide_tbl[bool_mask]

    # --- narrow table ---
    _ = narrow_tbl[slice_1]
    _ = narrow_tbl[slice_2]
    _ = narrow_tbl[fancy_idx]
    _ = narrow_tbl[bool_mask]

runtimes = timeit.repeat(workload, number=1, repeat=20, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.016671962797408922
Before SD: 0.0014536300434834309
After Mean: 0.014684626943198964
After SD: 0.002023690509660388
Improvement: -11.92%",,21,docker.io/sweperf/sweperf:astropy__astropy-8493,docker.io/sweperf/sweperf_annotate:astropy__astropy-8493,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-8493 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2019-03-10 16:28:15,2394af9f65825d48961457636fe8b5d40d8ad9b9,3.1
,APPROVED,astropy__astropy-8494,https://github.com/astropy/astropy/pull/8494,"import timeit
import statistics

from astropy.table import Table
import numpy as np


def simple_table(cols: int = 25, size: int = 100) -> Table:
    rng = np.random.default_rng(42)
    data = {chr(ord(""a"") + i): rng.random(size) for i in range(cols)}
    return Table(data)


def setup():
    global t
    t = simple_table(cols=25, size=100)

def workload():
    global t
    _ = t[1]
    for r in t:
        _ = r[""a""], r[""b""], r[""c""], r[""d""], r[""e""]

    ta, tb, tc, td, te = t[""a""], t[""b""], t[""c""], t[""d""], t[""e""]
    for ra, rb, rc, rd, re in zip(ta, tb, tc, td, te):
        _ = ra, rb, rc, rd, re

runtimes = timeit.repeat(workload, number=1, repeat=20, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0008115677570458502
Before SD: 1.347631016860501e-05
After Mean: 0.0003572843532310799
After SD: 5.7466518699475785e-06
Improvement: -55.98%",,21,docker.io/sweperf/sweperf:astropy__astropy-8494,docker.io/sweperf/sweperf_annotate:astropy__astropy-8494,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-8494 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2019-03-11 11:20:31,987be7297fed38e9fba0047419fe54cbe5f0d709,3.1
,APPROVED,astropy__astropy-8502,https://github.com/astropy/astropy/pull/8502,"import timeit
import statistics
import tempfile
import os

from astropy.io import fits

N_EXTENSIONS = 335          
CARDS_PER_KIND = 425      

def make_header(ncards=CARDS_PER_KIND):
    cards = {
        **{f""INT{i}"": i for i in range(ncards)},
        **{f""FLT{i}"": i + i / 10.0 for i in range(ncards)},
        **{f""STR{i}"": f""VALUE {i}"" for i in range(ncards)},
        **{f""HIERARCH FOO BAR {i}"": i for i in range(ncards)},
    }
    return fits.Header(cards)

hdr = make_header()
hdul = fits.HDUList(
    [fits.PrimaryHDU(header=hdr)] +
    [fits.ImageHDU(header=hdr) for _ in range(N_EXTENSIONS)]
)

temp_fits = tempfile.NamedTemporaryFile(suffix="".fits"", delete=False)
hdul.writeto(temp_fits.name, overwrite=True)

def workload():
    fits.getheader(temp_fits.name, ext=300)

runtimes = timeit.repeat(workload, number=1, repeat=25)

os.remove(temp_fits.name)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 2.6719567246036604
Before SD: 0.031655494408335
After Mean: 0.21950087611563504
After SD: 0.004044479543089526
Improvement: -91.79%",,25,docker.io/sweperf/sweperf:astropy__astropy-8502,docker.io/sweperf/sweperf_annotate:astropy__astropy-8502,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-8502 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2019-03-16 0:09:10,33db190c86941ea8b120814813d9fd4a5d423768,3.1
,APPROVED,astropy__astropy-8998,https://github.com/astropy/astropy/pull/8998,"import timeit
import statistics
import numpy as np

def patch_numpy():

    for name, repl in [
        (""int"", int),
        (""float"", float),
        (""bool"", bool),
        (""object"", object),
        (""str"", str),
        (""long"", int),
        (""complex"", complex),
        (""unicode"", str),
    ]:
        if not hasattr(np, name):
            setattr(np, name, repl)
            
    if not hasattr(np, ""asscalar""):
        np.asscalar = lambda a: a.item()
    if not hasattr(np, ""alen""):
        np.alen = lambda a: len(a)
    if not hasattr(np, ""rank""):
        np.rank = lambda a: np.ndim(a)
        
patch_numpy()
import astropy.units as u
from astropy.table import MaskedColumn

def setup():
    global m
    m = MaskedColumn([1, 2])

def workload():
    global m
    m.info

runtimes = timeit.repeat(workload, number=1000, repeat=2000, setup = setup)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 0.0011402966674650089
Before SD: 3.8515040033626756e-05
After Mean: 0.00027171488740714266
After SD: 2.8878465755819313e-06
Improvement: -76.17%",,87,docker.io/sweperf/sweperf:astropy__astropy-8998,docker.io/sweperf/sweperf_annotate:astropy__astropy-8998,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:astropy__astropy-8998 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",astropy/astropy,2019-07-15 1:34:23,387c3d28653706ad59e689bd3755b9e92f91305f,3.1
,APPROVED,dask__dask-10356,https://github.com/dask/dask/pull/10356,"import timeit
import statistics

from dask.bag.core import random_state_data_python

def workload():
    random_state_data_python(10000, 0)
    
runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.7729226380574983
Before SD: 0.013510905872480907
After Mean: 0.2821831404173281
After SD: 0.011016035903977829
Improvement: -92.52%",,1,docker.io/sweperf/sweperf:dask__dask-10356,docker.io/sweperf/sweperf_annotate:dask__dask-10356,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-10356 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2023-06-14 10:53:34,bdc71ba5a4ad7bfb0265a52a1b816936604845fe,2023.6
,APPROVED,dask__dask-10428,https://github.com/dask/dask/pull/10428,"import timeit
import statistics

import dask.dataframe as dd
from dask.utils import parse_bytes
from dask.sizeof import sizeof
from dask.datasets import timeseries
import pandas as pd

def timeseries_of_size(
    target_nbytes,
    *,
    start=""2000-01-01"",
    freq=""1s"",
    partition_freq=""1d"",
    dtypes={""name"": str, ""id"": int, ""x"": float, ""y"": float},
    seed=None,
    **kwargs,
):
    if isinstance(target_nbytes, str):
        target_nbytes = parse_bytes(target_nbytes)

    start_dt = pd.to_datetime(start)
    partition_freq_dt = pd.to_timedelta(partition_freq)

    example_part = timeseries(
        start=start,
        end=start_dt + partition_freq_dt,
        freq=freq,
        partition_freq=partition_freq,
        dtypes=dtypes,
        seed=seed,
        **kwargs,
    )
    p = example_part.compute(scheduler=""threads"")
    partition_size = sizeof(p)
    npartitions = round(target_nbytes / partition_size)

    ts = timeseries(
        start=start,
        end=start_dt + partition_freq_dt * npartitions,
        freq=freq,
        partition_freq=partition_freq,
        dtypes=dtypes,
        seed=seed,
        **kwargs,
    )
    return ts


def setup():
    global df, df2
    df  = timeseries_of_size(""1GB"", start=""2020-01-01"",
                             freq=""600ms"", partition_freq=""12h"",
                             dtypes={str(i): float for i in range(100)})

    df2 = timeseries_of_size(""512MB"", start=""2010-01-01"",
                             freq=""600ms"", partition_freq=""12h"",
                             dtypes={str(i): float for i in range(100)})


def workload():
    # Force alignment, then reduction, then materialise the result
    (df2 - df).mean().compute()

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 4.611844550509704
Before SD: 0.43231068551717095
After Mean: 1.4180699832097161
After SD: 0.013197235987137792
Improvement: -69.25%",,8,docker.io/sweperf/sweperf:dask__dask-10428,docker.io/sweperf/sweperf_annotate:dask__dask-10428,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-10428 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2023-07-25 17:13:16,a8f2acc2e3328707cda2a25cee6cfadec44ec815,2023.7
,APPROVED,dask__dask-10922,https://github.com/dask/dask/pull/10922,"import timeit
import statistics

import dask.array as da
import dask.dataframe as dd
from dask.dataframe.groupby import _nunique_df_chunk


def setup():
    global ddf
    n_rows       = 500_000          
    n_parts      = 5                  
    part_size    = n_rows // n_parts  

    grp = da.arange(n_rows, chunks=part_size)
    val = da.random.random(n_rows, chunks=part_size)

    ddf = dd.concat(
        [dd.from_dask_array(grp, columns=""grp""),
         dd.from_dask_array(val, columns=""val"")],
        axis=1,
    ).persist()

def workload():
    (_nunique_df_chunk(ddf, ""grp"", name=""val"")).compute()

runtimes = timeit.repeat(workload, number=1, repeat=3, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 54.85953725930303
Before SD: 0.37959229633659797
After Mean: 0.1686993149050977
After SD: 0.009041960880500665
Improvement: -99.69%",,2,docker.io/sweperf/sweperf:dask__dask-10922,docker.io/sweperf/sweperf_annotate:dask__dask-10922,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-10922 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2024-02-14 10:09:35,07099e5c0385983ad1cab805e42e66d03fc3f6d3,2024.2
,APPROVED,dask__dask-11466,https://github.com/dask/dask/pull/11466,"import timeit
import statistics

from dask import delayed
import random

N_LAYERS = 50
WIDTH = 100

def generate_deep_graph(n_layers, width):
    base = [delayed(lambda x: x)(i) for i in range(width)]
    layers = [base]

    for _ in range(n_layers):
        prev_layer = layers[-1]
        next_layer = [
            delayed(lambda *args: sum(args))(*random.sample(prev_layer, k=3))
            for _ in range(width)
        ]
        layers.append(next_layer)

    return layers[-1]

def setup():
    global final_sum
    random.seed(42)
    final_layer = generate_deep_graph(N_LAYERS, WIDTH)
    final_sum = delayed(sum)(final_layer)

def workload():
    global final_sum
    final_sum.compute()

runtimes = timeit.repeat(workload, number=1, repeat=20, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.3848998707457213
Before SD: 0.005694867803414778
After Mean: 0.3569968188996427
After SD: 0.008727389537422017
Improvement: -7.25%",,35,docker.io/sweperf/sweperf:dask__dask-11466,docker.io/sweperf/sweperf_annotate:dask__dask-11466,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-11466 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2024-10-29 15:54:57,5c9ccb18e1948a477b3054985273c366f554dc4e,2024.1
,APPROVED,dask__dask-11625,https://github.com/dask/dask/pull/11625,"import timeit
import statistics

import dask.array as da
import numpy as np


def setup():
    global arr_1, idx
    arr_1 = da.ones([6000, 6000], chunks=[3000, 3000])
    idx = np.repeat(np.arange(0, 6000, 6), 1000)


def workload():
    global arr_1
    arr_2 = arr_1.vindex[idx, idx[::-1]]


runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.9064418331847992
Before SD: 0.05839734528274034
After Mean: 0.06989274257747456
After SD: 0.00920834183694063
Improvement: -96.33%",,2,docker.io/sweperf/sweperf:dask__dask-11625,docker.io/sweperf/sweperf_annotate:dask__dask-11625,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-11625 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2024-12-27 17:55:12,fe465e055293851a1920bd9a318c92d1953a8b65,2024.12
,APPROVED,dask__dask-5501,https://github.com/dask/dask/pull/5501,"import timeit
import statistics
import dask
import dask.array as da

# Can replace this with 5_000 as well.
x = [da.asarray([i]) for i in range(5_000)]
x_opt = dask.optimize(*x)

def workload():
    dask.compute(*x_opt)

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.5953405687003397
Before SD: 0.007342560798678122
After Mean: 0.1192686561960727
After SD: 0.007580252359421765
Improvement: -79.97%",,7,docker.io/sweperf/sweperf:dask__dask-5501,docker.io/sweperf/sweperf_annotate:dask__dask-5501,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-5501 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2019-10-17 19:26:28,6d878e68248a12f15bb958951111efe8b030d9e8,2.6
,APPROVED,dask__dask-5553,https://github.com/dask/dask/pull/5553,"import timeit
import statistics

import pandas as pd
import dask.dataframe as dd

def setup():
    global ddf
    data = {}
    for i in range(10000):
        data[""col""+str(i)] = [1.0] * 10
    df = pd.DataFrame(data)
    ddf = dd.from_pandas(df, npartitions=1)

def workload():
    global ddf
    dloc = ddf.loc[0]
    dmeta = ddf._meta_nonempty

runtimes = timeit.repeat(workload, number=1, repeat=100, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.874702638053568
Before SD: 0.00811709165709619
After Mean: 0.48332750459143425
After SD: 0.0017711521842488167
Improvement: -74.22%",,22,docker.io/sweperf/sweperf:dask__dask-5553,docker.io/sweperf/sweperf_annotate:dask__dask-5553,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-5553 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2019-11-02 15:52:56,09f7b637a54280f395a06963c5af115ce42027f3,2.7
,APPROVED,dask__dask-5884,https://github.com/dask/dask/pull/5884,"import timeit
import statistics

import numpy as np
import dask.array as da


class ArrayLikeObject:
    def __init__(self):
        self._array = np.ones((1, 1, 20, 30), dtype=float)
        self.shape = self._array.shape
        self.ndim = self._array.ndim
        self.dtype = self._array.dtype

    def __getitem__(self, item):
        return self._array[item]


def workload():
    meta = np.zeros((0,), dtype=float)
    chunks = [[[[da.from_array(ArrayLikeObject(), meta=meta)] * 269] * 6] * 4]
    da.block(chunks)
    

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.4642023213469656
Before SD: 0.0017288507295616549
After Mean: 0.31062798971193845
After SD: 0.001169792568227729
Improvement: -33.08%",,3,docker.io/sweperf/sweperf:dask__dask-5884,docker.io/sweperf/sweperf_annotate:dask__dask-5884,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-5884 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2020-02-12 13:49:09,d3798151747297a88604e2f853f830f579f7e602,2.11
,APPROVED,dask__dask-5890,https://github.com/dask/dask/pull/5890,"import timeit
import statistics

import dask.array as da
import numpy as np

a = da.from_array(np.ones((1, 1)), chunks=1)
b = da.from_array(np.zeros((1, 1)), chunks=1)
c = a + b
dsk = c.__dask_graph__()
keys = c.__dask_keys__()

def workload():
    da.optimize(dsk, keys)

runtimes = timeit.repeat(workload, number=5000, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.6731996463681571
Before SD: 0.004894217744223935
After Mean: 0.3892542352498276
After SD: 0.0010868350627050451
Improvement: -42.18%",,2,docker.io/sweperf/sweperf:dask__dask-5890,docker.io/sweperf/sweperf_annotate:dask__dask-5890,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-5890 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2020-02-13 12:21:46,5f61f7f79b861be5ffdbf59950889166628a8fa6,2.11
,APPROVED,dask__dask-5891,https://github.com/dask/dask/pull/5891,"import timeit
import statistics

from dask.array.core import slices_from_chunks

def workload():
    slices_from_chunks(((2,) * 1000, (3,) * 1000, (4,) * 10))

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 10.182589858694701
Before SD: 0.17587425682274857
After Mean: 0.7270964732975699
After SD: 0.021837588489922254
Improvement: -92.86%",,26,docker.io/sweperf/sweperf:dask__dask-5891,docker.io/sweperf/sweperf_annotate:dask__dask-5891,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-5891 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2020-02-13 15:07:05,5f61f7f79b861be5ffdbf59950889166628a8fa6,2.11
,APPROVED,dask__dask-5933,https://github.com/dask/dask/pull/5933,"import timeit
import statistics

from pprint import pprint
import dask.array as da
from dask.blockwise import optimize_blockwise
from dask.base import visualize
from dask.array.optimization import optimize

def workload():
    a = da.ones(2000000000, chunks=10000000)
    b = a + a + a
    c = da.sum(b)
    c.compute()

runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.6443155468441546
Before SD: 0.043386703841418864
After Mean: 2.749443135843612
After SD: 0.03408540304441916
Improvement: -24.56%",,14,docker.io/sweperf/sweperf:dask__dask-5933,docker.io/sweperf/sweperf_annotate:dask__dask-5933,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-5933 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2020-02-20 11:08:07,54deb7fa4cdbbf3e124be6834224272be27ace65,2.11
,APPROVED,dask__dask-5940,https://github.com/dask/dask/pull/5940,"import timeit
import statistics

import dask.array as da

A = 500
B = 1000

def setup():
    print(""hi"")
    global layer
    a = da.ones((A, B, 2), chunks=1)
    b = da.zeros((A, B, 1), chunks=1)
    c = a + b
    g = c.__dask_graph__()
    layer = g.layers[c.name]

def workload():
    global layer
    layer._dict

runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 5.28135597598739
Before SD: 0.08384019092933347
After Mean: 1.7821986516006292
After SD: 0.007969411777967322
Improvement: -66.25%",,6,docker.io/sweperf/sweperf:dask__dask-5940,docker.io/sweperf/sweperf_annotate:dask__dask-5940,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-5940 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2020-02-24 7:26:45,72c7d906212f14df5d515be33c9cc5f0d86b3fec,2.11
,APPROVED,dask__dask-6186,https://github.com/dask/dask/pull/6186,"import timeit
import statistics

import dask.dataframe as dd
import pandas as pd
import numpy as np

size = 100_000_000
df = pd.DataFrame({'a': np.random.randint(10, size=size),'b': np.random.randint(10, size=size)})
ddf = dd.from_pandas(df, npartitions=2)

def workload():
    ddf.groupby('a').agg({'b':['mean','std']}).compute()

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.599402866093442
Before SD: 0.07899432682149385
After Mean: 1.3564545164001174
After SD: 0.028984283576465267
Improvement: -62.31%",,1,docker.io/sweperf/sweperf:dask__dask-6186,docker.io/sweperf/sweperf_annotate:dask__dask-6186,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-6186 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2020-05-08 16:55:56,9968a49bb4e9ae03d29110bbc5a41a4179636ab8,2.17
,APPROVED,dask__dask-6293,https://github.com/dask/dask/pull/6293,"import timeit
import statistics

import dask
import dask.array as da
import numpy as np

def setup():
    global stacked, sub_arrays
    sub_arrays = [
        da.from_delayed(
            dask.delayed(np.zeros)((100000,), dtype=""int64""), 
            shape=(100000,), 
            dtype=""int64"", 
            name=idx
        ) 
        for idx in range(10000)
    ]
    stacked = da.stack(sub_arrays)

def workload():
    global stacked, sub_arrays
    for i in range(len(sub_arrays)):
        stacked[i]

runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 13.064217879995704
Before SD: 0.12716199298804098
After Mean: 7.663897668593563
After SD: 0.16231639740067205
Improvement: -41.34%",,21,docker.io/sweperf/sweperf:dask__dask-6293,docker.io/sweperf/sweperf_annotate:dask__dask-6293,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-6293 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2020-06-05 20:14:04,8eeb0e0194ef0561b4202f42de06c0b7fc0784b9,2.18
,APPROVED,dask__dask-6491,https://github.com/dask/dask/pull/6491,"import timeit
import statistics

import dask.array as da

N = 50000

def workload():
    da.zeros((N, N)).sum().compute()

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.27634777829516677
Before SD: 0.01003649760150314
After Mean: 0.2450490264047403
After SD: 0.005606724652509162
Improvement: -11.33%",,37,docker.io/sweperf/sweperf:dask__dask-6491,docker.io/sweperf/sweperf_annotate:dask__dask-6491,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-6491 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2020-08-07 0:40:09,e5acf325ecc7af9147fe7644a1548380b54d5364,2.23
,APPROVED,dask__dask-6669,https://github.com/dask/dask/pull/6669,"import timeit
import statistics

import dask.array as da
import numpy as np

def setup():
    global x
    global idx
    idx = np.random.randint(0, 10000, size=1000)
    x = da.random.random((10000,), chunks=(10,))
    
def workload():
    global x
    global idx

    x.vindex[idx]

runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0599279085037997
Before SD: 0.00023056533357650955
After Mean: 0.0036629197468282656
After SD: 8.15775692760206e-05
Improvement: -93.89%",,2,docker.io/sweperf/sweperf:dask__dask-6669,docker.io/sweperf/sweperf_annotate:dask__dask-6669,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-6669 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2020-09-25 13:00:37,ee0d205ce8bec289cefd5989b7af0d5cda67fe8b,2.26
,APPROVED,dask__dask-7023,https://github.com/dask/dask/pull/7023,"import timeit
import statistics

import numpy as np
import dask.array as da

N_rows = 10**4
N_cols = 10**4
chunks = (1000, 1000)
new_chunks = ((20,) * 50, (10,) * 100)

# Global variable for the array so setup can define it and workload can reuse it
array = None

def setup():
    global array
    array = da.random.random((N_rows, N_cols), chunks=chunks)
    array._chunks = new_chunks
    _ = array.shape

def workload():
    _ = array.shape

runtimes = timeit.repeat(workload, number=1, repeat=10000, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.448018960421905e-06
Before SD: 4.316391295698584e-07
After Mean: 5.605885526165366e-07
After SD: 2.424188084213001e-07
Improvement: -77.10%",,52,docker.io/sweperf/sweperf:dask__dask-7023,docker.io/sweperf/sweperf_annotate:dask__dask-7023,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-7023 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2021-01-01 14:10:37,4a7a2438219c4ee493434042e50f4cdb67b6ec9f,2020.12
,APPROVED,dask__dask-7104,https://github.com/dask/dask/pull/7104,"import timeit
import statistics

import numpy as np
import dask.array as da

N_rows = 10**4
N_cols = 10**4
chunks = (1000, 1000)
new_chunks = ((20,) * 50, (10,) * 100)

# Global variable for the array so setup can define it and workload can reuse it
array = None

def setup():
    global array
    array = da.random.random((N_rows, N_cols), chunks=chunks)
    array._chunks = new_chunks
    _ = array.numblocks
    _ = array.npartitions
    _ = array.shape
    _ = array.ndim
    _ = array.size

def workload():
    _ = array.numblocks
    _ = array.npartitions
    _ = array.shape
    _ = array.ndim
    _ = array.size

runtimes = timeit.repeat(workload, number=1, repeat=10000, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.0427174817305057e-06
Before SD: 4.4244252286057846e-07
After Mean: 1.5731565130408854e-06
After SD: 3.370146439167994e-07
Improvement: -48.30%",,38,docker.io/sweperf/sweperf:dask__dask-7104,docker.io/sweperf/sweperf_annotate:dask__dask-7104,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-7104 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2021-01-23 11:55:56,0b33708f4627c3f9c7613c9554d1033db147d4b0,2021.01
,APPROVED,dask__dask-7172,https://github.com/dask/dask/pull/7172,"import timeit
import statistics

import dask.array as da
from dask.array.percentile import merge_percentiles
import numpy as np

nquantiles = 100
ndatasets = 100

def setup():
    scale = 100
    calculated_quantiles = nquantiles//2

    global finalq, qs, vals, Ns

    finalq = np.floor(np.random.rand(nquantiles) * scale)
    qs = list(np.floor(np.random.rand(ndatasets, calculated_quantiles) * scale))
    vals = list(np.random.rand(ndatasets, calculated_quantiles))
    Ns = np.ones(ndatasets) * 100
    
def workload():
    global finalq, qs, vals, Ns

    merge_percentiles(finalq, qs, vals, Ns=Ns)

runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.004085873172967694
Before SD: 6.44049667837242e-05
After Mean: 0.001920907359221019
After SD: 7.982501373817504e-05
Improvement: -52.99%",,1,docker.io/sweperf/sweperf:dask__dask-7172,docker.io/sweperf/sweperf_annotate:dask__dask-7172,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-7172 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2021-02-04 19:48:36,3d0e7bd93d6c6c67208765fd0a81f13088bb53a7,2021.02
,APPROVED,dask__dask-7403,https://github.com/dask/dask/pull/7403,"import timeit
import statistics

import dask.array as da
import numpy as np

def av_blocks(data, blocksize):
    sum_data = []
    for i in range(0, data.shape[0], blocksize):
        inc_data = da.sum(data[i:i+blocksize, ...], axis=0, dtype=data.dtype)
        sum_data.append(inc_data)
    av_data = da.stack(sum_data, axis=0) / np.float32(blocksize)
    
    return av_data

def workload():
    orig_chans = 4096
    t_sum_flags = da.ones((orig_chans,), dtype=np.float32, chunks=(orig_chans,))
    av_flags = av_blocks(t_sum_flags, 2)
    da.compute(av_flags)

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 12.262825020699529
Before SD: 0.05528127097721865
After Mean: 2.0909282422915565
After SD: 0.021081318204318394
Improvement: -82.95%",,5,docker.io/sweperf/sweperf:dask__dask-7403,docker.io/sweperf/sweperf_annotate:dask__dask-7403,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:dask__dask-7403 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",dask/dask,2021-03-16 13:37:55,a1187b13321d69565b9c21359d739c239bd04c65,2021.03
,APPROVED,matplotlib__matplotlib-13917,https://github.com/matplotlib/matplotlib/pull/13917,"import timeit
import statistics

from pylab import *

def setup():
    global cats
    plt.clf()
    cats = [str(x) for x in np.random.rand(4000)]
    
def workload():
    global cats
    plt.plot(cats)
    plt.gcf().canvas.draw()

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 13.109779178106692
Before SD: 0.07292067615687987
After Mean: 6.389580780407414
After SD: 0.013918244052245694
Improvement: -51.26%",,84,docker.io/sweperf/sweperf:matplotlib__matplotlib-13917,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-13917,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-13917 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2019-04-10 5:10:48,3f9389ef260a1c22db801c0744e9a2b941b0c9dc,3
,APPROVED,matplotlib__matplotlib-14504,https://github.com/matplotlib/matplotlib/pull/14504,"import timeit
import statistics

import matplotlib.pyplot as plt
import numpy as np

def setup():
    global fig
    plt.clf()
    fig, ax = plt.subplots()

    ax.plot(np.arange(2e7) + 1, np.arange(2e7))
    ax.set_xlim([1, 40])

def workload():
    for i in range(40):
        fig.tight_layout()
        plt.draw()
        
runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 10.63681790000992
Before SD: 0.01813817872432004
After Mean: 0.8207085315836593
After SD: 0.0030469387350462204
Improvement: -92.28%",,13,docker.io/sweperf/sweperf:matplotlib__matplotlib-14504,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-14504,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-14504 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2019-06-08 21:06:56,8960dbb2d467e4d70980e98797c6e28253d27caf,3.1
,APPROVED,matplotlib__matplotlib-15346,https://github.com/matplotlib/matplotlib/pull/15346,"import timeit
import statistics

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

import numpy as np

n = 50

def setup():
    global fig, ax, X, Y, Z, U, V, W
    fig = plt.figure()
    ax = fig.gca(projection='3d')
    x, y, z = [np.random.rand(n) for _ in range(3)]
    X, Y, Z = np.meshgrid(x, y, z)
    U, V, W = [np.random.rand(*X.shape) for _ in range(3)]

def workload():
    global fig, ax, X, Y, Z, U, V, W
    ax.quiver(X, Y, Z, U, V, W)

runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 2.5714919534372167
Before SD: 0.015637649916851792
After Mean: 0.251614837073721
After SD: 0.22048500236765922
Improvement: -90.22%",,1,docker.io/sweperf/sweperf:matplotlib__matplotlib-15346,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-15346,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-15346 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2019-09-29 17:11:19,ba7a162c01efbccce7432b5936bd5cc5b72b810c,3.1
,APPROVED,matplotlib__matplotlib-15834,https://github.com/matplotlib/matplotlib/pull/15834,"import timeit
import statistics
from matplotlib.colors import _to_rgba_no_colorcycle
import numpy as np

def setup():
    global t
    t = (0.2, 0.5, 0.8, 0.3)

def workload():
    global t
    _to_rgba_no_colorcycle(t)

runtimes = timeit.repeat(workload, number=100, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0005191053847811418
Before SD: 2.983347127548599e-05
After Mean: 0.0002917023744696053
After SD: 5.3453011144790224e-06
Improvement: -43.81%",,90,docker.io/sweperf/sweperf:matplotlib__matplotlib-15834,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-15834,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-15834 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2019-12-04 23:49:58,2555e38ec977cb2432bb10876254bbe8721e07f5,3.1
,APPROVED,matplotlib__matplotlib-17177,https://github.com/matplotlib/matplotlib/pull/17177,"import timeit
import statistics
import io
import numpy as np
import matplotlib

matplotlib.use(""PS"")

import matplotlib.pyplot as plt
IMG = np.random.randint(0, 255, (1024, 1024, 3), dtype=np.uint8)

def workload():
    fig, ax = plt.subplots(figsize=(6, 6), dpi=100)
    ax.axis(""off"")
    ax.imshow(IMG)
    buf = io.BytesIO()
    fig.savefig(buf, format=""ps"")      # triggers the hex-string wrapping
    plt.close(fig)

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.1501690558390692
Before SD: 0.0008887049925709971
After Mean: 0.059018340837210415
After SD: 0.0013657285412050238
Improvement: -60.70%",,1,docker.io/sweperf/sweperf:matplotlib__matplotlib-17177,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-17177,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-17177 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2020-04-17 19:04:47,91ad8671e8b8bd55a5de68bc17b18dcb67a5d6ac,3.2
,APPROVED,matplotlib__matplotlib-17994,https://github.com/matplotlib/matplotlib/pull/17994,"import timeit
import statistics

import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Polygon
import tempfile
import os

tempfile_path = tempfile.NamedTemporaryFile(delete=False).name

def tstack(a):
    return np.concatenate([x[..., np.newaxis] for x in a], axis=-1)

x_min, x_max = 360, 780
wl = np.arange(x_min, x_max, 1)
wl_len = len(wl)
colours = np.random.random([wl_len, 3])  # random colours held constant per run
padding = 0.1


def workload():
    """"""
    The code whose performance we want to measure.
    Re-creates the figure each iteration so the measurement includes
    everything from plotting through layout to file I/O.
    """"""
    values = np.sin(wl / 50) * 125 + 125

    fig = plt.figure(figsize=(10.24, 7.68))
    ax = fig.gca()

    # Construct clipping polygon
    polygon = Polygon(
        np.vstack([
            (x_min, 0),
            tstack([wl, values]),
            (x_max, 0),
        ]),
        facecolor='none',
        edgecolor='none'
    )
    ax.add_patch(polygon)

    # Draw bars clipped by the polygon
    ax.bar(
        x=wl - padding,
        height=max(values),
        width=1 + padding,
        color=colours,
        align='edge',
        clip_path=polygon
    )

    # Overlay line plot and axis limits
    ax.plot(wl, values)
    ax.set_xlim(x_min, x_max)
    ax.set_ylim(0, 250)

    fig.tight_layout()
    fig.savefig(tempfile_path)
    plt.close(fig)
    
os.remove(tempfile_path)  # Clean up the temporary file after saving

runtimes = timeit.repeat(workload, number=1, repeat=3)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 20.700872346312583
Before SD: 0.022970414386294907
After Mean: 4.863157168011337
After SD: 0.008343716436034971
Improvement: -76.51%",,56,docker.io/sweperf/sweperf:matplotlib__matplotlib-17994,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-17994,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-17994 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2020-07-21 12:41:12,57c8baaf85f0cfd44a27ef834dc971128b7f8ee4,3.3
,APPROVED,matplotlib__matplotlib-17995,https://github.com/matplotlib/matplotlib/pull/17995,"import timeit
import statistics

import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Polygon
import tempfile
import os

tempfile_path = tempfile.NamedTemporaryFile(delete=False).name

def tstack(a):
    return np.concatenate([x[..., np.newaxis] for x in a], axis=-1)

x_min, x_max = 360, 780
wl = np.arange(x_min, x_max, 1)
wl_len = len(wl)
colours = np.random.random([wl_len, 3])  # random colours held constant per run
padding = 0.1


def workload():
    """"""
    The code whose performance we want to measure.
    Re-creates the figure each iteration so the measurement includes
    everything from plotting through layout to file I/O.
    """"""
    values = np.sin(wl / 50) * 125 + 125

    fig = plt.figure(figsize=(10.24, 7.68))
    ax = fig.gca()

    # Construct clipping polygon
    polygon = Polygon(
        np.vstack([
            (x_min, 0),
            tstack([wl, values]),
            (x_max, 0),
        ]),
        facecolor='none',
        edgecolor='none'
    )
    ax.add_patch(polygon)

    # Draw bars clipped by the polygon
    ax.bar(
        x=wl - padding,
        height=max(values),
        width=1 + padding,
        color=colours,
        align='edge',
        clip_path=polygon
    )

    # Overlay line plot and axis limits
    ax.plot(wl, values)
    ax.set_xlim(x_min, x_max)
    ax.set_ylim(0, 250)

    fig.tight_layout()
    fig.savefig(tempfile_path)
    plt.close(fig)
    
os.remove(tempfile_path)  # Clean up the temporary file after saving

runtimes = timeit.repeat(workload, number=1, repeat=3)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 4.850268914344876
Before SD: 0.008279718485243327
After Mean: 0.3311978313140571
After SD: 0.00524409998125318
Improvement: -93.17%",,56,docker.io/sweperf/sweperf:matplotlib__matplotlib-17995,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-17995,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-17995 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2020-07-21 12:53:35,096d0ac1537f396528cdea0709e7d9d4125478df,3.3
,APPROVED,matplotlib__matplotlib-18018,https://github.com/matplotlib/matplotlib/pull/18018,"import timeit
import statistics

from pylab import *

tx = figtext(.5, .5, ""foo\nbar baz"")
gcf().canvas.draw()
gcf().patch.set_visible(False)
r = gcf()._cachedRenderer
    
def workload():
    global tx, r
    tx.draw(r)
        
runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00041142471134662627
Before SD: 2.8870854465644534e-05
After Mean: 0.0002848596824333072
After SD: 2.1721861623143267e-05
Improvement: -30.76%",,91,docker.io/sweperf/sweperf:matplotlib__matplotlib-18018,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-18018,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-18018 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2020-07-22 8:56:53,019a75231fd8d475c8b6f42a7d0cb1d99e9dcfa5,3.3
,APPROVED,matplotlib__matplotlib-18756,https://github.com/matplotlib/matplotlib/pull/18756,"import timeit
import statistics

import matplotlib.dates as mdates
import numpy as np
import datetime

def datetime_range(startDate, endDate, deltaDate):
    current = startDate
    while current < endDate:
        yield current
        current += deltaDate
    return

list_of_dates = [
    date for date in datetime_range(datetime.datetime(2020, 1, 1, 0, 1),
                                    datetime.datetime(2020, 12, 31, 23, 59),
                                    datetime.timedelta(minutes=1))
]

def workload():
    mdates.date2num(list_of_dates)

runtimes = timeit.repeat(workload, number=1, repeat=5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 6.297361067787278
Before SD: 0.008405692632438719
After Mean: 0.8469261301681399
After SD: 0.0024153902252698235
Improvement: -86.55%",,10,docker.io/sweperf/sweperf:matplotlib__matplotlib-18756,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-18756,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-18756 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2020-10-17 0:11:21,cf83ec4f46ae03668a1d89273b28147497ab65f2,3.3
,APPROVED,matplotlib__matplotlib-18997,https://github.com/matplotlib/matplotlib/pull/18997,"import timeit
import statistics

from matplotlib.cbook import _check_isinstance

def workload():
    _check_isinstance(int, x=1)
    _check_isinstance((float, int), x=1)

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 2.524455776438117e-06
Before SD: 9.880786100059784e-07
After Mean: 1.5856610843911767e-06
After SD: 6.993280196521016e-07
Improvement: -37.19%",,68,docker.io/sweperf/sweperf:matplotlib__matplotlib-18997,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-18997,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-18997 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2020-11-23 0:16:13,38fd428524ed9f33098a4a3cba508b88f78563d0,3.3
,APPROVED,matplotlib__matplotlib-19564,https://github.com/matplotlib/matplotlib/pull/19564,"import timeit
import statistics

from pylab import *
mpl.use(""pdf"")
rcParams[""text.usetex""] = True

def setup():
    plot()

def workload():
    for _ in range(100):
        savefig(""/tmp/test.pdf"", backend=""pdf"")

runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 4.433067437603604
Before SD: 0.2384185751645614
After Mean: 3.717661640678998
After SD: 0.24761483767419337
Improvement: -16.14%",,37,docker.io/sweperf/sweperf:matplotlib__matplotlib-19564,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-19564,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-19564 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2021-02-23 18:14:24,183018c13beefd2604f443678cef42fab4c0f13a,3.3
,APPROVED,matplotlib__matplotlib-19760,https://github.com/matplotlib/matplotlib/pull/19760,"import timeit
import statistics

from pylab import *
mpl.use(""agg"")

from matplotlib.figure import Figure

def workload():
    Figure().subplots(20, 20)

runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.617303566564806
Before SD: 0.021788782809291418
After Mean: 2.7787992560025305
After SD: 0.013082689009474664
Improvement: -23.18%",,93,docker.io/sweperf/sweperf:matplotlib__matplotlib-19760,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-19760,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-19760 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2021-03-23 12:49:23,bfa31a482d6baa9a6da417bc1c20d4cd93abcece,3.3
,APPROVED,matplotlib__matplotlib-20197,https://github.com/matplotlib/matplotlib/pull/20197,"import timeit
import statistics

import matplotlib
matplotlib.use('Agg')

from matplotlib.figure import Figure

def workload():
    Figure().subplots(10, 10)

runtimes = timeit.repeat(workload, number=1, repeat=5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.6584165384061634
Before SD: 0.007924893302375944
After Mean: 0.6383679883787409
After SD: 0.009159965292402983
Improvement: -3.04%",,93,docker.io/sweperf/sweperf:matplotlib__matplotlib-20197,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-20197,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-20197 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2021-05-10 8:04:39,3efd44784a8d0c3a76b0ade1635caf8763067f43,3.4
,APPROVED,matplotlib__matplotlib-21564,https://github.com/matplotlib/matplotlib/pull/21564,"import timeit
import statistics

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from mpl_toolkits.mplot3d import Axes3D


a = 20
d = 20
tm0 = 10
t_m = tm0 * np.pi/180

def phi(t):
    return np.pi/4 + (6 + 0.1*t) * t

def r(t):
    return d/2 * (1 - phi(t)/phi(t_m))

def Fp(x,y,t):
    return -1/np.sqrt((x + r(t)*np.cos(phi(t)))**2 + (y + r(t)*np.sin(phi(t)))**2)                                                            \
           -1/np.sqrt((x - r(t)*np.cos(phi(t)))**2 + (y - r(t)*np.sin(phi(t)))**2)  
   
X = np.arange(-1*a, a)
Y = np.arange(-1*a, a)
x, y = np.meshgrid(X,Y)


image_list = []
for t in range(tm0):
    image_list.append(Fp(x,y,t*np.pi/180))

def setup():
    ## Create animation and video from 3D images
    fig = plt.figure()
    ax = Axes3D(fig)
    ims = []
    for i in range(len(image_list)):
        im = ax.plot_surface(x, y, image_list[i], antialiased=False, animated=True)
        ims.append([im])
    
    global ani
    ani = animation.ArtistAnimation(fig, ims, blit=True, repeat_delay=2000)

def workload():
    global ani
    ani.to_html5_video()

runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 5.817801982408855
Before SD: 0.02920437842037805
After Mean: 1.0646133859991096
After SD: 0.016456180480242395
Improvement: -81.70%",,95,docker.io/sweperf/sweperf:matplotlib__matplotlib-21564,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-21564,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-21564 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2021-11-08 9:02:13,b525983fb5ad295ee8a789df46989574b452369a,3.4
,APPROVED,matplotlib__matplotlib-22108,https://github.com/matplotlib/matplotlib/pull/22108,"import timeit
import statistics
from matplotlib.transforms import Affine2D
import numpy as np

def setup():
    global mtx, theta, aff
    mtx = np.array([[.1, .2, .3], [.4, .5, .6], [0, 0, 1]])
    theta = np.pi / 4
    aff = Affine2D()
    aff.set_matrix(mtx)

def workload():
    global mtx, theta, aff
    aff.rotate(theta)
    
runtimes = timeit.repeat(workload, number=100, repeat=2000, setup=setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.00019566375855356455
Before SD: 2.9275027993763672e-06
After Mean: 9.297033865004778e-05
After SD: 2.6079892448663637e-06
Improvement: -52.48%",,69,docker.io/sweperf/sweperf:matplotlib__matplotlib-22108,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-22108,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-22108 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2022-01-05 10:40:45,68d6b79654626f1471caf9dd60d9f728823f0d90,3.5
,APPROVED,matplotlib__matplotlib-22875,https://github.com/matplotlib/matplotlib/pull/22875,"import timeit
import statistics

from pylab import *
mpl.use('agg')

from matplotlib.tests.test_mathtext import math_tests

def setup():
    global fig
    clf()
    fig = figure(figsize=(3, 10)); 
    fig.text(0, 0, ""\n"".join(filter(None, math_tests)), size=6); 

def workload():
    global fig
    for _ in range(10):
        fig.canvas.draw()

runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 4.047073603991885
Before SD: 0.07628795257241888
After Mean: 3.8206878218101337
After SD: 0.07041238939111671
Improvement: -5.59%",,24,docker.io/sweperf/sweperf:matplotlib__matplotlib-22875,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-22875,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-22875 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2022-04-21 20:18:29,709fba81d42d39a7cdde22e7d3c790ec4090a3f3,3.5
,APPROVED,matplotlib__matplotlib-23287,https://github.com/matplotlib/matplotlib/pull/23287,"import timeit
import statistics

from matplotlib.backends.backend_pdf import Name

def workload():
    Name(""foo\xff\x01"")

runtimes = timeit.repeat(workload, number=1, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.2164736886043101e-06
Before SD: 2.1002978241521612e-07
After Mean: 5.794971339055337e-07
After SD: 1.4115438407335807e-07
Improvement: -52.36%",,39,docker.io/sweperf/sweperf:matplotlib__matplotlib-23287,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-23287,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-23287 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2022-06-16 8:53:11,00cdf28e7adf2216d41fc28b6eebcee3b8217d5f,3.5
,APPROVED,matplotlib__matplotlib-23759,https://github.com/matplotlib/matplotlib/pull/23759,"import timeit
import statistics

import subprocess

def workload():
    # Running import in subprocess to properly time imports.
    subprocess.run(
        [""python"", ""-c"", ""import matplotlib.pyplot""],
        check=True
    )
    
runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.7099659791099839
Before SD: 0.6233347914520765
After Mean: 0.36053082630387506
After SD: 0.001922180401508619
Improvement: -49.22%",,97,docker.io/sweperf/sweperf:matplotlib__matplotlib-23759,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-23759,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-23759 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2022-08-27 17:27:06,5823ec9ef15dd169645c026684cb746de44223e9,3.5
,APPROVED,matplotlib__matplotlib-24847,https://github.com/matplotlib/matplotlib/pull/24847,"import timeit
import statistics

from matplotlib.transforms import Affine2D

def workload():
    Affine2D()
    
runtimes = timeit.repeat(workload, number=1, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.1844463010784238e-06
Before SD: 1.8236906842779255e-07
After Mean: 8.721915027708746e-07
After SD: 1.5834883188296936e-07
Improvement: -26.36%",,72,docker.io/sweperf/sweperf:matplotlib__matplotlib-24847,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-24847,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-24847 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2022-12-30 6:12:08,bcfd5e60ee2b010ccfb334c19510a5ba553fbad9,3.6
,APPROVED,matplotlib__matplotlib-26164,https://github.com/matplotlib/matplotlib/pull/26164,"import timeit
import statistics

from matplotlib.figure import Figure
import numpy as np
import pandas as pd
import timeit

rows = 20
cols = 20
total = rows * cols

def workload():
    fig_matplotlib = Figure()
    axs_matplotlib = fig_matplotlib.subplots(nrows=rows, ncols=cols)

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 2.6960159890004434
Before SD: 0.014700753853970462
After Mean: 1.994560694892425
After SD: 0.021452982621321632
Improvement: -26.02%",,97,docker.io/sweperf/sweperf:matplotlib__matplotlib-26164,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-26164,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-26164 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2023-06-21 17:06:10,060992a18e1f9d6a370f73c02583f314631bc96f,3.7
,APPROVED,matplotlib__matplotlib-26198,https://github.com/matplotlib/matplotlib/pull/26198,"import timeit
import statistics

from matplotlib import mathtext

math_tests = [
    r'$a+b+\dot s+\dot{s}+\ldots$',
    r'$x\hspace{-0.2}\doteq\hspace{-0.2}y$',
    r'\$100.00 $\alpha \_$',
    r'$\frac{\$100.00}{y}$',
    r'$x   y$',
    r'$x+y\ x=y\ x<y\ x:y\ x,y\ x@y$',
    r'$100\%y\ x*y\ x/y x\$y$',
    r'$x\leftarrow y\ x\forall y\ x-y$',
    r'$x \sf x \bf x {\cal X} \rm x$',
    r'$x\ x\,x\;x\quad x\qquad x\!x\hspace{ 0.5 }y$',
    r'$\{ \rm braces \}$',
    r'$\left[\left\lfloor\frac{5}{\frac{\left(3\right)}{4}} y\right)\right]$',
    r'$\left(x\right)$',
    r'$\sin(x)$',
    r'$x_2$',
    r'$x^2$',
    r'$x^2_y$',
    r'$x_y^2$',
    (r'$\sum _{\genfrac{}{}{0}{}{0\leq i\leq m}{0<j<n}}f\left(i,j\right)'
     r'\mathcal{R}\prod_{i=\alpha_{i+1}}^\infty a_i \sin(2 \pi f x_i)'
     r""\sqrt[2]{\prod^\frac{x}{2\pi^2}_\infty}$""),
    r'$x = \frac{x+\frac{5}{2}}{\frac{y+3}{8}}$',
    r'$dz/dt = \gamma x^2 + {\rm sin}(2\pi y+\phi)$',
    r'Foo: $\alpha_{i+1}^j = {\rm sin}(2\pi f_j t_i) e^{-5 t_i/\tau}$',
    r'Variable $i$ is good',
    r'$\Delta_i^j$',
    r'$\Delta^j_{i+1}$',
    r'$\ddot{o}\acute{e}\grave{e}\hat{O}\breve{\imath}\tilde{n}\vec{q}$',
    r""$\arccos((x^i))$"",
    r""$\gamma = \frac{x=\frac{6}{8}}{y} \delta$"",
    r'$\limsup_{x\to\infty}$',
    r""$f'\quad f'''(x)\quad ''/\mathrm{yr}$"",
    r'$\frac{x_2888}{y}$',
    r""$\sqrt[3]{\frac{X_2}{Y}}=5$"",
    r""$\sqrt[3]{x}=5$"",
    r'$\frac{X}{\frac{X}{Y}}$',
    r""$W^{3\beta}_{\delta_1 \rho_1 \sigma_2} = U^{3\beta}_{\delta_1 \rho_1} + \frac{1}{8 \pi 2} \int^{\alpha_2}_{\alpha_2} d \alpha^\prime_2 \left[\frac{ U^{2\beta}_{\delta_1 \rho_1} - \alpha^\prime_2U^{1\beta}_{\rho_1 \sigma_2} }{U^{0\beta}_{\rho_1 \sigma_2}}\right]$"",
    r'$\mathcal{H} = \int d \tau \left(\epsilon E^2 + \mu H^2\right)$',
    r'$\widehat{abc}\widetilde{def}$',
    '$\\Gamma \\Delta \\Theta \\Lambda \\Xi \\Pi \\Sigma \\Upsilon \\Phi \\Psi \\Omega$',
    '$\\alpha \\beta \\gamma \\delta \\epsilon \\zeta \\eta \\theta \\iota \\lambda \\mu \\nu \\xi \\pi \\kappa \\rho \\sigma \\tau \\upsilon \\phi \\chi \\psi$',
    r'${x}^{2}{y}^{2}$',
    r'${}_{2}F_{3}$',
    r'$\frac{x+{y}^{2}}{k+1}$',
    r'$x+{y}^{\frac{2}{k+1}}$',
    r'$\frac{a}{b/2}$',
    r'${a}_{0}+\frac{1}{{a}_{1}+\frac{1}{{a}_{2}+\frac{1}{{a}_{3}+\frac{1}{{a}_{4}}}}}$',
    r'${a}_{0}+\frac{1}{{a}_{1}+\frac{1}{{a}_{2}+\frac{1}{{a}_{3}+\frac{1}{{a}_{4}}}}}$',
    r'$\binom{n}{k/2}$',
    r'$\binom{p}{2}{x}^{2}{y}^{p-2}-\frac{1}{1-x}\frac{1}{1-{x}^{2}}$',
    r'${x}^{2y}$',
    r'$\sum _{i=1}^{p}\sum _{j=1}^{q}\sum _{k=1}^{r}{a}_{ij}{b}_{jk}{c}_{ki}$',
    r'$\sqrt{1+\sqrt{1+\sqrt{1+\sqrt{1+\sqrt{1+\sqrt{1+\sqrt{1+x}}}}}}}$',
    r'$\left(\frac{{\partial }^{2}}{\partial {x}^{2}}+\frac{{\partial }^{2}}{\partial {y}^{2}}\right){|\varphi \left(x+iy\right)|}^{2}=0$',
    r'${2}^{{2}^{{2}^{x}}}$',
    r'${\int }_{1}^{x}\frac{\mathrm{dt}}{t}$',
    r'$\int {\int }_{D}\mathrm{dx} \mathrm{dy}$',
    r'${y}_{{x}^{2}}$',
    r'${y}_{{x}_{2}}$',
    r'${x}_{92}^{31415}+\pi $',
    r'${x}_{{y}_{b}^{a}}^{{z}_{c}^{d}}$',
    r'${y}_{3}^{\prime \prime \prime }$',
    r""$\left( \xi \left( 1 - \xi \right) \right)$"",  # Bug 2969451
    r""$\left(2 \, a=b\right)$"",  # Sage bug #8125
    r""$? ! &$"",  # github issue #466
    r""$\left\Vert \frac{a}{b} \right\Vert \left\vert \frac{a}{b} \right\vert \left\| \frac{a}{b}\right\| \left| \frac{a}{b} \right| \Vert a \Vert \vert b \vert \| a \| | b |$"",
    r'$\mathring{A}  \AA$',
    r'$M \, M \thinspace M \/ M \> M \: M \; M \ M \enspace M \quad M \qquad M \! M$',
    r'$\Cap$ $\Cup$ $\leftharpoonup$ $\barwedge$ $\rightharpoonup$',
    r'$\hspace{-0.2}\dotplus\hspace{-0.2}$ $\hspace{-0.2}\doteq\hspace{-0.2}$ $\hspace{-0.2}\doteqdot\hspace{-0.2}$ $\ddots$',
    r'$xyz^kx_kx^py^{p-2} d_i^jb_jc_kd x^j_i E^0 E^0_u$',  # github issue #4873
    r'${xyz}^k{x}_{k}{x}^{p}{y}^{p-2} {d}_{i}^{j}{b}_{j}{c}_{k}{d} {x}^{j}_{i}{E}^{0}{E}^0_u$',
    r'${\int}_x^x x\oint_x^x x\int_{X}^{X}x\int_x x \int^x x \int_{x} x\int^{x}{\int}_{x} x{\int}^{x}_{x}x$',
    r'testing$^{123}$',
    r'$6-2$; $-2$; $ -2$; ${-2}$; ${  -2}$; $20^{+3}_{-2}$',
    r'$\overline{\omega}^x \frac{1}{2}_0^x$',  # github issue #5444
    r'$,$ $.$ $1{,}234{, }567{ , }890$ and $1,234,567,890$',  # github issue 5799
    r'$\left(X\right)_{a}^{b}$',  # github issue 7615
    r'$\dfrac{\$100.00}{y}$',  # github issue #1888
]

parser = mathtext.MathTextParser('agg')

def workload():
    [parser.parse(a) for a in math_tests]

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.29311394126561935
Before SD: 0.01869009078344245
After Mean: 0.2517442906211363
After SD: 0.009492876060145728
Improvement: -14.11%",,26,docker.io/sweperf/sweperf:matplotlib__matplotlib-26198,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-26198,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-26198 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2023-06-27 3:42:04,aee2ea3c3537fe5551c8737a1a580152c89ca0e6,3.7
,APPROVED,matplotlib__matplotlib-26335,https://github.com/matplotlib/matplotlib/pull/26335,"import timeit
import statistics

import matplotlib.pyplot as plt
import numpy as np

n=10
im=np.random.rand(100, 100)

def workload():
    for ii in range(n):
        plt.figure(1)
        plt.imshow(im)

runtimes = timeit.repeat(workload, number=5, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.020323539598030037
Before SD: 0.0013093666490112343
After Mean: 0.018292357239988632
After SD: 0.0015291112372779832
Improvement: -9.99%",,46,docker.io/sweperf/sweperf:matplotlib__matplotlib-26335,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-26335,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-26335 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2023-07-17 13:33:25,c0d9c983398cb07ab7a2055563f95b364abfa87c,3.7
,APPROVED,matplotlib__matplotlib-26899,https://github.com/matplotlib/matplotlib/pull/26899,"import timeit
import statistics

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from io import BytesIO

from matplotlib.figure import Figure
import numpy as np

def setup():
    global stream, fig_many
    # Random Number Generator.
    rng = np.random.default_rng()
    
    # Constants.
    figsize = (10, 6)
    ncols = 3
    nrows = 10
    size = 100
    size_total = ncols * nrows * size
    
    # Figure with many subplots.
    fig_many = Figure(figsize=figsize)
    axs_many = fig_many.subplots(ncols=ncols, nrows=nrows)
    
    # Figure with many subplots and sharex='col'.
    fig_many_sharex = Figure(figsize=figsize)
    axs_many_sharex = fig_many_sharex.subplots(ncols=ncols, nrows=nrows, sharex='col')
    
    # Figure with a single axes.
    fig_single = Figure(figsize=figsize)
    ax_single = fig_single.subplots()
    
    # Helper-function: Generate random line-plots in the many subplots.
    def generate_fig_many(axs):
        for row in range(nrows):
            for col in range(ncols):
                ax = axs[row, col]
                x = rng.normal(loc=row+1, scale=col+1, size=size)
                y = rng.normal(loc=col+1, scale=row+1, size=size)
                x = np.sort(x)
                ax.plot(x, y);
                ax.set_yticks([])
    
    # Generate fig_many 
    generate_fig_many(axs=axs_many)
    fig_many.tight_layout()
    
    # Generate fig_many_sharex
    generate_fig_many(axs=axs_many_sharex)
    fig_many_sharex.tight_layout()
    
    # Generate fig_single
    x = rng.normal(size=size_total)
    y = rng.normal(size=size_total)
    x = np.sort(x)
    ax_single.plot(x, y);
    fig_single.tight_layout()


def workload():
    global stream, fig_many
    stream = BytesIO()
    fig_many.savefig(stream, format='svg', bbox_inches='tight')
    s = stream.getvalue()

runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.6573071256047115
Before SD: 0.018639898279045244
After Mean: 0.48301592964679
After SD: 0.021425659162797973
Improvement: -26.52%",,99,docker.io/sweperf/sweperf:matplotlib__matplotlib-26899,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-26899,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-26899 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2023-09-23 15:38:45,7d2acfda30077403682d8beef5a3c340ac98a43b,3.8
,APPROVED,matplotlib__matplotlib-29399,https://github.com/matplotlib/matplotlib/pull/29399,"import timeit
import statistics

import matplotlib.pyplot as plt
import numpy as np

x = y = np.linspace(-1, 1, 8000)
X, Y = np.meshgrid(x, y)
Z = X ** 2 + Y ** 2

def setup():
    global fig, ax
    plt.clf()
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')

def workload():
    global fig, ax
    ax.plot_wireframe(X, Y, Z, axlim_clip=False)
    ax.set_xlim(0, 1)
    fig.canvas.draw()

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 3.5698751507035924
Before SD: 0.016124886041287194
After Mean: 2.5027704568987246
After SD: 0.014801222650604823
Improvement: -29.89%",,104,docker.io/sweperf/sweperf:matplotlib__matplotlib-29399,docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-29399,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:matplotlib__matplotlib-29399 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",matplotlib/matplotlib,2025-01-04 1:14:44,8d3c4db01c59592fa612b093beb9e3e5ad959191,3.1
,APPROVED,numpy__numpy-11518,https://github.com/numpy/numpy/pull/11518,"import timeit
import statistics

import numpy as np

a = np.zeros((10, 20, 30, 40, 50))

def workload():
    np.moveaxis(a, [0, 1, 2, 3, 4], [4, 3, 2, 1, 0])

runtimes = timeit.repeat(workload, number=1, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 6.217983014736092e-06
Before SD: 7.712849721872622e-07
After Mean: 4.918091643863591e-06
After SD: 6.83766421016573e-07
Improvement: -20.91%",,21,docker.io/sweperf/sweperf:numpy__numpy-11518,docker.io/sweperf/sweperf_annotate:numpy__numpy-11518,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-11518 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2018-07-06 16:43:51,739443679b50b43c34808b8fb767bac643fcd91d,1.15
,APPROVED,numpy__numpy-11720,https://github.com/numpy/numpy/pull/11720,"import timeit
import statistics

import numpy as np

b = np.random.random((5, 2))
t = np.random.random((5, 5, 2))
p = np.random.random((2, 5))

def workload():
    out = np.einsum('ij,ixy,ji->xy', b, t, p)

runtimes = timeit.repeat(workload, number=100, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.007506608858133841
Before SD: 1.7004217204785464e-05
After Mean: 0.00022913117294898257
After SD: 2.9526440948326743e-05
Improvement: -96.95%",,8,docker.io/sweperf/sweperf:numpy__numpy-11720,docker.io/sweperf/sweperf_annotate:numpy__numpy-11720,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-11720 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2018-08-12 16:07:07,ada168000ee3a6727af4eb02cf2443edbf58e962,1.15
,APPROVED,numpy__numpy-11941,https://github.com/numpy/numpy/pull/11941,"

import timeit
import statistics

import numpy as np

x = np.random.rand(100, 100, 100)

def workload():
    out = np.tensordot(x, x, axes=((1, 2, 0), (1, 2, 0))) 

runtimes = timeit.repeat(workload, number=1, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0048169017157051715
Before SD: 0.00021629524005894852
After Mean: 0.004300310492893914
After SD: 0.0002835254906206401
Improvement: -10.72%",,8,docker.io/sweperf/sweperf:numpy__numpy-11941,docker.io/sweperf/sweperf_annotate:numpy__numpy-11941,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-11941 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2018-09-13 0:57:40,fe6beb288befa5506b5c41ed498054e24b5241b5,1.15
,APPROVED,numpy__numpy-11991,https://github.com/numpy/numpy/pull/11991,"

import timeit
import statistics

import itertools
import numpy as np

grid_params = [
    [(16, 16), (32, 32), (64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)],
    ['uint8', 'uint16', 'uint32', 'uint64'],
    [(2, 2), (4, 4)]
]

block_list = []

def setup():
    block_list.clear()
    
    combinations = itertools.product(*grid_params)
    for shape, dtype, n_chunks in combinations:
        block_list.append([
            [
                np.full(
                    shape=[s // n_chunk for s, n_chunk in zip(shape, n_chunks)],
                    fill_value=1, 
                    dtype=dtype
                ) for _ in range(n_chunks[1])
            ]
            for _ in range(n_chunks[0])
        ])

def workload():
    for block in block_list:
        np.block(block)

runtimes = timeit.repeat(workload, number=5, repeat=1000, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.08749404940981186
Before SD: 0.004195937558588464
After Mean: 0.08035653817048297
After SD: 0.0013986073228343897
Improvement: -8.16%",,3,docker.io/sweperf/sweperf:numpy__numpy-11991,docker.io/sweperf/sweperf_annotate:numpy__numpy-11991,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-11991 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2018-09-19 14:51:43,de4893119139aad52b181324d1c9ce4862b1abc1,1.15
,APPROVED,numpy__numpy-12321,https://github.com/numpy/numpy/pull/12321,"

import timeit
import statistics

import numpy as np

def setup():
    global l
    l = [np.arange(10000), np.arange(10000)]

def workload():
    np.hstack(l)

runtimes = timeit.repeat(workload, number=5, repeat=100000, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 6.349776788789313e-05
Before SD: 2.8636786715280243e-06
After Mean: 5.288366480526747e-05
After SD: 2.2511830195971854e-06
Improvement: -16.72%",,140,docker.io/sweperf/sweperf:numpy__numpy-12321,docker.io/sweperf/sweperf_annotate:numpy__numpy-12321,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-12321 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2018-11-03 21:43:43,9cc9f01da14d0eb7904dfe4351d393ff57795e15,1.15
,APPROVED,numpy__numpy-12575,https://github.com/numpy/numpy/pull/12575,"

import timeit
import statistics

import numpy as np

N = 4000

def setup():
    global arrays, names
    arrays = [
        np.arange(5)
        for i in range(N)
    ]

    names = [
        'field_{}'.format(i)
        for i in range(N)
    ]
 
def workload():
    global arrays, names
    arr = np.core.records.fromarrays(arrays, names=names)

runtimes = timeit.repeat(workload, number=30, repeat=100, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.664001454791869
Before SD: 0.013764672245008722
After Mean: 0.4723857473302633
After SD: 0.0033658343091719236
Improvement: -82.27%",,141,docker.io/sweperf/sweperf:numpy__numpy-12575,docker.io/sweperf/sweperf_annotate:numpy__numpy-12575,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-12575 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2018-12-17 10:42:11,38236fb225418ad5979511e3caf7e992df72b1a7,1.15
,APPROVED,numpy__numpy-12596,https://github.com/numpy/numpy/pull/12596,"

import timeit
import statistics

import numpy as np

l50 = np.arange(1000)
fields_number = 10000
arrays = [l50 for _ in range(fields_number)]
formats = [l50.dtype.str for _ in range(fields_number)]
formats_str = ','.join(formats)
dtype_ = np.dtype(
    [
        ('field_{}'.format(i), l50.dtype.str)
        for i in range(fields_number)
    ]
)
buffer = l50.tostring() * fields_number

def workload():
    np.core.records.fromarrays(arrays, formats=formats)
    np.core.records.fromarrays(arrays, dtype=dtype_)
    np.core.records.fromarrays(arrays)
    np.core.records.fromarrays(arrays, formats=formats)
    np.core.records.fromarrays(arrays, formats=formats_str)
    np.core.records.fromstring(buffer, dtype=dtype_)
    np.core.records.fromstring(buffer, formats=formats)
    np.core.records.fromstring(buffer, formats=formats_str)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.48516641630994856
Before SD: 0.009486316615274853
After Mean: 0.4149662828075816
After SD: 0.011326822633838569
Improvement: -14.47%",,4,docker.io/sweperf/sweperf:numpy__numpy-12596,docker.io/sweperf/sweperf_annotate:numpy__numpy-12596,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-12596 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2018-12-19 19:33:52,6b8441665fb877ab65ec067de7be776ff4f5ac54,1.15
,APPROVED,numpy__numpy-13250,https://github.com/numpy/numpy/pull/13250,"

import timeit
import statistics

import numpy as np

def pad_with(vector, pad_width, iaxis, kwargs):
    pad_value = kwargs.get('padder', 10)
    vector[:pad_width[0]] = pad_value
    vector[-pad_width[1]:] = pad_value

N = 10**4
X = np.arange(N * N).reshape((N, N))

def workload():
    Y = np.pad(X, 1000, pad_with, padder=100)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.48118773045833224
Before SD: 0.002387945863296743
After Mean: 0.45599379107065036
After SD: 0.00444625643116332
Improvement: -5.24%",,143,docker.io/sweperf/sweperf:numpy__numpy-13250,docker.io/sweperf/sweperf_annotate:numpy__numpy-13250,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-13250 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2019-04-02 16:18:52,6eb63c386f83143aa8d256f44ce850e4e2ee0785,1.16
,APPROVED,numpy__numpy-13634,https://github.com/numpy/numpy/pull/13634,"import timeit
import statistics

import numpy as np

x = np.array([1])
xs = [x, x, x]

def workload():
    for func in [np.hstack, np.vstack, np.block]:
        func(xs)

runtimes = timeit.repeat(workload, number=1, repeat=10000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 2.072001898777671e-05
Before SD: 9.807150387758285e-07
After Mean: 1.849740805046167e-05
After SD: 1.1386980467585459e-06
Improvement: -10.73%",,149,docker.io/sweperf/sweperf:numpy__numpy-13634,docker.io/sweperf/sweperf_annotate:numpy__numpy-13634,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-13634 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2019-05-26 23:59:54,4b4eaa666b18016162c144b7757ba40d8237fdb8,1.16
,APPROVED,numpy__numpy-13697,https://github.com/numpy/numpy/pull/13697,"import timeit
import statistics

import numpy as np

x = np.array([1])
xs = [x, x, x]

def workload():
    for func in [np.hstack, np.vstack]:
        func(xs)

runtimes = timeit.repeat(workload, number=1, repeat=10000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.0405030101537705e-05
Before SD: 6.479803478727442e-07
After Mean: 8.145984573638999e-06
After SD: 5.320874577932667e-07
Improvement: -21.71%",,149,docker.io/sweperf/sweperf:numpy__numpy-13697,docker.io/sweperf/sweperf_annotate:numpy__numpy-13697,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-13697 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2019-06-02 0:23:22,4b4eaa666b18016162c144b7757ba40d8237fdb8,1.16
,APPROVED,numpy__numpy-17896,https://github.com/numpy/numpy/pull/17896,"import timeit
import statistics

import numpy as np

N = 100
X = np.arange(N * N).reshape((N, N))

def workload():
    # Default where is True.
    Y = np.mean(X)

runtimes = timeit.repeat(workload, number=1, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.3601117389043794e-05
Before SD: 1.938090791731625e-06
After Mean: 1.2155767733929679e-05
After SD: 2.3174318809968604e-06
Improvement: -10.63%",,84,docker.io/sweperf/sweperf:numpy__numpy-17896,docker.io/sweperf/sweperf_annotate:numpy__numpy-17896,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-17896 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2020-12-02 21:07:54,33dc7bea24f1ab6c47047b49521e732caeb485d5,1.19
,APPROVED,numpy__numpy-18203,https://github.com/numpy/numpy/pull/18203,"import timeit
import statistics

import numpy as np

def setup():
    global x
    x = np.random.rand(1000)

def workload():
    global x
    np.quantile(x, .5)

runtimes = timeit.repeat(workload, number=5, repeat=10**5, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00036674147679648014
Before SD: 1.0790485148701753e-05
After Mean: 0.00032718314899512916
After SD: 9.922290715999795e-06
Improvement: -10.79%",,4,docker.io/sweperf/sweperf:numpy__numpy-18203,docker.io/sweperf/sweperf_annotate:numpy__numpy-18203,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-18203 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2021-01-21 15:48:07,fe7b1dcfc16fd9a8a1e6ea24ea103abf870282ed,1.2
,APPROVED,numpy__numpy-18324,https://github.com/numpy/numpy/pull/18324,"import timeit
import statistics

import numpy as np

def setup():
    global x
    x = np.random.randn(1001)

def workload():
    global x
    np.median(x)

runtimes = timeit.repeat(workload, number=5, repeat=10**6, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00011486192835558904
Before SD: 6.26315897998119e-06
After Mean: 0.00010094766704001813
After SD: 5.418090672694691e-06
Improvement: -12.11%",,4,docker.io/sweperf/sweperf:numpy__numpy-18324,docker.io/sweperf/sweperf_annotate:numpy__numpy-18324,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-18324 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2021-02-04 17:36:42,61723384df3678b12a19439d1218f50554e1498d,1.2
,APPROVED,numpy__numpy-19599,https://github.com/numpy/numpy/pull/19599,"import timeit
import statistics

import numpy as np
from io import StringIO


num_lines_comments = int(1e5)
data = ['1,2,3 # comment'] * num_lines_comments
data_comments = StringIO('\n'.join(data))

num_lines_dtypes = int(1e5)
data = ['5, 7, 888'] * num_lines_dtypes
csv_data_dtypes = StringIO('\n'.join(data))

data = [""M, 21, 72, X, 155""] * 50000
csv_data_structured = StringIO('\n'.join(data))

np.random.seed(123)
test_array = np.random.rand(100000, 3)
skiprows_fname = 'test_array.csv'
np.savetxt(fname=skiprows_fname, X=test_array, delimiter=',')

size_uint64 = 10000
arr = np.arange(size_uint64).astype('uint64') + 2**63
uint64_data1 = StringIO('\n'.join(arr.astype(str).tolist()))
arr = arr.astype(object)
arr[500] = -1
uint64_data2 = StringIO('\n'.join(arr.astype(str).tolist()))

data = ['0, 1, 2, 3, 4, 5, 6, 7, 8, 9'] * 5000
csv_data_usecols = StringIO('\n'.join(data))

dates = np.arange('2020-01-01', '2020-01-21', dtype='datetime64[D]')
np.random.seed(123)
values = np.random.rand(20)
date_line = ''.join(f""{str(date)},{value}\n"" for date, value in zip(dates, values))
data = date_line * (20000 // 20)
csv_data_datetime = StringIO(data)


def workload():
    np.loadtxt(data_comments, delimiter=',')
    data_comments.seek(0)

    np.loadtxt(csv_data_dtypes, delimiter=',', dtype='object')
    csv_data_dtypes.seek(0)

    np.loadtxt(csv_data_structured, delimiter=',', dtype=[
        ('category_1', 'S1'),
        ('category_2', 'i4'),
        ('category_3', 'f8'),
        ('category_4', 'S1'),
        ('category_5', 'f8')])
    csv_data_structured.seek(0)

    np.loadtxt(skiprows_fname, delimiter=',', skiprows=10000)

    np.loadtxt(uint64_data1)
    uint64_data1.seek(0)

    np.loadtxt(uint64_data2)
    uint64_data2.seek(0)

    np.loadtxt(csv_data_usecols, delimiter=',', usecols=[1, 3, 5, 7])
    csv_data_usecols.seek(0)

    np.loadtxt(csv_data_datetime,
               delimiter=',',
               dtype=[('dates', 'M8[us]'), ('values', 'float64')])
    csv_data_datetime.seek(0)


runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.3517397653590888
Before SD: 0.006540530002550045
After Mean: 1.0909314116812312
After SD: 0.006229866689541552
Improvement: -19.29%",,179,docker.io/sweperf/sweperf:numpy__numpy-19599,docker.io/sweperf/sweperf_annotate:numpy__numpy-19599,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-19599 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2021-08-02 18:44:23,a1ee7968df16a4f57c8e22164d19aa2d14a6cdad,1.21
,APPROVED,numpy__numpy-19601,https://github.com/numpy/numpy/pull/19601,"import timeit
import statistics

import numpy as np
from io import StringIO


num_lines_comments = int(1e5)
data = ['1,2,3 # comment'] * num_lines_comments
data_comments = StringIO('\n'.join(data))

num_lines_dtypes = int(1e5)
data = ['5, 7, 888'] * num_lines_dtypes
csv_data_dtypes = StringIO('\n'.join(data))

data = [""M, 21, 72, X, 155""] * 50000
csv_data_structured = StringIO('\n'.join(data))

np.random.seed(123)
test_array = np.random.rand(100000, 3)
skiprows_fname = 'test_array.csv'
np.savetxt(fname=skiprows_fname, X=test_array, delimiter=',')

size_uint64 = 10000
arr = np.arange(size_uint64).astype('uint64') + 2**63
uint64_data1 = StringIO('\n'.join(arr.astype(str).tolist()))
arr = arr.astype(object)
arr[500] = -1
uint64_data2 = StringIO('\n'.join(arr.astype(str).tolist()))

data = ['0, 1, 2, 3, 4, 5, 6, 7, 8, 9'] * 5000
csv_data_usecols = StringIO('\n'.join(data))

dates = np.arange('2020-01-01', '2020-01-21', dtype='datetime64[D]')
np.random.seed(123)
values = np.random.rand(20)
date_line = ''.join(f""{str(date)},{value}\n"" for date, value in zip(dates, values))
data = date_line * (20000 // 20)
csv_data_datetime = StringIO(data)


def workload():
    np.loadtxt(data_comments, delimiter=',')
    data_comments.seek(0)

    np.loadtxt(csv_data_dtypes, delimiter=',', dtype='object')
    csv_data_dtypes.seek(0)

    np.loadtxt(csv_data_structured, delimiter=',', dtype=[
        ('category_1', 'S1'),
        ('category_2', 'i4'),
        ('category_3', 'f8'),
        ('category_4', 'S1'),
        ('category_5', 'f8')])
    csv_data_structured.seek(0)

    np.loadtxt(skiprows_fname, delimiter=',', skiprows=10000)

    np.loadtxt(uint64_data1)
    uint64_data1.seek(0)

    np.loadtxt(uint64_data2)
    uint64_data2.seek(0)

    np.loadtxt(csv_data_usecols, delimiter=',', usecols=[1, 3, 5, 7])
    csv_data_usecols.seek(0)

    np.loadtxt(csv_data_datetime,
               delimiter=',',
               dtype=[('dates', 'M8[us]'), ('values', 'float64')])
    csv_data_datetime.seek(0)


runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.3381418218032923
Before SD: 0.00646591014336387
After Mean: 1.299994302765699
After SD: 0.004716111624293895
Improvement: -2.85%",,179,docker.io/sweperf/sweperf:numpy__numpy-19601,docker.io/sweperf/sweperf_annotate:numpy__numpy-19601,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-19601 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2021-08-02 20:39:29,f25905b5d25a2fca1e23adad11d4597a1e658276,1.21
,APPROVED,numpy__numpy-19608,https://github.com/numpy/numpy/pull/19608,"import timeit
import statistics

import numpy as np
from io import StringIO


num_lines_comments = int(1e5)
data = ['1,2,3 # comment'] * num_lines_comments
data_comments = StringIO('\n'.join(data))

num_lines_dtypes = int(1e5)
data = ['5, 7, 888'] * num_lines_dtypes
csv_data_dtypes = StringIO('\n'.join(data))

data = [""M, 21, 72, X, 155""] * 50000
csv_data_structured = StringIO('\n'.join(data))

np.random.seed(123)
test_array = np.random.rand(100000, 3)
skiprows_fname = 'test_array.csv'
np.savetxt(fname=skiprows_fname, X=test_array, delimiter=',')

size_uint64 = 10000
arr = np.arange(size_uint64).astype('uint64') + 2**63
uint64_data1 = StringIO('\n'.join(arr.astype(str).tolist()))
arr = arr.astype(object)
arr[500] = -1
uint64_data2 = StringIO('\n'.join(arr.astype(str).tolist()))

data = ['0, 1, 2, 3, 4, 5, 6, 7, 8, 9'] * 5000
csv_data_usecols = StringIO('\n'.join(data))

dates = np.arange('2020-01-01', '2020-01-21', dtype='datetime64[D]')
np.random.seed(123)
values = np.random.rand(20)
date_line = ''.join(f""{str(date)},{value}\n"" for date, value in zip(dates, values))
data = date_line * (20000 // 20)
csv_data_datetime = StringIO(data)


def workload():
    np.loadtxt(data_comments, delimiter=',')
    data_comments.seek(0)

    np.loadtxt(csv_data_dtypes, delimiter=',', dtype='object')
    csv_data_dtypes.seek(0)

    np.loadtxt(csv_data_structured, delimiter=',', dtype=[
        ('category_1', 'S1'),
        ('category_2', 'i4'),
        ('category_3', 'f8'),
        ('category_4', 'S1'),
        ('category_5', 'f8')])
    csv_data_structured.seek(0)

    np.loadtxt(skiprows_fname, delimiter=',', skiprows=10000)

    np.loadtxt(uint64_data1)
    uint64_data1.seek(0)

    np.loadtxt(uint64_data2)
    uint64_data2.seek(0)

    np.loadtxt(csv_data_usecols, delimiter=',', usecols=[1, 3, 5, 7])
    csv_data_usecols.seek(0)

    np.loadtxt(csv_data_datetime,
               delimiter=',',
               dtype=[('dates', 'M8[us]'), ('values', 'float64')])
    csv_data_datetime.seek(0)


runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.0687431509979068
Before SD: 0.007257671469953935
After Mean: 0.8781097226799466
After SD: 0.0037889982700491094
Improvement: -17.84%",,179,docker.io/sweperf/sweperf:numpy__numpy-19608,docker.io/sweperf/sweperf_annotate:numpy__numpy-19608,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-19608 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2021-08-03 21:22:49,b5cdbf0434019e802b5e1a44bee06e67e0beef75,1.21
,APPROVED,numpy__numpy-19609,https://github.com/numpy/numpy/pull/19609,"import timeit
import statistics

import numpy as np
from io import StringIO


num_lines_comments = int(1e5)
data = ['1,2,3 # comment'] * num_lines_comments
data_comments = StringIO('\n'.join(data))

num_lines_dtypes = int(1e5)
data = ['5, 7, 888'] * num_lines_dtypes
csv_data_dtypes = StringIO('\n'.join(data))

data = [""M, 21, 72, X, 155""] * 50000
csv_data_structured = StringIO('\n'.join(data))

np.random.seed(123)
test_array = np.random.rand(100000, 3)
skiprows_fname = 'test_array.csv'
np.savetxt(fname=skiprows_fname, X=test_array, delimiter=',')

size_uint64 = 10000
arr = np.arange(size_uint64).astype('uint64') + 2**63
uint64_data1 = StringIO('\n'.join(arr.astype(str).tolist()))
arr = arr.astype(object)
arr[500] = -1
uint64_data2 = StringIO('\n'.join(arr.astype(str).tolist()))

data = ['0, 1, 2, 3, 4, 5, 6, 7, 8, 9'] * 5000
csv_data_usecols = StringIO('\n'.join(data))

dates = np.arange('2020-01-01', '2020-01-21', dtype='datetime64[D]')
np.random.seed(123)
values = np.random.rand(20)
date_line = ''.join(f""{str(date)},{value}\n"" for date, value in zip(dates, values))
data = date_line * (20000 // 20)
csv_data_datetime = StringIO(data)


def workload():
    np.loadtxt(data_comments, delimiter=',')
    data_comments.seek(0)

    np.loadtxt(csv_data_dtypes, delimiter=',', dtype='object')
    csv_data_dtypes.seek(0)

    np.loadtxt(csv_data_structured, delimiter=',', dtype=[
        ('category_1', 'S1'),
        ('category_2', 'i4'),
        ('category_3', 'f8'),
        ('category_4', 'S1'),
        ('category_5', 'f8')])
    csv_data_structured.seek(0)

    np.loadtxt(skiprows_fname, delimiter=',', skiprows=10000)

    np.loadtxt(uint64_data1)
    uint64_data1.seek(0)

    np.loadtxt(uint64_data2)
    uint64_data2.seek(0)

    np.loadtxt(csv_data_usecols, delimiter=',', usecols=[1, 3, 5, 7])
    csv_data_usecols.seek(0)

    np.loadtxt(csv_data_datetime,
               delimiter=',',
               dtype=[('dates', 'M8[us]'), ('values', 'float64')])
    csv_data_datetime.seek(0)


runtimes = timeit.repeat(workload, number=5, repeat=20)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.8213147351023506
Before SD: 0.05290344154605121
After Mean: 3.6293187207198936
After SD: 0.027651286722094864
Improvement: -5.02%",,179,docker.io/sweperf/sweperf:numpy__numpy-19609,docker.io/sweperf/sweperf_annotate:numpy__numpy-19609,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-19609 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2021-08-03 21:40:34,99eac42354f9c900bf8897abec6e7c1bd6c9ff6c,1.21
,APPROVED,numpy__numpy-19610,https://github.com/numpy/numpy/pull/19610,"import timeit
import statistics

import numpy as np
from io import StringIO


num_lines_comments = int(1e5)
data = ['1,2,3 # comment'] * num_lines_comments
data_comments = StringIO('\n'.join(data))

num_lines_dtypes = int(1e5)
data = ['5, 7, 888'] * num_lines_dtypes
csv_data_dtypes = StringIO('\n'.join(data))

data = [""M, 21, 72, X, 155""] * 50000
csv_data_structured = StringIO('\n'.join(data))

np.random.seed(123)
test_array = np.random.rand(100000, 3)
skiprows_fname = 'test_array.csv'
np.savetxt(fname=skiprows_fname, X=test_array, delimiter=',')

size_uint64 = 10000
arr = np.arange(size_uint64).astype('uint64') + 2**63
uint64_data1 = StringIO('\n'.join(arr.astype(str).tolist()))
arr = arr.astype(object)
arr[500] = -1
uint64_data2 = StringIO('\n'.join(arr.astype(str).tolist()))

data = ['0, 1, 2, 3, 4, 5, 6, 7, 8, 9'] * 5000
csv_data_usecols = StringIO('\n'.join(data))

dates = np.arange('2020-01-01', '2020-01-21', dtype='datetime64[D]')
np.random.seed(123)
values = np.random.rand(20)
date_line = ''.join(f""{str(date)},{value}\n"" for date, value in zip(dates, values))
data = date_line * (20000 // 20)
csv_data_datetime = StringIO(data)


def workload():
    np.loadtxt(data_comments, delimiter=',')
    data_comments.seek(0)

    np.loadtxt(csv_data_dtypes, delimiter=',', dtype='object')
    csv_data_dtypes.seek(0)

    np.loadtxt(csv_data_structured, delimiter=',', dtype=[
        ('category_1', 'S1'),
        ('category_2', 'i4'),
        ('category_3', 'f8'),
        ('category_4', 'S1'),
        ('category_5', 'f8')])
    csv_data_structured.seek(0)

    np.loadtxt(skiprows_fname, delimiter=',', skiprows=10000)

    np.loadtxt(uint64_data1)
    uint64_data1.seek(0)

    np.loadtxt(uint64_data2)
    uint64_data2.seek(0)

    np.loadtxt(csv_data_usecols, delimiter=',', usecols=[1, 3, 5, 7])
    csv_data_usecols.seek(0)

    np.loadtxt(csv_data_datetime,
               delimiter=',',
               dtype=[('dates', 'M8[us]'), ('values', 'float64')])
    csv_data_datetime.seek(0)


runtimes = timeit.repeat(workload, number=5, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.9617995819213685
Before SD: 0.05936629200124948
After Mean: 3.7919173635705374
After SD: 0.05407492342972274
Improvement: -4.29%",,179,docker.io/sweperf/sweperf:numpy__numpy-19610,docker.io/sweperf/sweperf_annotate:numpy__numpy-19610,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-19610 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2021-08-03 21:48:02,887766071724d27431b453b8270f299213b2d189,1.21
,APPROVED,numpy__numpy-19618,https://github.com/numpy/numpy/pull/19618,"import timeit
import statistics

import numpy as np
from io import StringIO

data = ['0, 1, 2, 3, 4, 5, 6, 7, 8, 9'] * 5000
csv_data_usecols = StringIO('\n'.join(data))

def workload():
    for combo in [2, [1, 3], [1, 3, 5, 7]]:
        np.loadtxt(csv_data_usecols, delimiter=',', usecols=combo)
        csv_data_usecols.seek(0)

runtimes = timeit.repeat(workload, number=5, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.11419468294788385
Before SD: 0.0005716209661333592
After Mean: 0.10130681198142702
After SD: 0.00032962689074443754
Improvement: -11.29%",,179,docker.io/sweperf/sweperf:numpy__numpy-19618,docker.io/sweperf/sweperf_annotate:numpy__numpy-19618,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-19618 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2021-08-05 16:46:03,1fdfdfa97b0528f67f8fcf826f1e33f45569340a,1.21
,APPROVED,numpy__numpy-19620,https://github.com/numpy/numpy/pull/19620,"import timeit
import statistics

import numpy as np
from io import StringIO


num_lines_dtypes = int(1e5)
data = ['5, 7, 888'] * num_lines_dtypes
csv_data_dtypes = StringIO('\n'.join(data))

dates = np.arange('2020-01-01', '2020-01-21', dtype='datetime64[D]')
np.random.seed(123)
values = np.random.rand(20)
date_line = ''.join(f""{str(date)},{value}\n"" for date, value in zip(dates, values))
data = date_line * (20000 // 20)
csv_data_datetime = StringIO(data)


def workload():
    for dtype in ['float32', 'float64', 'int32', 'int64', 'complex128', 'str', 'object']:
        np.loadtxt(csv_data_dtypes, delimiter=',', dtype=dtype)
        csv_data_dtypes.seek(0)

    np.loadtxt(csv_data_datetime,
               delimiter=',',
               dtype=[('dates', 'M8[us]'), ('values', 'float64')])
    csv_data_datetime.seek(0)


runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 6.2473106411099435
Before SD: 0.10734410850231425
After Mean: 5.768966328608803
After SD: 0.0662209008939733
Improvement: -7.66%",,179,docker.io/sweperf/sweperf:numpy__numpy-19620,docker.io/sweperf/sweperf_annotate:numpy__numpy-19620,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-19620 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2021-08-05 22:25:06,99eac42354f9c900bf8897abec6e7c1bd6c9ff6c,1.21
,APPROVED,numpy__numpy-21354,https://github.com/numpy/numpy/pull/21354,"import timeit
import statistics

import numpy as np

large_arr = np.random.random((10,) * 4)
large_mat = np.matrix(np.random.random((100, 100)))
scalar = 7

def workload():
    np.kron(large_arr, large_arr)
    np.kron(large_arr, scalar)        
    np.kron(large_mat, large_mat)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.7849834885692689
Before SD: 0.012514110106203104
After Mean: 0.4416078327104333
After SD: 0.0024059192105538164
Improvement: -43.74%",,192,docker.io/sweperf/sweperf:numpy__numpy-21354,docker.io/sweperf/sweperf_annotate:numpy__numpy-21354,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-21354 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2022-04-17 11:47:00,2ec5f6780ae08203bdcb56b439787c660b9cefb6,1.22
,APPROVED,numpy__numpy-21394,https://github.com/numpy/numpy/pull/21394,"import timeit
import statistics

import numpy as np

x1 = np.random.rand(100,)
x2 = x1 + 1j * np.random.rand(100,)

def workload():
    np.linalg.norm(x1)
    np.linalg.norm(x2)

runtimes = timeit.repeat(workload, number=10, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 6.3150111472758e-05
Before SD: 2.085599959186736e-06
After Mean: 5.0260619185602994e-05
After SD: 1.7593040907395574e-06
Improvement: -20.41%",,192,docker.io/sweperf/sweperf:numpy__numpy-21394,docker.io/sweperf/sweperf_annotate:numpy__numpy-21394,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-21394 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2022-04-26 8:17:54,fd646bd693400ce408566674f266407672248cad,1.22
,APPROVED,numpy__numpy-21832,https://github.com/numpy/numpy/pull/21832,"import timeit
import statistics

import numpy as np

def workload():
    np.linspace(0, 10, 2)
    np.linspace([1, 2], 10, 5)

runtimes = timeit.repeat(workload, number=5, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.000132370024614851
Before SD: 2.894846009153482e-06
After Mean: 9.89263415276364e-05
After SD: 1.968165284247546e-06
Improvement: -25.27%",,198,docker.io/sweperf/sweperf:numpy__numpy-21832,docker.io/sweperf/sweperf_annotate:numpy__numpy-21832,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-21832 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2022-06-23 12:30:08,cafec60a5e28af98fb8798049edd7942720d2d74,1.23
,APPROVED,numpy__numpy-23088,https://github.com/numpy/numpy/pull/23088,"import timeit
import statistics

import numpy as np

def workload():
    np.finfo(np.complex128)

runtimes = timeit.repeat(workload, number=10, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.168411365157226e-06
Before SD: 7.396440320803606e-07
After Mean: 2.060948328289669e-06
After SD: 7.649046075966984e-07
Improvement: -34.95%",,50,docker.io/sweperf/sweperf:numpy__numpy-23088,docker.io/sweperf/sweperf_annotate:numpy__numpy-23088,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-23088 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2023-01-25 10:50:33,a5f4e8e417d815cb577a8f2f9414b07a689d69b1,1.24
,APPROVED,numpy__numpy-24610,https://github.com/numpy/numpy/pull/24610,"import timeit
import statistics

import numpy as np
from numpy.lib._function_base_impl import _quantile_is_valid

n = 10_000
q = np.linspace(0.1, .9, n)

def workload():
    _quantile_is_valid(q)

runtimes = timeit.repeat(workload, number=1, repeat=100000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 9.561800233786925e-06
Before SD: 7.428361187979488e-07
After Mean: 5.111700034467503e-06
After SD: 5.08696797978463e-07
Improvement: -46.54%",,5,docker.io/sweperf/sweperf:numpy__numpy-24610,docker.io/sweperf/sweperf_annotate:numpy__numpy-24610,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-24610 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2023-09-01 11:45:07,63d9da80788d75a5c2abb8e79c34a6f6eb02ef7e,1.25
,APPROVED,numpy__numpy-24663,https://github.com/numpy/numpy/pull/24663,"import timeit
import statistics

import numpy as np

base = np.random.randint(1, 100, (10000, 10000), dtype='int64')
a = base.copy()
a1 = base.copy()

b = base.copy().astype('float')
b[b == 50] = np.nan

b1 = b.copy()

data = {'a': a, 'b': b, 'a1': a1, 'b1': b1}

def workload():
    for (x, y) in [('a','a'),('a','a1'),('b','b'),('b','b1')]:
        ax = data[x]
        bx = data[y]
        res = np.array_equal(ax, bx, equal_nan=True)

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 3.4271488066005986
Before SD: 0.05401126363477122
After Mean: 1.021134611297748
After SD: 0.002999145821551316
Improvement: -70.20%",,204,docker.io/sweperf/sweperf:numpy__numpy-24663,docker.io/sweperf/sweperf_annotate:numpy__numpy-24663,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-24663 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2023-09-07 13:32:17,cdfbdf428d9df9c7119cecae323512a4cd3f57b7,1.26
,APPROVED,numpy__numpy-25299,https://github.com/numpy/numpy/pull/25299,"import numpy as np
from numpy.polynomial import polyutils as pu

from numpy.testing import (
    assert_raises, assert_equal, assert_,
)

import functools
import timeit
import statistics

def setup():
    global testf, td, test_wrapper

    def test_wrapper(testf, td):
        try:
            testf(td)
            assert False
        except ValueError:
            pass

    testf = pu.as_series
    td = [[]]

def workload():
    global testf, td, test_wrapper

    test_wrapper(testf, td)


runtimes = timeit.repeat(workload, number=1000, repeat=100, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0009941416096989997
Before SD: 1.2385289029799862e-05
After Mean: 0.0008095845507341437
After SD: 9.452404921049272e-06
Improvement: -18.56%",,10,docker.io/sweperf/sweperf:numpy__numpy-25299,docker.io/sweperf/sweperf_annotate:numpy__numpy-25299,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-25299 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2023-12-02 20:37:41,44570a8fe8263c8de2463c969324643b9af2feec,1.26
,APPROVED,numpy__numpy-25788,https://github.com/numpy/numpy/pull/25788,"import timeit
import statistics

import numpy as np

n = 64
A = np.random.rand(n, n)
B = np.random.rand(n, n)

def workload():
    np.tensordot(A, B)

runtimes = timeit.repeat(workload, number=10, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 7.875949379775557e-05
Before SD: 2.269267322354032e-06
After Mean: 5.881387810068554e-05
After SD: 1.8040826500340073e-06
Improvement: -25.32%",,205,docker.io/sweperf/sweperf:numpy__numpy-25788,docker.io/sweperf/sweperf_annotate:numpy__numpy-25788,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-25788 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2024-02-08 8:25:20,cd0e99a04eac1efaae8ad78bf50a21e110222f05,1.26
,APPROVED,numpy__numpy-25991,https://github.com/numpy/numpy/pull/25991,"import timeit
import statistics

import numpy as np
from numpy.polynomial.polyutils import as_series

x = np.array([1.])

val1 = [x,]
val2 = [x, x]

def workload():
    as_series(val1, trim=True)
    as_series(val2, trim=True)

runtimes = timeit.repeat(workload, number=1, repeat=10**6)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 5.837814301485196e-06
Before SD: 8.697343772493295e-07
After Mean: 4.1472248685313386e-06
After SD: 8.377174972213345e-07
Improvement: -28.96%",,10,docker.io/sweperf/sweperf:numpy__numpy-25991,docker.io/sweperf/sweperf_annotate:numpy__numpy-25991,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-25991 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2024-03-11 9:58:20,b1e6ccd14b173b922f5d6a11bb252f4141dc42cd,1.26
,APPROVED,numpy__numpy-26130,https://github.com/numpy/numpy/pull/26130,"import timeit
import statistics

import numpy as np
from numpy.polynomial import Polynomial

x = np.array([1, 2, 3])
zero_d = np.float64(1.)

def workload():
    np.atleast_1d(x)
    
runtimes = timeit.repeat(workload, number=1, repeat=10**6)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 3.563228159910068e-07
Before SD: 1.2454096076386103e-07
After Mean: 2.915653828822542e-07
After SD: 1.1499756265632308e-07
Improvement: -18.17%",,201,docker.io/sweperf/sweperf:numpy__numpy-26130,docker.io/sweperf/sweperf_annotate:numpy__numpy-26130,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-26130 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2024-03-25 10:14:34,aa0cc043d1fe51e61024842b21905e11a2a4cee6,1.26
,APPROVED,numpy__numpy-26599,https://github.com/numpy/numpy/pull/26599,"import timeit
import statistics

import numpy as np

def workload():
    np.broadcast_shapes((6, 7000000), (5, 6, 1), (7000000,), (5, 1, 7000000))

runtimes = timeit.repeat(workload, number=10, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))


","Before Mean: 0.00012905067018279806
Before SD: 4.827513782928313e-06
After Mean: 2.2247631410020405e-05
After SD: 1.4769831257196554e-06
Improvement: -82.76%",,201,docker.io/sweperf/sweperf:numpy__numpy-26599,docker.io/sweperf/sweperf_annotate:numpy__numpy-26599,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-26599 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2024-06-02 18:14:00,e41b9c14e17bdb2088f1955ca2aa7f10ace895d7,2
,APPROVED,numpy__numpy-27830,https://github.com/numpy/numpy/pull/27830,"import timeit
import statistics

import numpy as np

N = 10000
X = np.linspace(0, 1, N)
c = np.linspace(0, 1, N)

def workload():
    np.polynomial.legendre.legval(X, c)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.35663001522287957
Before SD: 0.0008086038570580236
After Mean: 0.20685892460215838
After SD: 0.0007562422393352055
Improvement: -42.00%",,2,docker.io/sweperf/sweperf:numpy__numpy-27830,docker.io/sweperf/sweperf_annotate:numpy__numpy-27830,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:numpy__numpy-27830 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",numpy/numpy,2024-11-24 18:24:03,1489be4cc2b5c5328015730bf856aa9a509dbb6d,2.1
,APPROVED,pandas-dev__pandas-23772,https://github.com/pandas-dev/pandas/pull/23772,"
import timeit
import statistics

import dateutil
import pandas as pd
from pandas import date_range
    
tz = dateutil.tz.tzutc()

def setup():
    global index
    dst_rng = date_range(start='10/29/2000 1:00:00',
                             end='10/29/2000 1:59:59', freq='S')
    index = date_range(start='10/29/2000',
                                end='10/29/2000 00:59:59', freq='S')
    index = index.append(dst_rng)
    index = index.append(dst_rng)
    index = index.append(date_range(start='10/29/2000 2:00:00',
                                    end='10/29/2000 3:00:00',
                                    freq='S'))

def workload():
    global index
    index.tz_localize(tz, ambiguous='infer')
    
runtimes = timeit.repeat(workload, number=1, repeat=10000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0003814085036574397
Before SD: 1.5153123712622637e-05
After Mean: 4.723329379921779e-05
After SD: 2.336062046986531e-06
Improvement: -87.62%",,386,docker.io/sweperf/sweperf:pandas-dev__pandas-23772,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-23772,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-23772 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2018-11-18 21:20:24,91d1c50327c209e03ffc32c5fd64f9666de81e20,0.23
,APPROVED,pandas-dev__pandas-23888,https://github.com/pandas-dev/pandas/pull/23888,"
import timeit
import statistics

import pandas as pd

def setup():
    global x
    x = pd.Series(list('abcd') * 1000000).astype('category')
    
def workload():
    global x
    x == 'a'
    
runtimes = timeit.repeat(workload, number=5, repeat=100, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.03749761789687909
Before SD: 0.0021942083389571163
After Mean: 0.004719279352575541
After SD: 0.00012419579242362147
Improvement: -87.41%",,237,docker.io/sweperf/sweperf:pandas-dev__pandas-23888,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-23888,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-23888 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2018-11-24 22:57:33,d865e5213515cef6344f16f4c77386be9ce8f223,0.23
,APPROVED,pandas-dev__pandas-24023,https://github.com/pandas-dev/pandas/pull/24023,"
import timeit
import statistics

import pandas as pd
import numpy as np
import string

def setup():
    """"""Setup function to create the CategoricalIndex objects.""""""
    global a, b, c
    
    np.random.seed(42) 
    a = pd.CategoricalIndex(np.random.choice(list(string.ascii_letters[:10]), 100_000))
    b = a.copy()
    c = pd.CategoricalIndex(np.random.choice(list(string.ascii_letters[:10]), 100_000))
    
def workload():
    global a, b, c
    a.equals(b)
    a.equals(c)
    
runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.005045750829915051
Before SD: 0.00022732016818791071
After Mean: 0.0004970159545191564
After SD: 2.2657510184029433e-05
Improvement: -90.15%",,38,docker.io/sweperf/sweperf:pandas-dev__pandas-24023,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-24023,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-24023 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2018-11-30 19:11:14,dc8d35aa53d496b651f5e1ab4cb2604e9f7236c7,0.23
,APPROVED,pandas-dev__pandas-24083,https://github.com/pandas-dev/pandas/pull/24083,"
import timeit
import statistics

import pandas as pd
import numpy as np

def setup():
    global df, df2, rng, grouper
    rng = pd.period_range(start='1/1/1990', freq='S', periods=20000)
    df = pd.DataFrame(index=range(len(rng)))

    N = 10**4
    grouper = pd.period_range('1900-01-01', freq='D', periods=N)
    df2 = pd.DataFrame(np.random.randn(10**4, 2))

def workload():
    global df, df2, rng, grouper
    df['col2'] = rng
    df.set_index('col2', append=True)
    
    df2.groupby(grouper).sum()

runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 3.3078015617257917
Before SD: 0.022536785830443086
After Mean: 0.1244119101180695
After SD: 0.0013014520179806645
Improvement: -96.24%",,22,docker.io/sweperf/sweperf:pandas-dev__pandas-24083,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-24083,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-24083 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2018-12-04 0:24:46,3fe697f3c9dcb0c0a7a9b91c0098d31b39f51fef,0.23
,APPROVED,pandas-dev__pandas-24308,https://github.com/pandas-dev/pandas/pull/24308,"
import timeit
import statistics

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt

N = 2000
M = 5

def setup():
    global df
    plt.close('all')
    np.random.seed(42)
    idx = pd.date_range('1/1/1975', periods=N)
    df = pd.DataFrame(np.random.randn(N, M), index=idx)

def workload():
    global df
    df.plot()

runtimes = timeit.repeat(workload, number=1, repeat=26, setup=setup)[-25:]

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.8431394305173308
Before SD: 0.0023895356157252355
After Mean: 0.049356083560269326
After SD: 0.0006147885388493904
Improvement: -94.15%",,427,docker.io/sweperf/sweperf:pandas-dev__pandas-24308,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-24308,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-24308 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2018-12-16 13:24:41,41681c89df25e78d072c862feabe24ec715eed54,0.23
,APPROVED,pandas-dev__pandas-24491,https://github.com/pandas-dev/pandas/pull/24491,"
import timeit
import statistics

import pandas as pd
from datetime import timedelta

tz = 'US/Eastern'
N = 100000

def setup():
    global series, index
    series = pd.Series(
        pd.date_range(start='1/1/2000', periods=N, freq='T', tz=tz)
    )
    index = pd.date_range(start='2000',
                          periods=N,
                          freq='s',
                          tz=tz)
    
def workload():
    _ = series.dt.year
    _ = index + timedelta(minutes=2)
    

runtimes = timeit.repeat(workload, number=1, repeat=100, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.2497764976002509
Before SD: 0.0024569367685634653
After Mean: 0.005601024643983692
After SD: 0.0008961105935512101
Improvement: -97.76%",,442,docker.io/sweperf/sweperf:pandas-dev__pandas-24491,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-24491,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-24491 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2018-12-30 1:41:05,62506ca3c37b6b0d84833a8329e50c000316250e,0.23
,APPROVED,pandas-dev__pandas-25070,https://github.com/pandas-dev/pandas/pull/25070,"
import timeit
import statistics

import pandas as pd

N = 10**6

s_fast = pd.Series([False] * N)
s_slow = pd.Series([True] * N)

def workload():
    s_fast.all()
    s_slow.all()
    
    s_fast.any()
    s_slow.any()

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.00468734520021826
Before SD: 0.0004986688739741285
After Mean: 0.00015573567943647504
After SD: 5.828161998142796e-05
Improvement: -96.68%",,454,docker.io/sweperf/sweperf:pandas-dev__pandas-25070,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-25070,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-25070 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-02-01 7:18:52,9feb3ad92cc0397a04b665803a49299ee7aa1037,0.24
,APPROVED,pandas-dev__pandas-25665,https://github.com/pandas-dev/pandas/pull/25665,"import timeit
import statistics
import matplotlib
matplotlib.use(""Agg"")
import pandas as pd
import numpy as np
from pandas import DataFrame, date_range
import matplotlib.pyplot as plt

def setup():
    global df
    N = 2000
    M = 5
    idx = date_range(""1/1/1975"", periods=N)
    df = DataFrame(np.random.randn(N, M), index=idx)
    plt.close('all')
    
def workload():
    global df
    _ = df.plot()

runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 3.7992277955886675
Before SD: 0.059297378425922934
After Mean: 3.375945166122401
After SD: 0.022618624175830725
Improvement: -11.14%",,6,docker.io/sweperf/sweperf:pandas-dev__pandas-25665,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-25665,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-25665 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-03-11 16:38:10,10173821965fa65654b172891b2102a8426132ca,0.24
,APPROVED,pandas-dev__pandas-25820,https://github.com/pandas-dev/pandas/pull/25820,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10**5

def setup():
    global intv
    left = np.append(np.arange(N), np.array(0))
    right = np.append(np.arange(1, N + 1), np.array(1))
    intv = pd.IntervalIndex.from_arrays(left, right)
    intv._engine

def workload():
    global intv
    intv.is_monotonic_increasing


runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.01476184327970259
Before SD: 0.0008579883518718155
After Mean: 0.0007927232595975511
After SD: 2.912129164105048e-05
Improvement: -94.63%",,454,docker.io/sweperf/sweperf:pandas-dev__pandas-25820,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-25820,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-25820 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-03-21 11:56:57,3ab84a0c7389642a4f27de4f00d6518cb77c3470,0.24
,APPROVED,pandas-dev__pandas-25953,https://github.com/pandas-dev/pandas/pull/25953,"
import timeit
import statistics

import pandas as pd
import numpy as np

ops = ['mean', 'sum', 'median', 'std', 'skew', 'kurt', 'mad', 'prod', 'sem',
       'var']
level = 1

levels = [np.arange(10), np.arange(100), np.arange(100)]
codes = [np.arange(10).repeat(10000),
            np.tile(np.arange(100).repeat(100), 10),
            np.tile(np.tile(np.arange(100), 100), 10)]
index = pd.MultiIndex(levels=levels, codes=codes)
s = pd.Series(np.random.randn(len(index)), index=index)

op_funcs = [getattr(s, op) for op in ops]

def workload():
    for op in op_funcs:
        op(level=level)

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.10963932325801579
Before SD: 0.0008181389341457053
After Mean: 0.09130161583801964
After SD: 0.0009562042405102156
Improvement: -16.73%",,73,docker.io/sweperf/sweperf:pandas-dev__pandas-25953,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-25953,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-25953 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-04-02 1:22:45,48ea04fe5d3ba9b618152ae83aef703dbbb2c3f4,0.24
,APPROVED,pandas-dev__pandas-26015,https://github.com/pandas-dev/pandas/pull/26015,"
import timeit
import statistics

import pandas as pd
import numpy as np

mapper_options = ['dict', 'Series']

map_size = 1000
map_data1 = pd.Series(map_size - np.arange(map_size), dtype='category')
map_data2 = map_data1.copy().to_dict()

s = pd.Series(np.random.randint(0, map_size, 10000), dtype='category')

def workload():
    s.map(map_data1)
    s.map(map_data2)

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.002105879385082517
Before SD: 5.4993184789762045e-05
After Mean: 0.0008541430628392846
After SD: 3.5708989389084676e-05
Improvement: -59.44%",,56,docker.io/sweperf/sweperf:pandas-dev__pandas-26015,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26015,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26015 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-04-06 16:28:39,b6324be64884afdd2829e046748b7e843e338c65,0.24
,APPROVED,pandas-dev__pandas-26391,https://github.com/pandas-dev/pandas/pull/26391,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10**7

def setup():
    global intv
    left = np.append(np.arange(N), np.array(0))
    right = np.append(np.arange(1, N + 1), np.array(1))
    intv = pd.IntervalIndex.from_arrays(left, right)
    intv._engine

def workload():
    global intv
    intv.is_unique

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 3.7112313087855
Before SD: 0.06533191700371768
After Mean: 1.3447206930839457
After SD: 0.012382774332785767
Improvement: -63.77%",,455,docker.io/sweperf/sweperf:pandas-dev__pandas-26391,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26391,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26391 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-05-14 15:16:05,612c24433b8486eb6b6b0013354dd6d6a296c100,0.24
,APPROVED,pandas-dev__pandas-26605,https://github.com/pandas-dev/pandas/pull/26605,"
import timeit
import statistics

import pandas as pd
import pandas.util.testing as tm
import numpy as np

N = 10 ** 5
other_cols, sep, na_rep, na_frac = 3, None, '-', 0.0

mask_gen = lambda: np.random.choice([True, False], N, p=[1 - na_frac, na_frac])
s = pd.Series(tm.makeStringIndex(N)).where(mask_gen())
others = pd.DataFrame(
    {i: tm.makeStringIndex(N).where(mask_gen()) for i in range(other_cols)}
)

def workload():
    s.str.cat(others=others, sep=sep, na_rep=na_rep)

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.037658381062792616
Before SD: 0.001468314004478888
After Mean: 0.029279421601095236
After SD: 0.0012053355685302772
Improvement: -22.25%",,1,docker.io/sweperf/sweperf:pandas-dev__pandas-26605,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26605,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26605 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-06-01 15:32:46,0fd888c8b318d4041b0ae53c64715eca0d345dd3,0.24
,APPROVED,pandas-dev__pandas-26697,https://github.com/pandas-dev/pandas/pull/26697,"
import timeit
import statistics

import pandas as pd
import numpy as np

rng = pd.RangeIndex(1_000_000)

def workload():
    rng.get_loc(np.int64(900_000))

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.11031610792735591
Before SD: 0.0009822502925238704
After Mean: 9.379710536450147e-07
After SD: 1.5213434460136285e-06
Improvement: -100.00%",,457,docker.io/sweperf/sweperf:pandas-dev__pandas-26697,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26697,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26697 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-06-06 21:18:16,649ad5c91aabb95d7f200eec84b82cae1459fc65,0.24
,APPROVED,pandas-dev__pandas-26702,https://github.com/pandas-dev/pandas/pull/26702,"
import timeit
import statistics

import pandas as pd

N = 10**6
idx = pd.date_range(start='20140101', freq='T', periods=N)
exit = 10000

def workload():
    for _ in idx:
        pass

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.8603920226043555
Before SD: 0.015456167543908031
After Mean: 0.2791419468820095
After SD: 0.00169138447475115
Improvement: -85.00%",,457,docker.io/sweperf/sweperf:pandas-dev__pandas-26702,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26702,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26702 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-06-07 8:46:53,3ff4f38f2b4572af92946af9ce9d50481413358d,0.24
,APPROVED,pandas-dev__pandas-26711,https://github.com/pandas-dev/pandas/pull/26711,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10**6

left = np.append(np.arange(N), np.array(0))
right = np.append(np.arange(1, N + 1), np.array(1))
intv = pd.IntervalIndex.from_arrays(left, right)
intv._engine

intv2 = pd.IntervalIndex.from_arrays(left + 1, right + 1)
intv2._engine

left = pd.IntervalIndex.from_breaks(np.arange(N))
right = pd.IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))

def workload():
    intv.intersection(right)

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.4325672626006417
Before SD: 0.007201139112213684
After Mean: 0.010830852591316215
After SD: 0.009524321745260066
Improvement: -97.50%",,463,docker.io/sweperf/sweperf:pandas-dev__pandas-26711,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26711,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26711 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-06-07 19:08:56,0f3e8e8bd2118d56c7febe5d6081c5058cb22be7,0.24
,APPROVED,pandas-dev__pandas-26721,https://github.com/pandas-dev/pandas/pull/26721,"
import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame({
    'a': np.arange(1_000_000, dtype=np.int32),
    'b': np.arange(1_000_000, dtype=np.int64),
    'c': np.arange(1_000_000, dtype=float),
}).astype({'a': 'category', 'b': 'category'})

def workload():
    df.set_index(['a', 'b'])

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.085367325390107
Before SD: 0.003450002580758319
After Mean: 0.015777114866650663
After SD: 0.0009140338784490797
Improvement: -81.52%",,224,docker.io/sweperf/sweperf:pandas-dev__pandas-26721,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26721,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26721 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-06-07 22:15:10,3937fbc5fa7d4228c65e863a24d69fa4b7cf4ec7,0.24
,APPROVED,pandas-dev__pandas-26773,https://github.com/pandas-dev/pandas/pull/26773,"
import timeit
import statistics

import pandas as pd
import numpy as np
import tempfile
import os

tempfile_path_int= tempfile.NamedTemporaryFile(suffix="".json"", delete=False).name
tempfile_path_datetime = tempfile.NamedTemporaryFile(suffix="".json"", delete=False).name

N = 100000
orient = ""index""
indexes = {
    ""int"": np.arange(N),
    ""datetime"": pd.date_range(""20000101"", periods=N, freq=""H""),
}
df_int = pd.DataFrame(
    np.random.randn(N, 5),
    columns=[""float_{}"".format(i) for i in range(5)],
    index=indexes['int'],
)
df_datetime = pd.DataFrame(
    np.random.randn(N, 5),
    columns=[""float_{}"".format(i) for i in range(5)],
    index=indexes['datetime'],
)

df_int.to_json(tempfile_path_int, orient=orient)
df_datetime.to_json(tempfile_path_datetime, orient=orient)

def workload():
    _ = pd.read_json(tempfile_path_int, orient=orient)
    _ = pd.read_json(tempfile_path_datetime, orient=orient)

runtimes = timeit.repeat(workload, number=1, repeat=10)

os.remove(tempfile_path_int)
os.remove(tempfile_path_datetime)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 5.773207039985573
Before SD: 0.0328531546564316
After Mean: 1.3726399181934539
After SD: 0.068006702008551
Improvement: -76.22%",,6,docker.io/sweperf/sweperf:pandas-dev__pandas-26773,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26773,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26773 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-06-10 19:11:37,c64c9cb44222a42f7b02d4d6007919cd0645f1be,0.24
,APPROVED,pandas-dev__pandas-26776,https://github.com/pandas-dev/pandas/pull/26776,"import timeit
import statistics
import scipy.sparse
import warnings
import pandas as pd

def setup():
    global sparse
    N = 1000 
    sparse = scipy.sparse.rand(N, N, 0.005)
    warnings.simplefilter('ignore', FutureWarning)

def workload():
    global sparse
    pd.SparseDataFrame(sparse)

runtimes = timeit.repeat(workload, number=1, repeat=100, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.2787076130107744
Before SD: 0.005347847340857102
After Mean: 0.20705281338014175
After SD: 0.0009485175306814576
Improvement: -83.81%",,463,docker.io/sweperf/sweperf:pandas-dev__pandas-26776,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26776,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-26776 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-06-11 7:34:05,157a4e35d25cafdca2fbc48ccda2c14eb7f25bcb,0.24
,APPROVED,pandas-dev__pandas-27384,https://github.com/pandas-dev/pandas/pull/27384,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 5

def setup():
    global idx
    idx = pd.MultiIndex.from_product(
        [pd.date_range(""1/1/2000"", freq=""T"", periods=N // 2), [""a"", ""b""]]
    )

def workload():
    global idx
    idx.shape

runtimes = timeit.repeat(workload, number=1, repeat=100, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.1433584085892653
Before SD: 0.0018373169145415964
After Mean: 4.679277772083879e-06
After SD: 5.646775521142578e-07
Improvement: -100.00%",,480,docker.io/sweperf/sweperf:pandas-dev__pandas-27384,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-27384,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-27384 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-07-14 8:13:45,a4c19e7aea4989f42dd021313af7523ed52fea3b,0.24
,APPROVED,pandas-dev__pandas-27448,https://github.com/pandas-dev/pandas/pull/27448,"
import timeit
import statistics

import pandas as pd

N = 10 ** 5
values = list(""a"" * N + ""b"" * N + ""c"" * N)
indices = {
    ""monotonic_incr"": pd.CategoricalIndex(values),
    ""monotonic_decr"": pd.CategoricalIndex(reversed(values)),
    ""non_monotonic"": pd.CategoricalIndex(list(""abc"" * N)),
}

int_scalar = 10000
int_list = list(range(10000))

def workload():
    for data in indices.values():
        data[: int_scalar]

runtimes = timeit.repeat(workload, number=1, repeat=10**5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0003196328286640346
Before SD: 1.3811089594982878e-05
After Mean: 4.2671266381512394e-05
After SD: 4.156892249310045e-06
Improvement: -86.65%",,115,docker.io/sweperf/sweperf:pandas-dev__pandas-27448,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-27448,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-27448 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-07-18 6:39:11,a4c19e7aea4989f42dd021313af7523ed52fea3b,0.24
,APPROVED,pandas-dev__pandas-27495,https://github.com/pandas-dev/pandas/pull/27495,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 5

def setup():
    global idx
    idx = pd.MultiIndex.from_product(
        [pd.date_range(""1/1/2000"", freq=""T"", periods=N // 2), [""a"", ""b""]]
    )

def workload():
    global idx
    idx.is_monotonic
    idx.is_monotonic_increasing
    idx.is_monotonic_decreasing

runtimes = timeit.repeat(workload, number=1, repeat=100, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.03272101049835328
Before SD: 0.0006509282107446101
After Mean: 0.0011803019989747555
After SD: 0.0004068152192516659
Improvement: -96.39%",,482,docker.io/sweperf/sweperf:pandas-dev__pandas-27495,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-27495,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-27495 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-07-20 23:54:04,8f4295a6478300521689be74ad7e4f82fe6b61e1,0.25
,APPROVED,pandas-dev__pandas-27669,https://github.com/pandas-dev/pandas/pull/27669,"
import timeit
import statistics

import pandas as pd
import numpy as np

ii = pd.interval_range(0, 20)
values = np.linspace(0, 20, 100).repeat(10**4)

def workload():
    pd.cut(values, ii)

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 6.48400796656264
Before SD: 0.020576017935692643
After Mean: 0.7612376414821483
After SD: 0.0020766224940939326
Improvement: -88.26%",,17,docker.io/sweperf/sweperf:pandas-dev__pandas-27669,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-27669,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-27669 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-07-31 4:06:28,143bc34aa8f068b18e7137df7ca91b9929cc1389,0.25
,APPROVED,pandas-dev__pandas-28099,https://github.com/pandas-dev/pandas/pull/28099,"
import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame({""A"": 0, ""B"": 0}, index=range(4*10**7))

def workload():
    df.replace([np.inf, -np.inf], np.nan)
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.replace([np.inf, -np.inf, 1], np.nan)

runtimes = timeit.repeat(workload, number=1, repeat=5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 11.128274863609112
Before SD: 1.0826216110101157
After Mean: 0.4087419650051743
After SD: 0.004727749284601213
Improvement: -96.33%",,8,docker.io/sweperf/sweperf:pandas-dev__pandas-28099,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-28099,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-28099 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-08-22 18:59:55,347ad8564ec7dbf679f61e88f6914ab20d7ae3da,0.25
,APPROVED,pandas-dev__pandas-28447,https://github.com/pandas-dev/pandas/pull/28447,"
import timeit
import statistics

import pandas as pd
import numpy as np

n = 100000
df = pd.DataFrame(np.random.randn(10, n))

def workload():
    df.select_dtypes(include=""int"")

runtimes = timeit.repeat(workload, number=1, repeat=5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 10.439169518405105
Before SD: 0.016518814214956254
After Mean: 0.005775532184634358
After SD: 0.000763208533910866
Improvement: -99.94%",,24,docker.io/sweperf/sweperf:pandas-dev__pandas-28447,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-28447,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-28447 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-09-14 14:23:46,fae8177cbf104b52af01034cb4e6198ff6455f5d,0.25
,APPROVED,pandas-dev__pandas-29134,https://github.com/pandas-dev/pandas/pull/29134,"
import timeit
import statistics

import pandas as pd

long_cheap_index = pd.RangeIndex(1000000)
short_expensive_index = pd.IntervalIndex(
    [pd.Interval(pd.Timestamp(2018, 10, 1), pd.Timestamp(2018, 10, 2))])

large_expensive_multiindex = pd.MultiIndex.from_product(
    [long_cheap_index, short_expensive_index])
trivial_simple_index = pd.Int64Index([])


def workload():
    large_expensive_multiindex.equals(trivial_simple_index)
    trivial_simple_index.equals(large_expensive_multiindex)

runtimes = timeit.repeat(workload, number=1, repeat=5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 2.481628795200959
Before SD: 5.549044081386597
After Mean: 9.184808004647493e-06
After SD: 1.1038292233041099e-05
Improvement: -100.00%",,250,docker.io/sweperf/sweperf:pandas-dev__pandas-29134,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-29134,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-29134 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-10-21 16:17:58,80a4156b9eb6310e5f555fba15cab74b77898fe6,0.25
,APPROVED,pandas-dev__pandas-29469,https://github.com/pandas-dev/pandas/pull/29469,"
import timeit
import statistics

import pandas as pd
import numpy as np

mi_med = pd.MultiIndex.from_product( 
    [np.arange(1000), np.arange(10), list(""A"")], names=[""one"", ""two"", ""three""] 
) 

def workload():
    mi_med.get_loc((999, 9, ""A""))  

runtimes = timeit.repeat(workload, number=5, repeat=10**5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0001352915498794755
Before SD: 5.678985462078498e-06
After Mean: 3.3542741900892e-05
After SD: 3.0067022501248305e-06
Improvement: -75.21%",,477,docker.io/sweperf/sweperf:pandas-dev__pandas-29469,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-29469,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-29469 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-11-07 18:40:15,d3461c14b1d38edb823e675ef130876677bd3cf1,0.25
,APPROVED,pandas-dev__pandas-29820,https://github.com/pandas-dev/pandas/pull/29820,"
import timeit
import statistics

import pandas as pd
import numpy as np

n = 1_000_000
c = pd.Categorical([np.nan] * n + ['b'] * n + ['c'] * n,
                   dtype=pd.CategoricalDtype(['a', 'b', 'c'], ordered=True))
def workload():
    (c == 'b')

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.001500396121875383
Before SD: 6.761468580595226e-05
After Mean: 0.00024059189134277405
After SD: 7.024411644429771e-06
Improvement: -83.96%",,481,docker.io/sweperf/sweperf:pandas-dev__pandas-29820,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-29820,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-29820 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-11-23 23:03:34,ab0c5822eb3a4717003d0597307284dcd7c4a887,0.25
,APPROVED,pandas-dev__pandas-30171,https://github.com/pandas-dev/pandas/pull/30171,"
import timeit
import statistics

import pandas as pd

def workload():
    pd.DataFrame(range(1_000_000)) 

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.21082046185911169
Before SD: 0.0017733999542322407
After Mean: 0.0006946651893667877
After SD: 0.0002389017742028481
Improvement: -99.67%",,204,docker.io/sweperf/sweperf:pandas-dev__pandas-30171,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-30171,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-30171 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2019-12-09 22:11:14,8705aad961dd227d38ff93a39697547b98109c9d,0.25
,APPROVED,pandas-dev__pandas-30747,https://github.com/pandas-dev/pandas/pull/30747,"import timeit
import statistics

import pandas as pd

N = 10 ** 6
categories = [""a"", ""b"", ""c""]
values = [0] * N + [1] * N + [2] * N
data = pd.Categorical.from_codes(values, categories=categories)

list_ = list(range(10000))

def workload():
    data[list_]

runtimes = timeit.repeat(workload, number=5, repeat=10**3)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.005920143779832869
Before SD: 5.4638812485987236e-05
After Mean: 0.003050318282330409
After SD: 4.600425446524149e-05
Improvement: -48.48%",,64,docker.io/sweperf/sweperf:pandas-dev__pandas-30747,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-30747,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-30747 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-01-06 17:42:48,bebaff09d511b6478d3ce279fab34e55e48e796a,0.25
,APPROVED,pandas-dev__pandas-30768,https://github.com/pandas-dev/pandas/pull/30768,"import timeit
import statistics

import numpy as np
import pandas as pd

a = np.arange(10**5)

def workload():
    pd.qcut(a, 10**4)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.26908208796114197
Before SD: 0.001152296208431813
After Mean: 0.2416770112782251
After SD: 0.0008485170357715562
Improvement: -10.18%",,13,docker.io/sweperf/sweperf:pandas-dev__pandas-30768,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-30768,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-30768 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-01-07 5:18:48,090957c669333bb2bbcdb15ab17bd6b10e9757e8,0.25
,APPROVED,pandas-dev__pandas-30797,https://github.com/pandas-dev/pandas/pull/30797,"import timeit
import statistics

import pandas as pd

idx = pd.interval_range(0, 1000, 1000) 

def workload():
    getattr(idx, '_ndarray_values', idx)
    idx.closed
    
runtimes = timeit.repeat(workload, number=10, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.01094331435430795
Before SD: 7.461555346134788e-05
After Mean: 4.921651247423143e-06
After SD: 1.1729321998333607e-05
Improvement: -99.96%",,518,docker.io/sweperf/sweperf:pandas-dev__pandas-30797,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-30797,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-30797 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-01-07 21:18:19,21fd692f744b47379b9b2f0760b2663d6338f0cd,0.25
,APPROVED,pandas-dev__pandas-31037,https://github.com/pandas-dev/pandas/pull/31037,"import timeit
import statistics

import pandas as pd

s1 = pd.Series(pd.date_range(""2012-01-01"", periods=3, tz='UTC')) 
s2 = pd.Series(pd.date_range(""2012-01-01"", periods=3)) 
s3 = pd.Series([1, 2, 3]) 

def workload():
    s1.array
    s2.array
    s3.array

runtimes = timeit.repeat(workload, number=5, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00011989080321032088
Before SD: 6.6950346093205155e-06
After Mean: 1.1896760013711173e-05
After SD: 1.7935077417390859e-06
Improvement: -90.08%",,522,docker.io/sweperf/sweperf:pandas-dev__pandas-31037,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-31037,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-31037 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-01-15 11:17:29,7b9ebb0c01588a4efaf0aa17782360d58803840b,0.25
,APPROVED,pandas-dev__pandas-31300,https://github.com/pandas-dev/pandas/pull/31300,"
import timeit
import statistics

import numpy as np
import pandas as pd
from pandas.core.ops import *

arr = np.arange(10**6)
df = pd.DataFrame({""A"": arr})
ser = df[""A""]

def workload():
    _ = df.add(df, fill_value=4)
    _ = ser.add(ser, fill_value=1)

runtimes = timeit.repeat(workload, number=5, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.08377274042618228
Before SD: 0.0025052580119237803
After Mean: 0.0370635184791754
After SD: 0.0012238232241809103
Improvement: -55.76%",,13,docker.io/sweperf/sweperf:pandas-dev__pandas-31300,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-31300,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-31300 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-01-25 2:01:57,e7b6a25bdee1adf4fd26b878809a6c840a51c932,0.25
,APPROVED,pandas-dev__pandas-31409,https://github.com/pandas-dev/pandas/pull/31409,"
import timeit
import statistics

import numpy as np
import pandas.core.common as com

cast_func = com.cast_scalar_indexer

key1 = np.float64(17179869184.0)
key2 = float(key1) * 2**30             
key3 = np.float64(np.iinfo(np.int64).max)
keys = (key1, key2, key3)

def workload():
    for key in keys:
        cast_func(key)

runtimes = timeit.repeat(workload, number=5, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.2823379666835535e-05
Before SD: 2.148727906559973e-06
After Mean: 3.5168676389730535e-06
After SD: 1.1314908951533634e-06
Improvement: -72.57%",,348,docker.io/sweperf/sweperf:pandas-dev__pandas-31409,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-31409,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-31409 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-01-29 2:13:52,cc1c406b3e3d4fe0ec9cd7ac5cc13275ffc111f2,0.25
,APPROVED,pandas-dev__pandas-32130,https://github.com/pandas-dev/pandas/pull/32130,"import timeit
import statistics

import pandas as pd

idx = pd.Index(range(1000)).insert(-1, 1)
idx2 = idx.astype('uint64')

def workload():
    idx[:5]
    idx2[5:]
    
runtimes = timeit.repeat(workload, number=10, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0003732343147858046
Before SD: 5.098697375232814e-06
After Mean: 3.8185752055142073e-05
After SD: 1.8570079397135247e-06
Improvement: -89.77%",,552,docker.io/sweperf/sweperf:pandas-dev__pandas-32130,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32130,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32130 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-02-20 16:32:29,37a700699235be283078847447ffdd00a244a295,1
,APPROVED,pandas-dev__pandas-32821,https://github.com/pandas-dev/pandas/pull/32821,"import timeit
import statistics

import pandas as pd
import numpy as np

data = np.array([1, 2, 3], dtype=float) 
index = pd.core.arrays.sparse.IntIndex(5, np.array([0, 2, 4])) 
dtype = pd.SparseDtype(""float64"", 0)   

def workload():
    pd.arrays.SparseArray._simple_new(data, index, dtype) 
    
runtimes = timeit.repeat(workload, number=5, repeat=10000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0001616430049703922
Before SD: 6.1705630190803416e-06
After Mean: 1.9142479402944444e-06
After SD: 4.267108335650609e-07
Improvement: -98.82%",,601,docker.io/sweperf/sweperf:pandas-dev__pandas-32821,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32821,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32821 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-03-19 7:26:36,dec52115edeef3e2b8f0d3823bb182e10de477fa,1
,APPROVED,pandas-dev__pandas-32825,https://github.com/pandas-dev/pandas/pull/32825,"
import timeit
import statistics

import pandas as pd
import scipy.sparse

n_samples = 100
n_features = 1000
X = scipy.sparse.rand(
    n_samples, n_features, random_state=0, density=0.01, format=""csr""
)

def workload():
    pd.DataFrame.sparse.from_spmatrix(X)

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.07422655200352893
Before SD: 0.00047746831697096715
After Mean: 0.005683673592284322
After SD: 0.00034707554886764054
Improvement: -92.34%",,611,docker.io/sweperf/sweperf:pandas-dev__pandas-32825,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32825,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32825 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-03-19 11:59:13,fddaa993540ef2894adad40db98d060688ff249d,1
,APPROVED,pandas-dev__pandas-32826,https://github.com/pandas-dev/pandas/pull/32826,"import timeit
import statistics

import pandas as pd
import numpy as np

arrays = [pd.arrays.SparseArray(np.random.randint(0, 2, 1000), dtype=""float64"") for _ in range(10000)]
index = pd.Index(range(len(arrays[0])))  
columns = pd.Index(range(len(arrays)))   

def workload():
    pd.DataFrame._from_arrays(arrays, index=index, columns=columns)  
    
runtimes = timeit.repeat(workload, number=5, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.0469589998363518
Before SD: 0.006947412991449967
After Mean: 0.43825101719470694
After SD: 0.0021670084501146515
Improvement: -58.14%",,601,docker.io/sweperf/sweperf:pandas-dev__pandas-32826,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32826,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32826 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-03-19 13:51:36,dbd7a5d3e2f1d196e8634c620fc72db1127de157,1
,APPROVED,pandas-dev__pandas-32856,https://github.com/pandas-dev/pandas/pull/32856,"
import timeit
import statistics

import pandas as pd
import numpy as np

arrays = [pd.arrays.SparseArray(np.random.randint(0, 2, 1000), dtype=""float64"") for _ in range(10000)]
index = pd.Index(range(len(arrays[0])))  
columns = pd.Index(range(len(arrays)))  

def workload():
    pd.DataFrame._from_arrays(arrays, index=index, columns=columns)  

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.08915017943945713
Before SD: 0.0006613892451918514
After Mean: 0.05724692112766206
After SD: 0.0005038466776811673
Improvement: -35.79%",,328,docker.io/sweperf/sweperf:pandas-dev__pandas-32856,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32856,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32856 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-03-20 9:13:09,3b406a32929f7d38a532f956d3aee1c9ee6bb364,1
,APPROVED,pandas-dev__pandas-32883,https://github.com/pandas-dev/pandas/pull/32883,"
import timeit
import statistics

import pandas as pd

n = 100_000
df = pd.DataFrame({'a': range(n), 'b': range(1, n+1)})
mi = pd.MultiIndex.from_frame(df)
mi.get_loc(mi[0]) 

def workload():
    mi.copy().get_loc(mi[0])

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.002945858247112483
Before SD: 0.00014665796177411734
After Mean: 2.962469233898446e-05
After SD: 3.1825808744960497e-06
Improvement: -98.99%",,601,docker.io/sweperf/sweperf:pandas-dev__pandas-32883,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32883,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-32883 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-03-21 13:33:34,139228b36c6752ace9b52260d97c217198b00e79,1
,APPROVED,pandas-dev__pandas-33032,https://github.com/pandas-dev/pandas/pull/33032,"
import timeit
import statistics

import pandas as pd
import numpy as np

arr = np.arange(10**7).reshape(-1, 10) 
df = pd.DataFrame(arr)
dtypes = ['u1', 'u2', 'u4', 'u8', 'i1', 'i2', 'i4', 'i8', 'f8', 'f4']                                                                              
for i, d in enumerate(dtypes): 
    df[i] = df[i].astype(d)

df.columns = [""A"", ""A""] + list(df.columns[2:])

def workload():
    df.iloc[10000]

runtimes = timeit.repeat(workload, number=5, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0810616845919285
Before SD: 0.0037245110317000803
After Mean: 0.000501746001187712
After SD: 3.11118114156774e-05
Improvement: -99.38%",,78,docker.io/sweperf/sweperf:pandas-dev__pandas-33032,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-33032,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-33032 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-03-26 3:27:56,b6cb1a4448edcc2813bbe6b97f35c653bd1e342d,1
,APPROVED,pandas-dev__pandas-33324,https://github.com/pandas-dev/pandas/pull/33324,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 6 
data = pd.Series(np.random.rand(N), index=pd.Int64Index(range(N))) 

def workload():
    data.iloc[:800000]
    data[:800000]

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.08523738675750792
Before SD: 0.0020519190453360783
After Mean: 5.5382042191922664e-05
After SD: 7.587577626215361e-05
Improvement: -99.94%",,210,docker.io/sweperf/sweperf:pandas-dev__pandas-33324,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-33324,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-33324 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-04-06 14:22:55,a9c105a7a6dfa210f2706e2d8df6a6222964ff26,1
,APPROVED,pandas-dev__pandas-33540,https://github.com/pandas-dev/pandas/pull/33540,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 1000
c = pd.CategoricalIndex(list(""a"" * N + ""b"" * N + ""c"" * N))
s = pd.Series(c)

def workload():
    s.is_monotonic_increasing

runtimes = timeit.repeat(workload, number=5, repeat=10*4)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0001877464499557391
Before SD: 2.2344012571992914e-05
After Mean: 0.00012377624661894516
After SD: 1.523118653682815e-05
Improvement: -34.07%",,657,docker.io/sweperf/sweperf:pandas-dev__pandas-33540,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-33540,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-33540 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-04-14 3:28:12,e8e2ea746b6b3b6a95426fa4503cc423b9508dee,1
,APPROVED,pandas-dev__pandas-34052,https://github.com/pandas-dev/pandas/pull/34052,"
import timeit
import statistics

import pandas as pd

n = 1000
df = pd.DataFrame({""A"": [str(i) for i in range(n)] * 10, ""B"": list(range(n)) * 10})
g = df.groupby(""A"").rolling(window=2)

def workload():
    g.sum()

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.122752208210295
Before SD: 0.004098811948133848
After Mean: 0.043493666913127525
After SD: 0.001183568912918246
Improvement: -96.13%",,679,docker.io/sweperf/sweperf:pandas-dev__pandas-34052,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34052,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34052 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-05-07 18:26:48,6ad157e937624854312934a3e2df8437083cf957,1
,APPROVED,pandas-dev__pandas-34178,https://github.com/pandas-dev/pandas/pull/34178,"
import timeit
import statistics

import pandas as pd

cat = pd.Categorical([""a""] * 1_000_000 + [""b""] * 1_000_000)
ser = pd.Series(cat)

def workload():
    ser.groupby(cat).first()

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.1018343673122581
Before SD: 0.0016034836910248553
After Mean: 0.020844656459521504
After SD: 0.0013195518989137637
Improvement: -79.53%",,679,docker.io/sweperf/sweperf:pandas-dev__pandas-34178,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34178,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34178 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-05-14 18:36:35,085af07ea0c5c7b1135043cf49c1c8f295bccec5,1
,APPROVED,pandas-dev__pandas-34192,https://github.com/pandas-dev/pandas/pull/34192,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 5
idx = pd.date_range(start=""1/1/2000"", periods=N, freq=""s"")
s = pd.Series(np.random.randn(N), index=idx)

def workload():
    s.sort_index()

runtimes = timeit.repeat(workload, number=1, repeat=10**5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00023699716459494083
Before SD: 1.1247091246178313e-05
After Mean: 4.564887940010521e-05
After SD: 3.9528902346590524e-06
Improvement: -80.74%",,148,docker.io/sweperf/sweperf:pandas-dev__pandas-34192,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34192,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34192 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-05-15 15:43:10,a94b13aac2c9cce2306fabdb696f7e5450fed11b,1
,APPROVED,pandas-dev__pandas-34199,https://github.com/pandas-dev/pandas/pull/34199,"
import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randn(100000, 5))
bool_indexer = [True] * 50000 + [False] * 50000

def workload():
    df[bool_indexer]

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.02369601422327105
Before SD: 0.00021602551211332942
After Mean: 0.00718183202855289
After SD: 0.0001153424564545788
Improvement: -69.69%",,253,docker.io/sweperf/sweperf:pandas-dev__pandas-34199,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34199,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34199 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-05-15 20:25:45,5f26c3429d7102bd6b4821e1ef29fc84d4367e02,1
,APPROVED,pandas-dev__pandas-34354,https://github.com/pandas-dev/pandas/pull/34354,"
import timeit
import statistics

import pandas as pd
import numpy as np

def setup():
    global value_df, ref_df
    my_date_range = pd.date_range('20200101 00:00', '20200102 0:00', freq='S')
    level_0_names = list(str(i) for i in range(30))
    #level_0_names = list(range(30))
    index = pd.MultiIndex.from_product([level_0_names, my_date_range])
    column_names = ['col_1', 'col_2']

    # Building a df that represents some value over time (think sensors)
    # Indexed by sensor and time 
    value_df = pd.DataFrame(np.random.rand(len(index),2), index=index, columns=column_names)

    # Build a reference df for the reference value the sensor can take (like its max)
    # Indexed by sensor
    ref_df = pd.DataFrame(np.random.randint(1, 10, (len(level_0_names), 2)), 
                    index = level_0_names, 
                    columns=column_names)


def workload():
    global value_df, ref_df
    value_df.sub(ref_df, level=0)

runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 4.691541911987588
Before SD: 0.029409793902081604
After Mean: 0.06123485181014985
After SD: 0.006039007532545855
Improvement: -98.69%",,142,docker.io/sweperf/sweperf:pandas-dev__pandas-34354,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34354,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34354 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-05-24 14:09:46,f5ab5a80a9193bdee50c661ce5a3abaabc312fd2,1
,APPROVED,pandas-dev__pandas-34737,https://github.com/pandas-dev/pandas/pull/34737,"
import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame({""A"": 0, ""B"": 0}, index=range(4 * 10 ** 7))

def workload():
    df.replace([np.inf, -np.inf, 1], np.nan, inplace=False)
    
runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.3922088980092667
Before SD: 0.003984588139570013
After Mean: 0.23353363330243154
After SD: 0.0014435874675624487
Improvement: -40.46%",,89,docker.io/sweperf/sweperf:pandas-dev__pandas-34737,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34737,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34737 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-06-12 21:11:45,f30aeefec8e6f0819b9e7c2f8375f8f0f7b21086,1
,APPROVED,pandas-dev__pandas-34948,https://github.com/pandas-dev/pandas/pull/34948,"
import timeit
import statistics

import pandas as pd
import numpy as np

map_size = 1000
map_data1 = pd.Series(map_size - np.arange(map_size), dtype='category').to_dict()
map_data2 = pd.Series(map_size - np.arange(map_size), dtype='int').to_dict()

s1 = pd.Series(np.random.randint(0, map_size, 10000), dtype='category')
s2 = pd.Series(np.random.randint(0, map_size, 10000), dtype='int')

df = pd.DataFrame({""A"": 0, ""B"": 0}, index=range(4 * 10 ** 7))

def workload():
    s1.map(map_data1)
    s2.map(map_data2)
    
runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0012287797601893543
Before SD: 3.458187915740296e-05
After Mean: 0.0011331204146845266
After SD: 3.452169921637247e-05
Improvement: -7.78%",,286,docker.io/sweperf/sweperf:pandas-dev__pandas-34948,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34948,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-34948 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-06-23 10:06:25,068d1b5be234231e5a829399d58136f5028834eb,1
,APPROVED,pandas-dev__pandas-35166,https://github.com/pandas-dev/pandas/pull/35166,"
import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randn(1000, 3), columns=list(""ABC""))

def workload():
    df.apply(lambda x: x[""A""] + x[""B""], axis=1)
    
runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.015380466239294037
Before SD: 0.0004725274560232036
After Mean: 0.0064600817405153065
After SD: 0.000390715530610687
Improvement: -58.00%",,44,docker.io/sweperf/sweperf:pandas-dev__pandas-35166,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-35166,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-35166 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-07-07 19:38:58,42a6d4457a1ff096e645d62ab90aca9210af86c3,1
,APPROVED,pandas-dev__pandas-36280,https://github.com/pandas-dev/pandas/pull/36280,"
import timeit
import statistics

import pandas as pd
import numpy as np

dti = pd.date_range(""2016-01-01"", periods=10000, tz=""US/Pacific"")
dti2 = type(dti)(dti._data.copy())

np.random.shuffle(dti._data._data)

cd1 = pd.CategoricalDtype(dti)
cd2 = pd.CategoricalDtype(dti2)
cd3 = pd.CategoricalDtype(dti2[:-1])
cd4 = pd.CategoricalDtype(pd.Index(range(len(dti))))

def workload():
    cd1 == cd2
    cd1 == cd3
    cd1 == cd4
    
runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0009371864584973082
Before SD: 1.6123835902013597e-05
After Mean: 0.0003211583389202133
After SD: 2.5231550792055634e-05
Improvement: -65.73%",,698,docker.io/sweperf/sweperf:pandas-dev__pandas-36280,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36280,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36280 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-09-11 1:52:01,822dc6f901fafd646257de2fc5ea918bbec82f93,1.1
,APPROVED,pandas-dev__pandas-36317,https://github.com/pandas-dev/pandas/pull/36317,"
import timeit
import statistics

import pandas as pd
import numpy as np

x = np.array([str(u) for u in range(1_000_000)], dtype=object)

def workload():
    pd.Series(x, dtype=str)
    
runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.03852172577288002
Before SD: 0.002104235376681154
After Mean: 0.017905452566919847
After SD: 0.0018354846292584338
Improvement: -53.52%",,698,docker.io/sweperf/sweperf:pandas-dev__pandas-36317,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36317,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36317 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-09-12 23:02:45,822dc6f901fafd646257de2fc5ea918bbec82f93,1.1
,APPROVED,pandas-dev__pandas-36325,https://github.com/pandas-dev/pandas/pull/36325,"
import timeit
import statistics

import pandas as pd
import numpy as np

x = np.array([str(u) for u in range(1_000_000)], dtype=object)

def workload():
    pd.Series(x, dtype=""string"")
    
runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.04129311381140724
Before SD: 0.002476935707285059
After Mean: 0.01775693342089653
After SD: 0.0015573943745544046
Improvement: -57.00%",,699,docker.io/sweperf/sweperf:pandas-dev__pandas-36325,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36325,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36325 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-09-13 6:52:50,0d4a1c15c64970bf1f73325f683f13de3b91730d,1.1
,APPROVED,pandas-dev__pandas-36432,https://github.com/pandas-dev/pandas/pull/36432,"
import timeit
import statistics

import pandas as pd
import numpy as np

x = np.array([str(u) for u in range(1_000_000)], dtype=object).reshape(500_000, 2)

def workload():
    pd.DataFrame(x, dtype=str)
    
runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.13146991024608723
Before SD: 0.01157996105188487
After Mean: 0.01777602156973444
After SD: 0.0014820111927350875
Improvement: -86.48%",,277,docker.io/sweperf/sweperf:pandas-dev__pandas-36432,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36432,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36432 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-09-17 18:06:58,aed64e85eb17edb0e55013868b1aa4e44e977a36,1.1
,APPROVED,pandas-dev__pandas-36611,https://github.com/pandas-dev/pandas/pull/36611,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 7
dtypes = [""int64"", ""int32"", ""float64"", ""float32"", ""object""]
max_number = 1000
series_type = [""random_hits"", ""random_misses"", ""monotone_hits"", ""monotone_misses""]

series_value_tuples_to_run = []
for dtype in dtypes:
    for series in series_type:
        if series == ""random_hits"":
            np.random.seed(42)
            array = np.random.randint(0, max_number, N)
        if series == ""random_misses"":
            np.random.seed(42)
            array = np.random.randint(0, max_number, N) + max_number
        if series == ""monotone_hits"":
            array = np.repeat(np.arange(max_number), N // max_number)
        if series == ""monotone_misses"":
            array = np.arange(N) + max_number
            
        series = pd.Series(array).astype(dtype)
        values = np.arange(max_number).astype(dtype)
        series_value_tuples_to_run.append((series, values))


def workload():
    for series, values in series_value_tuples_to_run:
        _ = series.isin(values)
    
runtimes = timeit.repeat(workload, number=1, repeat=3)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 7.613361887692008
Before SD: 0.024567379980292528
After Mean: 5.936274504327836
After SD: 0.06007440123701428
Improvement: -22.03%",,93,docker.io/sweperf/sweperf:pandas-dev__pandas-36611,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36611,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36611 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-09-24 20:16:34,f34fe6244e941c8701f9c0d243277ff075c58f05,1.1
,APPROVED,pandas-dev__pandas-36638,https://github.com/pandas-dev/pandas/pull/36638,"
import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randn(1_000_000, 10))

def workload():
    repr(df) 

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.7772244445804972
Before SD: 0.003268285167496337
After Mean: 0.007956896995892748
After SD: 0.0005607158371451397
Improvement: -98.98%",,52,docker.io/sweperf/sweperf:pandas-dev__pandas-36638,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36638,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36638 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-09-25 15:55:36,3b12293cea245507e7de71ecbadb3f61e6c71c45,1.1
,APPROVED,pandas-dev__pandas-36872,https://github.com/pandas-dev/pandas/pull/36872,"
import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame({'column1': range(600), 'group': 5*['l'+str(i) for i in range(120)]})
df = df.sort_values('group',kind='mergesort').reset_index(drop=True)

def workload():
    df['count'] = df.groupby('group').rolling(3,min_periods=1)['column1'].count().values

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.02294785696314648
Before SD: 0.0002999863818395448
After Mean: 0.0038310903718229384
After SD: 0.00010570179136903318
Improvement: -83.31%",,712,docker.io/sweperf/sweperf:pandas-dev__pandas-36872,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36872,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-36872 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-10-05 2:27:35,32d79ef46621de51e13732690c2e52566a5c67b6,1.1
,APPROVED,pandas-dev__pandas-37064,https://github.com/pandas-dev/pandas/pull/37064,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 5
N_groupby = 100

arr_options = [
    (100 * np.random.random(N)).astype(dtype)
    for dtype in [""int"", ""float""]
]
expanding_groupby_options = [
    pd.DataFrame({""A"": arr[:N_groupby], ""B"": range(N_groupby)}).groupby(""B"").expanding()
    for arr in arr_options
]
methods = [""median"", ""mean"", ""max"", ""min"", ""std"", ""count"", ""sum""]

def workload():
    for expanding_groupby in expanding_groupby_options:
        for method in methods:
            # Using timeit to measure the execution time of each method
            getattr(expanding_groupby, method)()

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.5560135753150098
Before SD: 0.0033340211303922724
After Mean: 0.034780822910834105
After SD: 0.00045728759738019887
Improvement: -93.74%",,712,docker.io/sweperf/sweperf:pandas-dev__pandas-37064,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37064,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37064 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-10-12 0:51:38,68f15fcec3a57bbd46e4132b9ded22e99802f6ed,1.1
,APPROVED,pandas-dev__pandas-37118,https://github.com/pandas-dev/pandas/pull/37118,"
import timeit
import statistics

import pandas as pd
import numpy as np

values = np.random.randn(100000, 4)   
df = pd.DataFrame(values).astype(""int"") 

def workload():
    df.sum() 

runtimes = timeit.repeat(workload, number=1, repeat=10**4)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0005899825462372973
Before SD: 3.488163414584123e-05
After Mean: 0.0003833218111714814
After SD: 3.4118831883088335e-05
Improvement: -35.03%",,97,docker.io/sweperf/sweperf:pandas-dev__pandas-37118,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37118,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37118 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-10-14 18:22:06,34afd03224503eeba4562649aa249d9d589b9c24,1.1
,APPROVED,pandas-dev__pandas-37130,https://github.com/pandas-dev/pandas/pull/37130,"
import timeit
import statistics

import pandas as pd
import numpy as np

n = 100_000
rng1 = pd.RangeIndex(n)
rng2 = pd.RangeIndex(n)

def workload():
    rng1 == rng2

runtimes = timeit.repeat(workload, number=1, repeat=10**4)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.00022301813044468873
Before SD: 6.675167864093349e-05
After Mean: 5.0595657841768116e-06
After SD: 1.159621909422267e-06
Improvement: -97.73%",,10,docker.io/sweperf/sweperf:pandas-dev__pandas-37130,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37130,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37130 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-10-15 7:14:21,d25cb8d4f494df6f27b842bb49f03cb8e3e3a890,1.1
,APPROVED,pandas-dev__pandas-37149,https://github.com/pandas-dev/pandas/pull/37149,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 2000
df = pd.DataFrame({""A"": [1] * N, ""B"": [np.nan, 1.0] * (N // 2)})
df = df.sort_values(""A"").set_index(""A"")

def workload():
    df.groupby(""A"")[""B""].fillna(method=""ffill"")

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 2.6442886579059994
Before SD: 0.061808416554227655
After Mean: 0.0007434270204976202
After SD: 5.6359168156483896e-05
Improvement: -99.97%",,35,docker.io/sweperf/sweperf:pandas-dev__pandas-37149,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37149,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37149 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-10-15 22:52:55,85793fb884e8838722945114ed525f93a30349ad,1.1
,APPROVED,pandas-dev__pandas-37400,https://github.com/pandas-dev/pandas/pull/37400,"
import timeit
import statistics

import pandas as pd

idx_large_fast = pd.RangeIndex(100000)
idx_small_slow = pd.date_range(start=""1/1/2012"", periods=1)
mi_large_slow = pd.MultiIndex.from_product([idx_large_fast, idx_small_slow])
idx_non_object = pd.RangeIndex(1)

def workload():
    mi_large_slow.equals(idx_non_object)

runtimes = timeit.repeat(workload, number=5, repeat=10**6)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 7.373663800302893e-06
Before SD: 1.3017821964103296e-06
After Mean: 5.44248777552275e-06
After SD: 1.214678104391236e-06
Improvement: -26.19%",,561,docker.io/sweperf/sweperf:pandas-dev__pandas-37400,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37400,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37400 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-10-25 11:30:35,18b4864b7d8638c3101ec11fd6562d2fbfe872a8,1.1
,APPROVED,pandas-dev__pandas-37426,https://github.com/pandas-dev/pandas/pull/37426,"
import timeit
import statistics

import pandas as pd
import numpy as np

values = np.random.randn(100000, 4)  
df = pd.DataFrame(values).astype(""int"")

def workload():
    df.sum()

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0004017277738894336
Before SD: 5.488288145396426e-05
After Mean: 0.00023822607874171808
After SD: 1.2596924324789646e-05
Improvement: -40.70%",,100,docker.io/sweperf/sweperf:pandas-dev__pandas-37426,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37426,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37426 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-10-26 19:10:02,c45da41115db5aeae28b133b9499deca07788b1a,1.1
,APPROVED,pandas-dev__pandas-37450,https://github.com/pandas-dev/pandas/pull/37450,"
import timeit
import statistics

import pandas as pd

n = 100_000
ser = pd.Series(['a'] * n)

def workload():
    dir(ser)

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.003240029243112076
Before SD: 0.00035870092390545544
After Mean: 0.0001221545775188133
After SD: 0.0003015733888014556
Improvement: -96.23%",,736,docker.io/sweperf/sweperf:pandas-dev__pandas-37450,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37450,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37450 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-10-27 18:27:26,d89331b96e919acc2a83f7f6201830d246018e36,1.1
,APPROVED,pandas-dev__pandas-37569,https://github.com/pandas-dev/pandas/pull/37569,"
import timeit
import statistics

import pandas as pd

n = 100_000
idx1 = pd.Int64Index(range(n))
idx2 = idx1.view()

idx3 = pd.Float64Index(range(n))
idx4 = idx3.view()

def workload():
    idx1 == idx2
    idx3 == idx4

runtimes = timeit.repeat(workload, number=1, repeat=10**4)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.00041954466585884803
Before SD: 6.770715458037768e-05
After Mean: 1.569321944261901e-05
After SD: 1.3117429991574902e-06
Improvement: -96.26%",,78,docker.io/sweperf/sweperf:pandas-dev__pandas-37569,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37569,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37569 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-11-01 22:11:40,6092dc7d9c81623ac603a563e416f2fd1151bcda,1.1
,APPROVED,pandas-dev__pandas-37945,https://github.com/pandas-dev/pandas/pull/37945,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 6
rng = pd.date_range(""1/1/2000"", periods=N, freq=""min"")
data = np.random.randn(N)
data[::2] = np.nan
ts = pd.Series(data, index=rng)

def workload():
    ts.fillna(0.0)

runtimes = timeit.repeat(workload, number=1, repeat=10**4)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.003692432718089549
Before SD: 9.807906606831878e-05
After Mean: 0.0018618053753627463
After SD: 6.939589450356454e-05
Improvement: -49.58%",,68,docker.io/sweperf/sweperf:pandas-dev__pandas-37945,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37945,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37945 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-11-18 20:41:56,a022d7b0d1e5bcc0f97b5fbdd848551cc77e71a0,1.1
,APPROVED,pandas-dev__pandas-37971,https://github.com/pandas-dev/pandas/pull/37971,"
import timeit
import statistics

import pandas as pd

idx = pd.IntervalIndex.from_breaks(range(10**4))
arr = idx._data

def workload():
    arr.argsort()

runtimes = timeit.repeat(workload, number=1, repeat=10**3)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.026637574674852657
Before SD: 0.000134066872145873
After Mean: 6.093345832778141e-05
After SD: 3.019773658421557e-06
Improvement: -99.77%",,33,docker.io/sweperf/sweperf:pandas-dev__pandas-37971,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37971,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-37971 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-11-20 3:25:43,b2b81d854a67d79cb84767e75254c1b380cf6982,1.1
,APPROVED,pandas-dev__pandas-38103,https://github.com/pandas-dev/pandas/pull/38103,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10000
rng = pd.date_range(start=""1/1/1990"", periods=N, freq=""53s"")
s = pd.Series(np.random.randn(N), index=rng)

dates = pd.date_range(start=""1/1/1990"", periods=N * 10, freq=""5s"")
date = dates[0]

def workload():
    s.asof(date)

runtimes = timeit.repeat(workload, number=5, repeat=10**5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0003657987819914706
Before SD: 9.586117414714891e-06
After Mean: 5.372291146544739e-05
After SD: 4.412743702509411e-06
Improvement: -85.31%",,74,docker.io/sweperf/sweperf:pandas-dev__pandas-38103,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38103,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38103 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-11-27 2:44:09,45ac7dafe280b8d5430e86f05cd63d859fcc61a9,1.1
,APPROVED,pandas-dev__pandas-38148,https://github.com/pandas-dev/pandas/pull/38148,"
import timeit
import statistics

import pandas as pd
import numpy as np
from string import ascii_lowercase

def setitem(x, x_cols, df):
    new = pd.DataFrame(index=df.index)
    new[x_cols] = x
    new[df.columns] = df
    return new

def concat(x, x_cols, df):
    return pd.concat(
        [
            pd.DataFrame(x, columns=x_cols, index=df.index),
            df,
        ],
        axis=1,
    )

x = np.ones((1000, 10))
x_col = list(ascii_lowercase[:10])
df = pd.DataFrame(
    {
        ""str"": np.random.choice(np.array(list(ascii_lowercase)), size=1000),
        ""int"": np.arange(1000, dtype=int),
    }
)
def workload():
    setitem(x, x_col, df)
    concat(x, x_col, df)

runtimes = timeit.repeat(workload, number=1, repeat=10**4)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0037200146708753893
Before SD: 5.338637340651613e-05
After Mean: 0.0010889010753133335
After SD: 3.809981511472526e-05
Improvement: -70.73%",,156,docker.io/sweperf/sweperf:pandas-dev__pandas-38148,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38148,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38148 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-11-29 14:07:15,59710bcd85ab8982da1bb26af0db7575a2c3565f,1.1
,APPROVED,pandas-dev__pandas-38353,https://github.com/pandas-dev/pandas/pull/38353,"
import timeit
import statistics

import pandas as pd
from pandas.core.algorithms import isin

ii = pd.IntervalIndex.from_breaks(range(100000))
values = ii[:100]

def workload():
    isin(ii, values)

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.04907549383246806
Before SD: 0.001272878876682005
After Mean: 0.007268444970773998
After SD: 0.0016939791626786984
Improvement: -85.19%",,755,docker.io/sweperf/sweperf:pandas-dev__pandas-38353,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38353,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38353 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-12-08 5:28:38,e2dec8d03020eb2b31d376a7fcd7348977c6a319,1.1
,APPROVED,pandas-dev__pandas-38379,https://github.com/pandas-dev/pandas/pull/38379,"
import timeit
import statistics

import pandas as pd
import numpy as np

arr = np.random.randint(0, 10, 1_000_001)
s = pd.Series(arr, dtype=""Int64"")

def workload():
    s.isin([1, 2, 3, 20])

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.026945398190291597
Before SD: 0.00045941835035712386
After Mean: 0.01398143568134401
After SD: 0.0006574322106909878
Improvement: -48.11%",,802,docker.io/sweperf/sweperf:pandas-dev__pandas-38379,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38379,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38379 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-12-09 1:08:46,edbd4503f9fe4969a2ae3482edb65055ee0e20a3,1.1
,APPROVED,pandas-dev__pandas-38560,https://github.com/pandas-dev/pandas/pull/38560,"
import timeit
import statistics

import pandas as pd

idx_large_fast = pd.RangeIndex(100_000)
idx_small_slow = pd.date_range(start=""1/1/2012"", periods=1)
mi_large_slow = pd.MultiIndex.from_product([idx_large_fast, idx_small_slow])

idx_non_object = pd.RangeIndex(1)

def workload():
    idx_non_object.equals(mi_large_slow)

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.006407494524028152
Before SD: 0.032026105578540576
After Mean: 4.076885525137186e-06
After SD: 4.217671400143715e-06
Improvement: -99.94%",,520,docker.io/sweperf/sweperf:pandas-dev__pandas-38560,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38560,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-38560 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2020-12-18 13:08:58,54682234e3a3e89e246313bf8f9a53f98b199e7b,1.1
,APPROVED,pandas-dev__pandas-39332,https://github.com/pandas-dev/pandas/pull/39332,"
import timeit
import statistics

import pandas as pd

dti = pd.date_range(""2016-01-01"", periods=10000, tz=""US/Pacific"")
dti2 = dti.tz_convert(""UTC"")

def workload():
    dti.get_indexer(dti2)

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.057505616042763
Before SD: 0.0006640594419269992
After Mean: 0.00031278624199330805
After SD: 9.760730615539836e-05
Improvement: -99.46%",,809,docker.io/sweperf/sweperf:pandas-dev__pandas-39332,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-39332,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-39332 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-01-22 5:08:55,c322b2436cdbb447a430bb9eb1aff965d07e7e4e,1.2
,APPROVED,pandas-dev__pandas-39388,https://github.com/pandas-dev/pandas/pull/39388,"
import timeit
import statistics

import pandas as pd
import numpy as np

window_options = [10, 1000, None]
method_options = [""corr"", ""cov""]
pairwise_options = [True, False]

N = 10 ** 4

arr = np.random.random(N)
df = pd.DataFrame(arr)

def workload():
    for window in window_options:
        for method in method_options:
            for pairwise in pairwise_options:
                if window is None:
                    r = df.expanding()
                else:
                    r = df.rolling(window=window)
                getattr(r, method)(df, pairwise=pairwise)

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.06483996267081238
Before SD: 0.0009963897470379411
After Mean: 0.050704034211230466
After SD: 0.0008624689223294472
Improvement: -21.80%",,809,docker.io/sweperf/sweperf:pandas-dev__pandas-39388,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-39388,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-39388 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-01-25 3:32:10,37b5800afb335fe1d09dde9153ca32c48c39f73e,1.2
,APPROVED,pandas-dev__pandas-39664,https://github.com/pandas-dev/pandas/pull/39664,"import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame({""A"": range(50), ""B"": range(50)})
gb_ewm = df.groupby(""A"").ewm(com=1.0)
methods = (""var"", ""std"", ""cov"", ""corr"")

def workload():
    for method in methods:
        getattr(gb_ewm, method)()
        
    gb_ewm.mean(engine='cython')

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.2470653169514843
Before SD: 0.007227524630371592
After Mean: 0.0626514062617207
After SD: 0.0011582129720629718
Improvement: -97.21%",,4,docker.io/sweperf/sweperf:pandas-dev__pandas-39664,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-39664,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-39664 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-02-08 6:37:32,e889b94124e67a581e424d5f60690cdb6b844346,1.2
,APPROVED,pandas-dev__pandas-39678,https://github.com/pandas-dev/pandas/pull/39678,"import timeit
import statistics

import pandas as pd
import numpy as np

dtype = np.dtype(float)
dtype2 = pd.Int32Dtype()

def workload():
    pd.api.types.is_extension_array_dtype(dtype)
    pd.api.types.is_extension_array_dtype(dtype2)

runtimes = timeit.repeat(workload, number=5, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.6539676630636677e-06
Before SD: 3.1535923799347623e-07
After Mean: 1.9927207002183423e-06
After SD: 2.3526570823566014e-07
Improvement: -24.92%",,821,docker.io/sweperf/sweperf:pandas-dev__pandas-39678,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-39678,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-39678 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-02-08 14:59:53,373d67722cd7a02f419a8fbbcaff037921cae6f7,1.2
,APPROVED,pandas-dev__pandas-39972,https://github.com/pandas-dev/pandas/pull/39972,"import itertools
import timeit
import statistics

import pandas as pd
import numpy as np

params = [[12, 24, 36], [12, 120]]

dataframes = []
st = []

def _apply_func(s):
    return [
        ""background-color: lightcyan"" if s.name == ""row_1"" else """" for v in s
    ]

for cols, rows in itertools.product(*params):
    df = pd.DataFrame(
            np.random.randn(rows, cols),
            columns=[f""float_{i+1}"" for i in range(cols)],
            index=[f""row_{i+1}"" for i in range(rows)],
        )
    st.append(
        df.style.apply(_apply_func, axis=1)
    )
    
def workload():
    for elem in st:
        elem.render()


runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.2103382483002497
Before SD: 0.0031867796117883308
After Mean: 0.07579733145877253
After SD: 0.003025022888560687
Improvement: -63.96%",,1,docker.io/sweperf/sweperf:pandas-dev__pandas-39972,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-39972,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-39972 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-02-22 17:12:44,dfb92d0f1bca79185128538698fbc660077eccfd,1.2
,APPROVED,pandas-dev__pandas-40035,https://github.com/pandas-dev/pandas/pull/40035,"import timeit
import statistics

import datetime
import pandas as pd

# example json data
data = {""hello"": [""thisisatest"", 999898, datetime.date.today()],
        ""nest1"": {""nest2"": {""nest3"": ""nest3_value"", ""nest3_int"": 3445}},
        ""nest1_list"": {""nest2"": [""blah"", 32423, 546456.876, 92030234]},
        ""hello2"": ""string""}

hundred_thousand_rows = [data for i in range(100000)]

def workload():
    pd.json_normalize(hundred_thousand_rows)

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.4169327268085907
Before SD: 0.04454673112868276
After Mean: 0.4273874971026089
After SD: 0.0013384785834151297
Improvement: -82.32%",,1,docker.io/sweperf/sweperf:pandas-dev__pandas-40035,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40035,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40035 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-02-24 23:10:37,316f5acce16cc4407c54c5c939222e544a231f65,1.2
,APPROVED,pandas-dev__pandas-40072,https://github.com/pandas-dev/pandas/pull/40072,"import timeit
import statistics

import pandas as pd

idx = pd.date_range('20000101','20201231',periods=50000)
df = pd.DataFrame(data=range(50000),index=idx)

def workload():
    df.ewm(halflife=pd.Timedelta('100d'),times=df.index).mean()

runtimes = timeit.repeat(workload, number=1, repeat=5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 17.26611212460557
Before SD: 0.0670105361609323
After Mean: 0.0019518165034241974
After SD: 0.00024877570870570763
Improvement: -99.99%",,828,docker.io/sweperf/sweperf:pandas-dev__pandas-40072,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40072,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40072 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-02-26 5:31:16,ab687aec38668cdb0139ca02d6e37e8c8386ae7d,1.2
,APPROVED,pandas-dev__pandas-40178,https://github.com/pandas-dev/pandas/pull/40178,"import timeit
import statistics

import numpy as np
import pandas as pd

ncols = 1000
N = 1000
data = np.random.randn(N, ncols)
labels = np.random.randint(0, 100, size=N)
df = pd.DataFrame(data)
df_am = df._as_manager('array')

def workload():
    df_am.groupby(labels).sum()

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.2714030879706843
Before SD: 0.002376031133212636
After Mean: 0.23250550432188902
After SD: 0.0008436328771124457
Improvement: -14.33%",,838,docker.io/sweperf/sweperf:pandas-dev__pandas-40178,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40178,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40178 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-03-02 20:03:53,b835ca2fc2f772c27c914ae532cd32f8db69724a,1.2
,APPROVED,pandas-dev__pandas-40254,https://github.com/pandas-dev/pandas/pull/40254,"
import timeit
import statistics

import numpy as np
import pandas as pd

N = 10 ** 3
sample = np.array([np.nan, 1.0])
data = np.random.choice(sample, (N, N))
df = pd.DataFrame(data)
df_am = df._as_manager(""array"")

def workload():
    df_am.isna()

runtimes = timeit.repeat(workload, number=1, repeat=10000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0034278998428839257
Before SD: 4.089448823167148e-05
After Mean: 0.003144785667967517
After SD: 3.8861214307301065e-05
Improvement: -8.26%",,839,docker.io/sweperf/sweperf:pandas-dev__pandas-40254,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40254,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40254 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-03-05 14:01:33,940926fea84d74c83332c6f4906f579defd03c34,1.2
,APPROVED,pandas-dev__pandas-40339,https://github.com/pandas-dev/pandas/pull/40339,"import timeit
import statistics

import numpy as np
import pandas as pd
import string

m = 100
n = 1000

dfs = []
for dtype in [""int"", ""category""]:
    levels = np.arange(m)
    index = pd.MultiIndex.from_product([levels] * 2)
    columns = np.arange(n)
    if dtype == ""int"":
        values = np.arange(m * m * n).reshape(m * m, n)
    else:
        n = 50
        columns = columns[:n]
        indices = np.random.randint(0, 52, size=(m * m, n))
        values = np.take(list(string.ascii_letters), indices)
        values = [pd.Categorical(v) for v in values.T]
        
    df = pd.DataFrame(values, index, columns)
    df2 = df.iloc[:-1]

    dfs.extend([
        df, df2
    ])

def workload():
    for df in dfs:
        df.unstack()

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.47638923782040365
Before SD: 0.002922797829821111
After Mean: 0.3948411296005361
After SD: 0.0016264068592412304
Improvement: -17.12%",,196,docker.io/sweperf/sweperf:pandas-dev__pandas-40339,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40339,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40339 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-03-10 1:55:08,93c52e4e1d172512b32e0e76e9b09c0cf76daf21,1.2
,APPROVED,pandas-dev__pandas-40818,https://github.com/pandas-dev/pandas/pull/40818,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 1_000_000
df = pd.DataFrame(np.random.randn(N, 10), columns=list(""abcdefghij""))
df[""key""] = np.random.randint(0, 100, size=N)

def workload():
    df.groupby(""key"").agg(""mean"")
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.4906609703414142
Before SD: 0.0090737929133133
After Mean: 0.2214291507494636
After SD: 0.002045578910232326
Improvement: -54.87%",,838,docker.io/sweperf/sweperf:pandas-dev__pandas-40818,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40818,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40818 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-04-06 22:41:56,3b4b193d57841b74853f8b16d2a9ac2e353fcff7,1.2
,APPROVED,pandas-dev__pandas-40840,https://github.com/pandas-dev/pandas/pull/40840,"
import timeit
import statistics

import pandas as pd

dti = pd.date_range(""2016-01-01"", periods=3)
dta = dti._data

def workload():
    dta.copy()
    dta.T
    
runtimes = timeit.repeat(workload, number=5, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 9.983877564081921e-06
Before SD: 6.947174143679744e-07
After Mean: 3.906273248139769e-06
After SD: 3.880987815554089e-07
Improvement: -60.87%",,844,docker.io/sweperf/sweperf:pandas-dev__pandas-40840,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40840,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-40840 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-04-08 22:27:24,b4e95661e416c4cc6b9c2910a89ad9887b3efeb5,1.2
,APPROVED,pandas-dev__pandas-41503,https://github.com/pandas-dev/pandas/pull/41503,"import timeit
import statistics

import importlib
import sys
import pkg_resources
from pandas.plotting._core import _get_plot_backend

dist = pkg_resources.get_distribution(""pandas"")
spec = importlib.machinery.ModuleSpec(""my_backend"", None)
mod = importlib.util.module_from_spec(spec)
mod.plot = lambda *args, **kwargs: 1

backends = pkg_resources.get_entry_map(""pandas"")
my_entrypoint = pkg_resources.EntryPoint(
    ""pandas_plotting_backend"", mod.__name__, dist=dist
)
backends[""pandas_plotting_backends""][mod.__name__] = my_entrypoint
for i in range(1000):
    backends[""pandas_plotting_backends""][str(i)] = my_entrypoint
sys.modules[""my_backend""] = mod 

def workload():
    _get_plot_backend(""my_backend"")
    
runtimes = timeit.repeat(workload, number=5, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 9.82224780949764e-07
Before SD: 0.00018134952851918282
After Mean: 7.013671623426489e-07
After SD: 5.291984738892682e-06
Improvement: -28.59%",,850,docker.io/sweperf/sweperf:pandas-dev__pandas-41503,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41503,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41503 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-05-16 12:02:14,f7dd14bd62e587b6846616844a79a159e0d7e61c,1.2
,APPROVED,pandas-dev__pandas-41567,https://github.com/pandas-dev/pandas/pull/41567,"import timeit
import statistics
import pandas as pd
import numpy as np

def setup():
    global s
    n = 10_000 
    data = np.random.choice(list(""ABCDEabcde12345""), size=(n, 20))
    str_data = ["""".join(row) for row in data]
    s = pd.Series(str_data, dtype=""string"")

def workload():
    global s
    _ = s.str.rpartition(""A"")

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0063248020014725626
Before SD: 0.0007488151748247275
After Mean: 0.004955627390882
After SD: 0.00025000589329711486
Improvement: -21.65%",,91,docker.io/sweperf/sweperf:pandas-dev__pandas-41567,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41567,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41567 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-05-19 12:07:18,bda839c2e76d0c9b5d72f401102183f83641dc88,1.2
,APPROVED,pandas-dev__pandas-41911,https://github.com/pandas-dev/pandas/pull/41911,"
import timeit
import statistics

import pandas as pd

ser = pd.Series([True] * 10**6)

def workload():
    ser.all()
    

runtimes = timeit.repeat(workload, number=5, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0025799721323826815
Before SD: 2.5707293852235737e-05
After Mean: 0.0002059428978653159
After SD: 1.5764421801974635e-05
Improvement: -92.02%",,312,docker.io/sweperf/sweperf:pandas-dev__pandas-41911,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41911,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41911 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-06-09 21:14:30,ce3bac9af43838c7d690ee86e9bec4976a3303e3,1.2
,APPROVED,pandas-dev__pandas-41924,https://github.com/pandas-dev/pandas/pull/41924,"
import timeit
import statistics

import pandas as pd

ser = pd.Series([True] * 10**6)

def workload():
    ser.all()
    

runtimes = timeit.repeat(workload, number=5, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.002578635920479428
Before SD: 2.608494422217566e-05
After Mean: 0.00020269261179491877
After SD: 1.4944897701099635e-05
Improvement: -92.14%",,312,docker.io/sweperf/sweperf:pandas-dev__pandas-41924,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41924,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41924 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-06-10 11:35:06,1739199759f6dd0580a079d6ee96bc4de98ade97,1.2
,APPROVED,pandas-dev__pandas-41972,https://github.com/pandas-dev/pandas/pull/41972,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 6
index = pd.UInt64Index(range(N))
data = pd.Series(np.random.rand(N), index=index)

def workload():
    data.iloc[:800000]
    data.loc[[800000]]

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.10667631139745935
Before SD: 0.0038244940939431214
After Mean: 0.0004656964488094673
After SD: 0.0025579760170164442
Improvement: -99.56%",,851,docker.io/sweperf/sweperf:pandas-dev__pandas-41972,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41972,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-41972 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-06-12 20:08:10,cef3598fb9d60720e3c38fb67636d40c63d2857d,1.2
,APPROVED,pandas-dev__pandas-42197,https://github.com/pandas-dev/pandas/pull/42197,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10**5

left = np.append(np.arange(N), np.array(0))
right = np.append(np.arange(1, N + 1), np.array(1))
intv = pd.IntervalIndex.from_arrays(left, right)

intv2 = pd.IntervalIndex.from_arrays(left + 1, right + 1)

def workload():
    intv.intersection(intv2)
    

runtimes = timeit.repeat(workload, number=5, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.9670383975759614
Before SD: 0.013207062229350936
After Mean: 0.4031494880514219
After SD: 0.010570243812670183
Improvement: -58.31%",,851,docker.io/sweperf/sweperf:pandas-dev__pandas-42197,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42197,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42197 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-06-23 3:38:33,3ce150d2594d9738c5e43139194692151be4f2a8,1.2
,APPROVED,pandas-dev__pandas-42268,https://github.com/pandas-dev/pandas/pull/42268,"
import timeit
import statistics

import pandas as pd
import numpy as np


N = 10 ** 5
left = pd.IntervalIndex.from_breaks(np.arange(N))
right = pd.IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))

def workload():
    left.intersection(right)

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.12521914184326305
Before SD: 0.024722219144198667
After Mean: 0.011851636243518442
After SD: 0.026415319218381833
Improvement: -90.54%",,851,docker.io/sweperf/sweperf:pandas-dev__pandas-42268,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42268,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42268 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-06-27 16:42:14,fa6b96e128ebc23f1f6e49967f2a795f79f81e5b,1.2
,APPROVED,pandas-dev__pandas-42270,https://github.com/pandas-dev/pandas/pull/42270,"
import timeit
import statistics

import pandas as pd
import string, itertools

data_unique = pd.CategoricalIndex(
            ["""".join(perm) for perm in itertools.permutations(string.printable, 3)]
)
cat_list = [""a"", ""c""]

def workload():
    data_unique.get_indexer(cat_list)

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 1.0477123976300937
Before SD: 0.03753603492272728
After Mean: 0.0005731303233187646
After SD: 0.002179530710360013
Improvement: -99.95%",,851,docker.io/sweperf/sweperf:pandas-dev__pandas-42270,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42270,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42270 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-06-27 19:57:46,fa6b96e128ebc23f1f6e49967f2a795f79f81e5b,1.2
,APPROVED,pandas-dev__pandas-42353,https://github.com/pandas-dev/pandas/pull/42353,"import timeit
import statistics

import pandas as pd

dti = pd.date_range('2016-01-01', periods=10**5, freq=""s"")
dti2 = dti.delete(50000)

def workload():
    dti.union(dti2)
    
runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.014802776854485273
Before SD: 0.00039667806537938894
After Mean: 0.01288519440102391
After SD: 0.000391174199459482
Improvement: -12.95%",,14,docker.io/sweperf/sweperf:pandas-dev__pandas-42353,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42353,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42353 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-07-03 3:28:17,5675cd8ab28dd30d554039bb3d8c752aa39cf651,1.3
,APPROVED,pandas-dev__pandas-42486,https://github.com/pandas-dev/pandas/pull/42486,"import timeit
import statistics

import pandas as pd
import numpy as np

rng = np.random.default_rng(0)

data = rng.integers(0, 1000, size=(10000, 10))
df = pd.DataFrame(data)

def workload():
    df.to_dict(orient=""records"") 
    df.to_dict(orient=""split"") 
    df.to_dict(orient=""dict"") 

runtimes = timeit.repeat(workload, number=1, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.7652803873276571
Before SD: 0.0016794152365078349
After Mean: 0.08316006762441247
After SD: 0.000730300002217221
Improvement: -89.13%",,23,docker.io/sweperf/sweperf:pandas-dev__pandas-42486,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42486,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42486 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-07-11 19:09:07,55a03d289fb98403f22d7e6f67b201c8b130fc19,1.3
,APPROVED,pandas-dev__pandas-42611,https://github.com/pandas-dev/pandas/pull/42611,"import timeit
import statistics

import pandas as pd
import numpy as np
import string

try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm


dtype = ""Int32""
N, K = 5000, 50
index = tm.makeStringIndex(N)
columns = tm.makeStringIndex(K)

def create_df(data):
    return pd.DataFrame(data, index=index, columns=columns)

df_string = create_df(
    np.random.choice(list(string.ascii_letters), size=(N, K))
)

def workload():
    df_string.select_dtypes(exclude=dtype)


runtimes = timeit.repeat(workload, number=5, repeat=10**3)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00996616146992892
Before SD: 0.00013551958039503232
After Mean: 0.00015583609971799888
After SD: 5.303885949097171e-06
Improvement: -98.44%",,23,docker.io/sweperf/sweperf:pandas-dev__pandas-42611,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42611,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42611 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-07-19 16:43:50,fa8ccbfde58beb3ff466db02c45ad18508cc9f80,1.3
,APPROVED,pandas-dev__pandas-42631,https://github.com/pandas-dev/pandas/pull/42631,"import timeit
import statistics

import pandas as pd
import numpy as np

N_rows = 1000
N_cols = 1000
float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]
sparse_arrays = [
    pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=""float64"")
    for _ in range(N_cols)
]
int_arrays = [
    pd.array(np.random.randint(1000, size=N_rows), dtype=""Int64"")
    for _ in range(N_cols)
]
index = pd.Index(range(N_rows))
columns = pd.Index(range(N_cols))

def workload():
    pd.DataFrame._from_arrays(
        int_arrays,
        index=index,
        columns=columns,
        verify_integrity=False,
    )
    
runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
    ","Before Mean: 0.02099350629298715
Before SD: 0.00023216448615400955
After Mean: 0.010584020258218516
After SD: 0.00020036988188076063
Improvement: -49.58%",,853,docker.io/sweperf/sweperf:pandas-dev__pandas-42631,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42631,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42631 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-07-20 16:26:31,17f6cbb815c525f9655ce12d44ebf6fb73be0d73,1.3
,APPROVED,pandas-dev__pandas-42704,https://github.com/pandas-dev/pandas/pull/42704,"import timeit
import statistics

import pandas as pd

lev = pd.Index(list(""ABCDEFGHIJ""))
ri = pd.Index(range(1000))
mi = pd.MultiIndex.from_product([lev, ri], names=[""foo"", ""bar""])

index = pd.date_range(""2016-01-01"", periods=10000, freq=""s"", tz=""US/Pacific"")
index = index.tz_localize(None).to_period(""s"")

ser = pd.Series(index, index=mi)
df = ser.unstack(""bar"")

def workload():
    ser.unstack(""bar"")
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.07192182071181014
Before SD: 0.0006108065232091353
After Mean: 0.0370696422427427
After SD: 0.00034429278582397593
Improvement: -48.46%",,19,docker.io/sweperf/sweperf:pandas-dev__pandas-42704,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42704,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42704 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-07-25 1:47:47,c1aea793e03f11b587fbda833b2f5ad06c4bbced,1.3
,APPROVED,pandas-dev__pandas-42714,https://github.com/pandas-dev/pandas/pull/42714,"import timeit
import statistics

import itertools
import pandas as pd
import numpy as np

N = 10 ** 7

dtypes = [""Int64"", ""Float64""]
max_number = [5, 1000]
series_types = [""random_hits"", ""random_misses"", ""monotone_hits"", ""monotone_misses""]


sv_pairs = []

for dtype, max_num, series_type in itertools.product(dtypes, max_number, series_types):
    if series_type == ""random_hits"":
        array = np.random.randint(0, max_num, N)
    if series_type == ""random_misses"":
        array = np.random.randint(0, max_num, N) + max_num
    if series_type == ""monotone_hits"":
        array = np.repeat(np.arange(max_num), N // max_num)
    if series_type == ""monotone_misses"":
        array = np.arange(N) + max_num

    sv_pairs.append(
        (pd.Series(array).astype(dtype), np.arange(max_num).astype(dtype.lower()))
    )

def workload():
    for series, values in sv_pairs:
        series.isin(values)

runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 5.000184761602432
Before SD: 0.01967770078874298
After Mean: 1.216502236004453
After SD: 0.00414671997599092
Improvement: -75.67%",,1,docker.io/sweperf/sweperf:pandas-dev__pandas-42714,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42714,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42714 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-07-25 19:08:47,daec2e73b48fe34086dcdeeb0858d29536b6ca6a,1.3
,APPROVED,pandas-dev__pandas-42841,https://github.com/pandas-dev/pandas/pull/42841,"import timeit
import statistics

import pandas as pd
import numpy as np

methods = [""any"", ""all""]

ngroups = 1000
ncols = 10
size = ngroups * 2
rng = np.arange(ngroups).reshape(-1, 1)
rng = np.broadcast_to(rng, (len(rng), ncols))
taker = np.random.randint(0, ngroups, size=size)
values = rng.take(taker, axis=0)
key = np.concatenate(
    [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]
)

cols = [f""values{n}"" for n in range(ncols)]
df = pd.DataFrame(values, columns=cols)
df[""key""] = key

def workload():
    for method in methods:
        df.groupby(""key"")[cols].transform(method)
        getattr(df.groupby(""key"")[cols], method)

runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.021944661037239712
Before SD: 0.0002597048817873614
After Mean: 0.012127154016518035
After SD: 0.00019524988632500171
Improvement: -44.74%",,861,docker.io/sweperf/sweperf:pandas-dev__pandas-42841,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42841,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42841 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-01 15:24:08,098661e8773dc2026f89ec39ca87625c2fb870dd,1.3
,APPROVED,pandas-dev__pandas-42998,https://github.com/pandas-dev/pandas/pull/42998,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 3
df = pd.DataFrame(index=range(N))
df2 = pd.DataFrame(np.random.randn(N, 2))

def workload():
    for i in range(100):
        df.insert(0, i, np.random.randn(N), allow_duplicates=True)
        df2.insert(
            1, ""colname"", np.random.randn(N), allow_duplicates=True
        )

runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.35518137423088775
Before SD: 0.19094629190505255
After Mean: 0.12828234676271677
After SD: 0.062202663645714425
Improvement: -63.88%",,861,docker.io/sweperf/sweperf:pandas-dev__pandas-42998,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42998,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-42998 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-12 18:03:26,e86bba67da5a3baf2f7ed7deb45318a085f892a0,1.3
,APPROVED,pandas-dev__pandas-43010,https://github.com/pandas-dev/pandas/pull/43010,"import timeit
import statistics

import pandas as pd
import numpy as np

s = pd.Series(np.random.randn(100000)).astype(""int"")
s_func = getattr(s, ""mad"")

def workload():
    s_func()
    
runtimes = timeit.repeat(workload, number=5, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.01028371739666909
Before SD: 0.0007053853035386481
After Mean: 0.005289038800401613
After SD: 0.00021358834097743944
Improvement: -48.57%",,10,docker.io/sweperf/sweperf:pandas-dev__pandas-43010,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43010,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43010 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-13 2:06:57,6fd01648b6d14b24690b85f993b193699df12439,1.3
,APPROVED,pandas-dev__pandas-43052,https://github.com/pandas-dev/pandas/pull/43052,"
import timeit
import statistics

import pandas as pd
import numpy as np

constructor_options = [pd.DataFrame, pd.Series]
window_options = [10, 1000]
dtype_options = [""int"", ""float""]
method = ""mean""

N = 10 ** 5

ewm_options = []
for constructor in constructor_options:
    for window in window_options:
        for dtype in dtype_options:
            arr = (100 * np.random.random(N)).astype(dtype)
            times = pd.date_range(""1900"", periods=N, freq=""23s"")
            ewm = constructor(arr).ewm(halflife=window)
            ewm_options.append(ewm)
            
def workload():
    for ewm in ewm_options:
        ewm.mean()

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.021013208153308368
Before SD: 0.000602988673597654
After Mean: 0.0133949176419992
After SD: 0.0005128845439907524
Improvement: -36.25%",,860,docker.io/sweperf/sweperf:pandas-dev__pandas-43052,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43052,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43052 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-15 14:34:05,0d46c238e7ec92363152270f444bc0cb251919b7,1.3
,APPROVED,pandas-dev__pandas-43059,https://github.com/pandas-dev/pandas/pull/43059,"
import timeit
import statistics

import pandas as pd
import numpy as np
import tempfile
import os

try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm


N = 100_000
C = 5

temp_path = tempfile.NamedTemporaryFile(suffix="".dta"", delete=False).name


df = pd.DataFrame(
    np.random.randn(N, C),
    columns=[f""float{i}"" for i in range(C)],
    index=pd.date_range(""20000101"", periods=N, freq=""H""),
)
df[""object""] = tm.makeStringIndex(N)
df[""int8_""] = np.random.randint(np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N)
df[""int16_""] = np.random.randint(np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N)
df[""int32_""] = np.random.randint(np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N)
df[""float32_""] = np.array(np.random.randn(N), dtype=np.float32)

for i in range(10):
    missing_data = np.random.randn(N)
    missing_data[missing_data < 0] = np.nan
    df[f""missing_{i}""] = missing_data

convert_dates_arg = {""index"": ""tc""}
df.to_stata(temp_path, convert_dates=convert_dates_arg)


def workload():
    pd.read_stata(temp_path)


runtimes = timeit.repeat(workload, number=5, repeat=25)

os.remove(temp_path)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.564224630240351
Before SD: 0.012535148059919106
After Mean: 0.4129073414299637
After SD: 0.010098808112779077
Improvement: -26.82%",,4,docker.io/sweperf/sweperf:pandas-dev__pandas-43059,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43059,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43059 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-15 19:42:59,e7d9057f2bd2757219b1cb21f5380b15e7a0f018,1.3
,APPROVED,pandas-dev__pandas-43073,https://github.com/pandas-dev/pandas/pull/43073,"import timeit
import statistics

import pandas as pd
import numpy as np

dfs = []

for factor in [4, 5]:
    N = 10 ** factor
    labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)
    labels2 = np.random.randint(0, 3, size=N)
    df = pd.DataFrame(
        {
            ""key"": labels,
            ""key2"": labels2,
            ""value1"": np.random.randn(N),
            ""value2"": [""foo"", ""bar"", ""baz"", ""qux""] * (N // 4),
        }
    )
    dfs.append(df)

def df_copy_function(g):
    g.name
    return g.copy()

def workload():
    for df in dfs:
        df.groupby(""key"").apply(df_copy_function)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.19746765658201185
Before SD: 0.0026022609502794917
After Mean: 0.17925381435721646
After SD: 0.0022737850022533676
Improvement: -9.22%",,860,docker.io/sweperf/sweperf:pandas-dev__pandas-43073,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43073,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43073 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-17 1:18:07,bc16631b0580902315c4c08926e739b86c6c65ab,1.3
,APPROVED,pandas-dev__pandas-43160,https://github.com/pandas-dev/pandas/pull/43160,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10000
M = 10
df_tall = pd.DataFrame(np.random.randn(N, M))
df_mixed_tall = df_tall.copy()
df_mixed_tall[""foo""] = ""bar""
df_mixed_tall[0] = pd.period_range(""2000"", periods=N)
df_mixed_tall[1] = range(N)

def workload():
    df_mixed_tall.to_numpy()

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.0684369242907269
Before SD: 0.0004804135454135875
After Mean: 0.046565644218353554
After SD: 0.0007510260417156819
Improvement: -31.96%",,181,docker.io/sweperf/sweperf:pandas-dev__pandas-43160,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43160,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43160 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-22 4:02:07,8814de9fbc7d53c6db201eab717fd3d6b607654b,1.3
,APPROVED,pandas-dev__pandas-43171,https://github.com/pandas-dev/pandas/pull/43171,"import timeit
import statistics

import numpy as np
import pandas as pd

N = 10 ** 3
arr = (100 * np.random.random(N)).astype(""float"")
data = pd.DataFrame(arr)

methods = [""sum"", ""max"", ""min"", ""median"", ""mean""]

def workload():
    for method in methods:
        getattr(data.rolling(10), method)(engine=""cython"")

runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.005873805875366088
Before SD: 0.00011604092473463784
After Mean: 0.00457743578456575
After SD: 9.19387572333655e-05
Improvement: -22.07%",,22,docker.io/sweperf/sweperf:pandas-dev__pandas-43171,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43171,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43171 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-22 23:15:14,8814de9fbc7d53c6db201eab717fd3d6b607654b,1.3
,APPROVED,pandas-dev__pandas-43237,https://github.com/pandas-dev/pandas/pull/43237,"import timeit
import statistics

import pandas as pd
import numpy as np

try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm

N, K = 5000, 50

# arrays which we wont consolidate
dict_of_categoricals = {i: pd.Categorical(np.arange(N)) for i in range(K)}

def workload():
    pd.DataFrame(dict_of_categoricals)

runtimes = timeit.repeat(workload, number=1, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0010034468883823137
Before SD: 3.4761910116621994e-05
After Mean: 0.0003954225778579712
After SD: 2.1013052341723106e-05
Improvement: -60.59%",,479,docker.io/sweperf/sweperf:pandas-dev__pandas-43237,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43237,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43237 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-26 17:02:57,f346574c8bb8921664f6d47d2e4b0f1252e181b9,1.3
,APPROVED,pandas-dev__pandas-43243,https://github.com/pandas-dev/pandas/pull/43243,"import timeit
import statistics

import pandas as pd
import numpy as np

ngroups = 1000
ncols = 2
size = ngroups * 2
rng = np.arange(ngroups).reshape(-1, 1)
rng = np.broadcast_to(rng, (len(rng), ncols))
taker = np.random.randint(0, ngroups, size=size)
values = rng.take(taker, axis=0)
key = np.random.randint(0, size, size=size)

cols = [f""values{n}"" for n in range(ncols)]
df = pd.DataFrame(values, columns=cols)
df[""key""] = key

def workload():
    df.groupby(""key"")[cols].skew()

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.5107752308039926
Before SD: 0.009249994934099916
After Mean: 1.30028372539673
After SD: 0.011745428149390481
Improvement: -13.93%",,93,docker.io/sweperf/sweperf:pandas-dev__pandas-43243,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43243,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43243 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-27 2:53:03,15302106ef41e562d2f80c6d1ecffdd4aea7158a,1.3
,APPROVED,pandas-dev__pandas-43274,https://github.com/pandas-dev/pandas/pull/43274,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 3
df = pd.DataFrame(index=range(N))
df2 = pd.DataFrame(np.random.randn(N, 2))

def workload():
    for i in range(100):
        df[i] = np.random.randn(N)

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.06206720650527859
Before SD: 0.0004946437304390809
After Mean: 0.01998406095581595
After SD: 0.0003529682868123727
Improvement: -67.80%",,207,docker.io/sweperf/sweperf:pandas-dev__pandas-43274,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43274,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43274 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-28 18:07:09,2b3a9b160337e5a5c58fc9a562352be216e6584c,1.3
,APPROVED,pandas-dev__pandas-43277,https://github.com/pandas-dev/pandas/pull/43277,"
import timeit
import statistics

import pandas as pd
import numpy as np
import tempfile
import os

try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm


N = 100_000
C = 5

temp_path = tempfile.NamedTemporaryFile(suffix="".dta"", delete=False).name


df = pd.DataFrame(
    np.random.randn(N, C),
    columns=[f""float{i}"" for i in range(C)],
    index=pd.date_range(""20000101"", periods=N, freq=""H""),
)
df[""object""] = tm.makeStringIndex(N)
df[""int8_""] = np.random.randint(np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N)
df[""int16_""] = np.random.randint(np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N)
df[""int32_""] = np.random.randint(np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N)
df[""float32_""] = np.array(np.random.randn(N), dtype=np.float32)

for i in range(10):
    missing_data = np.random.randn(N)
    missing_data[missing_data < 0] = np.nan
    df[f""missing_{i}""] = missing_data

convert_dates_arg = {""index"": ""tc""}
df.to_stata(temp_path, convert_dates=convert_dates_arg)


def workload():
    pd.read_stata(temp_path)


runtimes = timeit.repeat(workload, number=5, repeat=25)

os.remove(temp_path)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.43800539323827253
Before SD: 0.009541841681291538
After Mean: 0.3888973888754845
After SD: 0.007392008095205523
Improvement: -11.21%",,860,docker.io/sweperf/sweperf:pandas-dev__pandas-43277,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43277,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43277 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-28 18:51:27,2b3a9b160337e5a5c58fc9a562352be216e6584c,1.3
,APPROVED,pandas-dev__pandas-43281,https://github.com/pandas-dev/pandas/pull/43281,"
        
import timeit
import statistics

import pandas as pd
import numpy as np

import operator

arr = np.arange(10 ** 6).reshape(1000, -1)
df = pd.DataFrame(arr)
df[""C""] = 1.0
df = df
ser = df[0]
row = df.iloc[0]
        
def workload():
    operator.floordiv(df, ser)

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.17714313463540748
Before SD: 0.0017951502118152818
After Mean: 0.14990049400134012
After SD: 0.0021659492228021594
Improvement: -15.38%",,17,docker.io/sweperf/sweperf:pandas-dev__pandas-43281,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43281,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43281 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-29 3:39:09,e39ea3024cebb4e7a7fd35972a44637de6c41650,1.3
,APPROVED,pandas-dev__pandas-43285,https://github.com/pandas-dev/pandas/pull/43285,"import timeit
import statistics

import pandas as pd
import numpy as np

cols = 36
rows = 12

def _apply_func(s):
    return [
        ""background-color: lightcyan"" if s.name == ""row_1"" else """" for v in s
    ]

def initialize():
    df = pd.DataFrame(
        np.random.randn(rows, cols),
        columns=[f""float_{i+1}"" for i in range(cols)],
        index=[f""row_{i+1}"" for i in range(rows)],
    )
    st = df.style.apply(_apply_func, axis=1)
    return st

initialize()

def workload():
    st = initialize()
    st._render_html(True, True)

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.1053342736302875
Before SD: 0.001727993293803873
After Mean: 0.03790910643991083
After SD: 0.000685693373732678
Improvement: -64.01%",,10,docker.io/sweperf/sweperf:pandas-dev__pandas-43285,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43285,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43285 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-29 14:35:11,beb7c48283d85f2c126f4685cac2538683030f5a,1.3
,APPROVED,pandas-dev__pandas-43287,https://github.com/pandas-dev/pandas/pull/43287,"import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randn(10000, 1))

def workload():
    df.style.applymap_index(lambda v: ""color: blue;"")._compute()

runtimes = timeit.repeat(workload, number=5, repeat=200)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.09308751470758579
Before SD: 0.029403369937138435
After Mean: 0.07804096015897813
After SD: 0.019045714397582642
Improvement: -16.16%",,10,docker.io/sweperf/sweperf:pandas-dev__pandas-43287,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43287,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43287 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-29 17:07:11,9bf09adcdab1a5babaed9f3315f2572cebf9f1f2,1.3
,APPROVED,pandas-dev__pandas-43307,https://github.com/pandas-dev/pandas/pull/43307,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 100000
data = np.random.randn(N)

def workload():
    df = pd.DataFrame(data)

runtimes = timeit.repeat(workload, number=1, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.7658117768587544e-05
Before SD: 4.929053730611008e-06
After Mean: 1.900799728173297e-05
After SD: 3.913145242272411e-06
Improvement: -31.28%",,501,docker.io/sweperf/sweperf:pandas-dev__pandas-43307,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43307,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43307 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-30 18:34:41,375267f72c2af6e3bfe13493e442f9f50e50dba2,1.3
,APPROVED,pandas-dev__pandas-43308,https://github.com/pandas-dev/pandas/pull/43308,"import timeit
import statistics

import pandas as pd
import numpy as np

rng = pd.period_range(start=""1/1/1990"", freq=""S"", periods=20000)
df = pd.DataFrame(index=range(len(rng)))

def workload():
    df[""col""] = rng

runtimes = timeit.repeat(workload, number=5, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00017603331606369467
Before SD: 8.750496554461426e-06
After Mean: 9.048374116246123e-05
After SD: 6.8236635797029185e-06
Improvement: -48.60%",,861,docker.io/sweperf/sweperf:pandas-dev__pandas-43308,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43308,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43308 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-30 20:16:05,9a81226bb3d75516cccae407cf87797580c30a5f,1.3
,APPROVED,pandas-dev__pandas-43316,https://github.com/pandas-dev/pandas/pull/43316,"import timeit
import statistics

import pandas as pd
import numpy as np

N, M = 10000, 100
dtype = 'object'
values = np.random.randn(N, M)
values[::2] = np.nan
if dtype == ""Int64"":
    values = values.round()
df = pd.DataFrame(values, dtype=dtype)

def workload():
    df.fillna(inplace=False, method='pad')

runtimes = timeit.repeat(workload, number=1, repeat=50)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.10992075363872572
Before SD: 0.0028083694422007767
After Mean: 0.09845505479141138
After SD: 0.0016274527150159617
Improvement: -10.43%",,25,docker.io/sweperf/sweperf:pandas-dev__pandas-43316,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43316,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43316 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-31 1:29:17,08ac29ab685d5e488a5b122944f8ee2f5000b6c9,1.3
,APPROVED,pandas-dev__pandas-43332,https://github.com/pandas-dev/pandas/pull/43332,"import timeit
import statistics

import pandas as pd
import numpy as np

try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm

N = 10000
indices = tm.makeStringIndex(N).values
indices2 = tm.makeStringIndex(N).values
key = np.tile(indices[:8000], 10)
key2 = np.tile(indices2[:8000], 10)
left = pd.DataFrame(
    {""key"": key, ""key2"": key2, ""value"": np.random.randn(80000)}
)
right = pd.DataFrame(
    {
        ""key"": indices[2000:],
        ""key2"": indices2[2000:],
        ""value2"": np.random.randn(8000),
    }
)

df = pd.DataFrame(
    {
        ""key1"": np.tile(np.arange(500).repeat(10), 2),
        ""key2"": np.tile(np.arange(250).repeat(10), 4),
        ""value"": np.random.randn(10000),
    }
)
df2 = pd.DataFrame({""key1"": np.arange(500), ""value2"": np.random.randn(500)})
df3 = df[:5000]

def workload():
    pd.merge(left.loc[:2000], right.loc[:2000], how=""cross"", sort=False)
    pd.merge(left.loc[:2000], right.loc[:2000], how=""cross"", sort=True)

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 5.6540344303316665
Before SD: 0.0424491914910699
After Mean: 2.0035718812572303
After SD: 0.014920882140757154
Improvement: -64.56%",,27,docker.io/sweperf/sweperf:pandas-dev__pandas-43332,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43332,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43332 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-31 18:07:18,a826be1f616bdca3a028085b3d6f9e54c1d959cf,1.3
,APPROVED,pandas-dev__pandas-43335,https://github.com/pandas-dev/pandas/pull/43335,"import timeit
import statistics

import pandas as pd

lev = pd.Index(list(""ABCDEFGHIJ""))
ri = pd.Index(range(1000))
mi = pd.MultiIndex.from_product([lev, ri], names=[""foo"", ""bar""])

index = pd.date_range(""2016-01-01"", periods=10000, freq=""s"", tz=""US/Pacific"")
index = index.tz_localize(None).to_period(""s"")

ser = pd.Series(index, index=mi)
df = ser.unstack(""bar"")

def workload():
    ser.unstack(""bar"")
    
runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.03059952493297169
Before SD: 0.0003367724117124002
After Mean: 0.014007007650157902
After SD: 0.00020941901558851092
Improvement: -54.22%",,861,docker.io/sweperf/sweperf:pandas-dev__pandas-43335,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43335,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43335 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-08-31 21:16:46,58059c152ccf8a714eb3233f13ed22987eb42b44,1.3
,APPROVED,pandas-dev__pandas-43352,https://github.com/pandas-dev/pandas/pull/43352,"import timeit
import statistics

import numpy as np
import pandas as pd
import string

m = 100
n = 50

levels = np.arange(m)
index = pd.MultiIndex.from_product([levels] * 2)
columns = np.arange(n)

indices = np.random.randint(0, 52, size=(m * m, n))
values = np.take(list(string.ascii_letters), indices)
values = [pd.Categorical(v) for v in values.T]

df = pd.DataFrame(
    {i: cat for i, cat in enumerate(values)}, index, columns
)

def workload():
    df.unstack()

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.09917194766481408
Before SD: 0.0007107482991255003
After Mean: 0.06273866725573317
After SD: 0.00042787780466298274
Improvement: -36.74%",,56,docker.io/sweperf/sweperf:pandas-dev__pandas-43352,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43352,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43352 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-01 21:13:13,62c12cf09cdd77b35d404667d859fd90190aeb70,1.3
,APPROVED,pandas-dev__pandas-43353,https://github.com/pandas-dev/pandas/pull/43353,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 4

labels = np.random.randint(0, 2000, size=N)
labels2 = np.random.randint(0, 3, size=N)
df = pd.DataFrame(
    {
        ""key"": labels,
        ""key2"": labels2,
        ""value1"": np.random.randn(N),
        ""value2"": [""foo"", ""bar"", ""baz"", ""qux""] * (N // 4),
    }
)

def df_copy_function(g):
    # ensure that the group name is available (see GH #15062)
    g.name
    return g.copy()

def workload():
    df.groupby(""key"").apply(df_copy_function)

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.17431380695430562
Before SD: 0.001599227341367289
After Mean: 0.15214204700663686
After SD: 0.0023787678250227905
Improvement: -12.72%",,861,docker.io/sweperf/sweperf:pandas-dev__pandas-43353,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43353,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43353 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-01 21:46:33,62c12cf09cdd77b35d404667d859fd90190aeb70,1.3
,APPROVED,pandas-dev__pandas-43354,https://github.com/pandas-dev/pandas/pull/43354,"import timeit
import statistics

import pandas as pd
import numpy as np

factor = 4

N = 10 ** factor
labels = np.random.randint(0, 2000, size=N)
labels2 = np.random.randint(0, 3, size=N)
df = pd.DataFrame(
    {
        ""key"": labels,
        ""key2"": labels2,
        ""value1"": np.random.randn(N),
        ""value2"": [""foo"", ""bar"", ""baz"", ""qux""] * (N // 4),
    }
)

def df_copy_function(g):
    g.name
    return g.copy()

def workload():
    df.groupby(""key"").apply(df_copy_function)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.15435937214060685
Before SD: 0.002063020756484092
After Mean: 0.13489753590256442
After SD: 0.0016231655038152545
Improvement: -12.61%",,861,docker.io/sweperf/sweperf:pandas-dev__pandas-43354,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43354,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43354 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-02 2:34:11,58059c152ccf8a714eb3233f13ed22987eb42b44,1.3
,APPROVED,pandas-dev__pandas-43370,https://github.com/pandas-dev/pandas/pull/43370,"import timeit
import statistics

import pandas as pd
import numpy as np


mi = pd.MultiIndex.from_product([range(100), range(100), range(100)])

def workload():
    mi.get_indexer(mi[:-1])

runtimes = timeit.repeat(workload, number=5, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.1077647393068766
Before SD: 0.020991677617130257
After Mean: 0.6675120756815887
After SD: 0.010154123873909746
Improvement: -78.52%",,861,docker.io/sweperf/sweperf:pandas-dev__pandas-43370,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43370,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43370 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-02 22:02:06,58059c152ccf8a714eb3233f13ed22987eb42b44,1.3
,APPROVED,pandas-dev__pandas-43510,https://github.com/pandas-dev/pandas/pull/43510,"

import timeit
import statistics

import pandas as pd
import numpy as np

arr = np.random.randn(10 ** 5, 100)
df = pd.DataFrame(arr)
gb = df.groupby(df.index % 3)

def workload():
    gb.quantile(0.5)

runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.4672352844430134
Before SD: 0.020066789507113394
After Mean: 1.375895710531622
After SD: 0.00508712405211875
Improvement: -6.23%",,862,docker.io/sweperf/sweperf:pandas-dev__pandas-43510,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43510,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43510 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-11 4:43:14,5f36af325c276454201495eaf66be55bd17964a5,1.3
,APPROVED,pandas-dev__pandas-43518,https://github.com/pandas-dev/pandas/pull/43518,"import timeit
import statistics

import pandas as pd
import numpy as np

np.random.seed(23446365)
arr = np.random.randn(10**5, 10)
mask = arr < -1
arr[mask] = np.nan

df = pd.DataFrame(arr)

gb = df.groupby(df.index % 7)

def workload():
    gb.pad()

runtimes = timeit.repeat(workload, number=5, repeat=500)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.11836241742456331
Before SD: 0.0006128174455462109
After Mean: 0.056466332718380724
After SD: 0.0006155890240724968
Improvement: -52.29%",,862,docker.io/sweperf/sweperf:pandas-dev__pandas-43518,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43518,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43518 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-11 19:25:00,f525864349e89240fbab1fd0d5887bb506a61e73,1.3
,APPROVED,pandas-dev__pandas-43524,https://github.com/pandas-dev/pandas/pull/43524,"import timeit
import statistics

import pandas as pd
import numpy as np

factor = 4

N = 10 ** factor
labels = np.random.randint(0, 2000, size=N)
labels2 = np.random.randint(0, 3, size=N)
df = pd.DataFrame(
    {
        ""key"": labels,
        ""key2"": labels2,
        ""value1"": np.random.randn(N),
        ""value2"": [""foo"", ""bar"", ""baz"", ""qux""] * (N // 4),
    }
)

def df_copy_function(g):
    g.name
    return g.copy()

def workload():
    df.groupby([""key"", ""key2""]).apply(df_copy_function)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.3544186213618377
Before SD: 0.003749990686030018
After Mean: 0.32310515280172697
After SD: 0.004592626430779084
Improvement: -8.84%",,445,docker.io/sweperf/sweperf:pandas-dev__pandas-43524,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43524,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43524 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-11 23:06:05,415dec58354cf20a11e1dbd8726757a38d167b4d,1.3
,APPROVED,pandas-dev__pandas-43558,https://github.com/pandas-dev/pandas/pull/43558,"import timeit
import statistics

import pandas as pd

ser = pd.Series(range(5))

def workload():
    ser.to_frame()
    
runtimes = timeit.repeat(workload, number=5, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00011638761109265033
Before SD: 6.5378184382952465e-06
After Mean: 3.997690820135176e-05
After SD: 9.198167583824898e-06
Improvement: -65.65%",,125,docker.io/sweperf/sweperf:pandas-dev__pandas-43558,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43558,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43558 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-13 23:36:14,e9d0a58c4152a16153dfb330164991d37fdd02dc,1.3
,APPROVED,pandas-dev__pandas-43578,https://github.com/pandas-dev/pandas/pull/43578,"import timeit
import statistics

import pandas as pd
import numpy as np

factor = 4

N = 10 ** factor
labels = np.random.randint(0, 2000, size=N)
labels2 = np.random.randint(0, 3, size=N)
df = pd.DataFrame(
    {
        ""key"": labels,
        ""key2"": labels2,
        ""value1"": np.random.randn(N),
        ""value2"": [""foo"", ""bar"", ""baz"", ""qux""] * (N // 4),
    }
)

def df_copy_function(g):
    g.name
    return g.copy()

def workload():
    df.groupby([""key"", ""key2""]).apply(df_copy_function)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.29562477362749634
Before SD: 0.0035466626965527004
After Mean: 0.23496380992699414
After SD: 0.0038546587235063763
Improvement: -20.52%",,863,docker.io/sweperf/sweperf:pandas-dev__pandas-43578,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43578,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43578 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-15 3:48:17,084c543bf9e70ed4f2ce1d4115b9959f7ae0c396,1.3
,APPROVED,pandas-dev__pandas-43589,https://github.com/pandas-dev/pandas/pull/43589,"import timeit
import statistics

from dateutil import tz
import pandas as pd
from time import time

dates = pd.date_range('2010-01-01', periods=1000, tz=tz.tzutc())
index = pd.MultiIndex.from_product([range(100), dates])
index2 = index.copy()

def workload():
    index.equals(index2)
    
runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.9063532489561476
Before SD: 0.002772171526347378
After Mean: 0.011759725958108902
After SD: 0.0002591138512938981
Improvement: -98.70%",,171,docker.io/sweperf/sweperf:pandas-dev__pandas-43589,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43589,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43589 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-15 20:43:55,eb643d7dcc71b9d6b85f8a2585d7c99908c1f104,1.3
,APPROVED,pandas-dev__pandas-43623,https://github.com/pandas-dev/pandas/pull/43623,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 100000
data = np.random.randn(N)

def workload():
    df = pd.DataFrame(data)

runtimes = timeit.repeat(workload, number=1, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.0508025551098398e-05
Before SD: 4.0418127524571865e-06
After Mean: 1.2466490003862419e-05
After SD: 3.7636563677979286e-06
Improvement: -39.21%",,863,docker.io/sweperf/sweperf:pandas-dev__pandas-43623,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43623,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43623 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-17 19:33:49,26064f0f7ea01607a85b399ee4f3de29a864f338,1.3
,APPROVED,pandas-dev__pandas-43634,https://github.com/pandas-dev/pandas/pull/43634,"import timeit
import statistics

import numpy as np
import pandas as pd

cols = list('abcdefghjkl')
df = pd.DataFrame(np.random.randint(0, 100, size=(100, len(cols))), columns=cols)
df_str = df.astype(str)
df_string = df.astype('string')

def workload():
    df_string.groupby('a')[cols[1:]].last()
    
runtimes = timeit.repeat(workload, number=1, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.022126045993296428
Before SD: 0.0003208783503529931
After Mean: 0.001615385160781443
After SD: 8.581266712914741e-05
Improvement: -92.70%",,863,docker.io/sweperf/sweperf:pandas-dev__pandas-43634,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43634,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43634 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-18 9:24:34,f3d481759a970d35cfc530038fc6ad58f69016cb,1.3
,APPROVED,pandas-dev__pandas-43675,https://github.com/pandas-dev/pandas/pull/43675,"import timeit
import statistics

import pandas as pd
import numpy as np

ngroups = 1000
ncols = 10
size = ngroups * 2
rng = np.arange(ngroups).reshape(-1, 1)
rng = np.broadcast_to(rng, (len(rng), ncols))
taker = np.random.randint(0, ngroups, size=size)
values = rng.take(taker, axis=0)
key = [""foo""] * size

cols = [f""values{n}"" for n in range(ncols)]
df = pd.DataFrame(values, columns=cols)
df[""key""] = key

def workload():
    df.groupby(cols)[""key""].any()

runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.044992057686147745
Before SD: 0.00037403684860871987
After Mean: 0.013988416784035508
After SD: 0.00018943019626555823
Improvement: -68.91%",,10,docker.io/sweperf/sweperf:pandas-dev__pandas-43675,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43675,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43675 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-20 22:58:46,ae049aea7b83a63dddad42fae486e44e827025be,1.3
,APPROVED,pandas-dev__pandas-43683,https://github.com/pandas-dev/pandas/pull/43683,"import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randn(10000, 1000))
df.iloc[50:1000, 20:50] = np.nan
df.iloc[2000:3000] = np.nan
df.iloc[:, 60:70] = np.nan

def workload():
    df.dropna(how='all', axis=0)

runtimes = timeit.repeat(workload, number=5, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.4898276049591368
Before SD: 0.002031492326533317
After Mean: 0.1643403661233606
After SD: 0.00187849994873455
Improvement: -66.45%",,863,docker.io/sweperf/sweperf:pandas-dev__pandas-43683,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43683,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43683 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-21 17:24:45,439acc99b2968ec8062eee05af7346acea20915b,1.3
,APPROVED,pandas-dev__pandas-43694,https://github.com/pandas-dev/pandas/pull/43694,"import timeit
import statistics

import pandas as pd
import numpy as np

ngroups = 1000
ncols = 5
size = ngroups * 2
rng = np.arange(ngroups).reshape(-1, 1)
rng = np.broadcast_to(rng, (len(rng), ncols))
taker = np.random.randint(0, ngroups, size=size)
values = rng.take(taker, axis=0)
key = np.random.randint(0, size, size=size, dtype='uint')

cols = [f""values{n}"" for n in range(ncols)]
df = pd.DataFrame(values, columns=cols)
df[""key""] = key

def workload():
    df.groupby(cols)[""key""].count()

runtimes = timeit.repeat(workload, number=5, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.006720843915455043
Before SD: 8.322413250274477e-05
After Mean: 0.005980102698522387
After SD: 8.011221801232099e-05
Improvement: -11.02%",,863,docker.io/sweperf/sweperf:pandas-dev__pandas-43694,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43694,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43694 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-21 23:47:46,aad2cba39cdade7a02388362ef63987ffee399ea,1.3
,APPROVED,pandas-dev__pandas-43696,https://github.com/pandas-dev/pandas/pull/43696,"import timeit
import statistics

import pandas as pd
import numpy as np

s = pd.Series(np.random.randint(1, 10, 100000))

def workload():
    s.nsmallest(3, keep='last')

runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.04402516884356737
Before SD: 0.0004932649807016518
After Mean: 0.00931086652597878
After SD: 0.0012647778454767762
Improvement: -78.85%",,106,docker.io/sweperf/sweperf:pandas-dev__pandas-43696,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43696,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43696 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-22 3:49:33,9a21c3c6d353042efa04f5f0e1380bf082a97aaa,1.3
,APPROVED,pandas-dev__pandas-43725,https://github.com/pandas-dev/pandas/pull/43725,"import timeit
import statistics

import pandas as pd
import numpy as np

ngroups = 1000
ncols = 1
size = ngroups * 2
rng = np.arange(ngroups).reshape(-1, 1)
rng = np.broadcast_to(rng, (len(rng), ncols))
taker = np.random.randint(0, ngroups, size=size)
values = rng.take(taker, axis=0)
key = np.random.randint(0, size, size=size, dtype='uint')

cols = [f""values{n}"" for n in range(ncols)]
df = pd.DataFrame(values, columns=cols)
df[""key""] = key

def workload():
    df.groupby(""key"")[cols].quantile()

runtimes = timeit.repeat(workload, number=5, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.008482635597197804
Before SD: 9.194856138628264e-05
After Mean: 0.005309335768723395
After SD: 8.179651549502454e-05
Improvement: -37.41%",,863,docker.io/sweperf/sweperf:pandas-dev__pandas-43725,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43725,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43725 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-23 19:50:06,b3e9ae715ab908a9735401d8164da505a293d3c6,1.3
,APPROVED,pandas-dev__pandas-43737,https://github.com/pandas-dev/pandas/pull/43737,"import timeit
import statistics

import pandas as pd
import numpy as np

cols = 24
rows = 120

df = pd.DataFrame(
    np.random.randn(rows, cols),
    columns=[f""float_{i+1}"" for i in range(cols)],
    index=[f""row_{i+1}"" for i in range(rows)],
)

def workload():
    ttips = pd.DataFrame(""abc"", index=df.index[::2], columns=df.columns[::2])
    st = df.style.set_tooltips(ttips)
    st.hide_index(st.index[12:])
    st.hide_columns(st.columns[12:])
    st._render_html(True, True)

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.38933681399328635
Before SD: 0.08381722276732702
After Mean: 0.33304644683841617
After SD: 0.054170085546546766
Improvement: -14.46%",,7,docker.io/sweperf/sweperf:pandas-dev__pandas-43737,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43737,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43737 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-25 11:07:44,cd13e3a42d03f2c3f93b1de3e04352d01aac2241,1.3
,APPROVED,pandas-dev__pandas-43760,https://github.com/pandas-dev/pandas/pull/43760,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 500_000
dtype = 'int64'

def initialize():
    vals = np.random.randint(-10, 10, (N, 5))
    null_vals = vals.astype(float, copy=True)
    null_vals[::2, :] = np.nan
    null_vals[::3, :] = np.nan
    df = pd.DataFrame(vals, columns=list(""abcde""), dtype=dtype)
    keys = np.random.randint(0, 100, size=N)
    df[""key""] = keys
    return df

def workload():
    df = initialize()
    df.groupby(""key"").transform('cumsum')

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.3812197122676298
Before SD: 0.006386847553503294
After Mean: 0.29302520556142553
After SD: 0.0027671366743336496
Improvement: -23.13%",,863,docker.io/sweperf/sweperf:pandas-dev__pandas-43760,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43760,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43760 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-26 21:07:45,5d21d1350aacfa44d83969395d1bc6feb1fccbd4,1.3
,APPROVED,pandas-dev__pandas-43823,https://github.com/pandas-dev/pandas/pull/43823,"
import timeit
import statistics

import pandas as pd
import numpy as np

dti = pd.date_range(""2016-01-01"", periods=10**5, freq=""S"")

def workload():
    dti.tolist()

runtimes = timeit.repeat(workload, number=5, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.9309840832953341
Before SD: 0.002760287865856315
After Mean: 0.20380682519753462
After SD: 0.0025439075211139786
Improvement: -78.11%",,863,docker.io/sweperf/sweperf:pandas-dev__pandas-43823,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43823,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-43823 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-09-30 21:04:24,5319489f6c602ccf4070b9abd951c3c7344a8461,1.3
,APPROVED,pandas-dev__pandas-44192,https://github.com/pandas-dev/pandas/pull/44192,"import timeit
import statistics

import os
import pandas
import numpy
import tempfile

temp_output_file = tempfile.NamedTemporaryFile(suffix="".csv.gz"", delete=False).name

nb_col = 100000
nb_row = 5

def write_file():

    feature_list = {'sample': ['s_' + str(i+1) for i in range(nb_row)]}
    for i in range(nb_col):
        feature_list.update({'feature_' + str(i+1): list(numpy.random.uniform(low=0, high=10, size=nb_row))})
    df = pandas.DataFrame(feature_list)
    df.to_csv(temp_output_file, index=False, float_format=""%.6f"")

def workload():
    col_names = pandas.read_csv(temp_output_file, low_memory=False, nrows=1).columns
    types_dict = {col: numpy.float32 for col in col_names}
    types_dict.update({'sample': str})
    feature_df = pandas.read_csv(temp_output_file, index_col=""sample"", na_filter=False, dtype=types_dict, low_memory=False)

write_file()
runtimes = timeit.repeat(workload, number=1, repeat=3)

os.remove(temp_output_file)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 105.94698462466476
Before SD: 2.900340802094236
After Mean: 2.0324380723371482
After SD: 0.007040211446777867
Improvement: -98.08%",,70,docker.io/sweperf/sweperf:pandas-dev__pandas-44192,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44192,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44192 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-10-26 16:00:05,1b9be34545664f58481abdce9bf0c1bb7b07f0ae,1.3
,APPROVED,pandas-dev__pandas-44566,https://github.com/pandas-dev/pandas/pull/44566,"
import timeit
import statistics

import pandas as pd

import numpy as np

values = np.random.randn(1000000, 4)

def workload():
    pd.core.nanops.nansum(values, axis=1, skipna=True)

runtimes = timeit.repeat(workload, number=1, repeat=5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 10.94233608362265
Before SD: 0.0650021632880385
After Mean: 0.033476938802050424
After SD: 0.001125157760526118
Improvement: -99.69%",,870,docker.io/sweperf/sweperf:pandas-dev__pandas-44566,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44566,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44566 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-11-21 20:48:48,8f1dd29caf4ad954172c22f277ab336085566afc,1.3
,APPROVED,pandas-dev__pandas-44594,https://github.com/pandas-dev/pandas/pull/44594,"import timeit
import statistics

import pandas as pd
import numpy as np

types = [np.dtype(""float64"") for _ in range(10000)]

def workload():
    pd.core.dtypes.cast.find_common_type(types)
    
runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.017899473911791575
Before SD: 8.709581491206555e-05
After Mean: 0.001084988207789138
After SD: 4.410312630074661e-05
Improvement: -93.94%",,265,docker.io/sweperf/sweperf:pandas-dev__pandas-44594,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44594,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44594 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-11-23 21:10:53,d5f772382118f01cc6f3ed5888796fe88cda4bb6,1.3
,APPROVED,pandas-dev__pandas-44608,https://github.com/pandas-dev/pandas/pull/44608,"import timeit
import statistics

import pandas as pd

arr = pd.date_range(""2012-01-01"", periods=3).array
scalar = arr[0]

def workload():
    arr._validate_setitem_value(scalar)
    
runtimes = timeit.repeat(workload, number=5, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.4746331530623137e-05
Before SD: 3.3562039251617527e-06
After Mean: 7.601727280416526e-06
After SD: 3.235990670327572e-06
Improvement: -48.45%",,252,docker.io/sweperf/sweperf:pandas-dev__pandas-44608,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44608,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44608 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-11-24 20:43:29,8374c6565c5c8ba51c57790d66fd4177e26cc016,1.3
,APPROVED,pandas-dev__pandas-44610,https://github.com/pandas-dev/pandas/pull/44610,"import timeit
import statistics

import tempfile

import pandas as pd
import numpy as np


tempfile_path = tempfile.NamedTemporaryFile(suffix="".csv"", delete=False).name
pd.DataFrame({
    'id': np.arange(100000000),
    'b': np.random.choice(['a','b','c','d'],size=(100000000,),p=[0.25,0.25,0.25,0.25])
}).to_csv(tempfile_path,index=None)

def workload():
    pd.read_csv(tempfile_path, index_col='id')

runtimes = timeit.repeat(workload, number=1, repeat=3)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 47.3375491273473
Before SD: 0.1632962234620717
After Mean: 8.25858831232957
After SD: 0.05596834390960274
Improvement: -82.55%",,61,docker.io/sweperf/sweperf:pandas-dev__pandas-44610,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44610,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44610 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-11-24 23:15:21,75d0a96ee22794cb7c349d557c001b01b8373e30,1.3
,APPROVED,pandas-dev__pandas-44666,https://github.com/pandas-dev/pandas/pull/44666,"import timeit
import statistics

import numpy as np
import pandas as pd

N = 10 ** 3
df2 = pd.DataFrame(
    {
        c: {
            0: np.random.randint(0, 2, N).astype(np.bool_),
            1: np.random.randint(0, N, N).astype(np.int16),
            2: np.random.randint(0, N, N).astype(np.int32),
            3: np.random.randint(0, N, N).astype(np.int64),
        }[np.random.randint(0, 4)]
        for c in range(N)
    }
)
idx2 = np.random.permutation(range(1200))
df2_am1 = df2._as_manager(""array"").copy()


dtype = 'int'
m = 100
n = 1000

levels = np.arange(m)
index = pd.MultiIndex.from_product([levels] * 2)
columns = np.arange(n)
values = np.arange(m * m * n).reshape(m * m, n)

df = pd.DataFrame(values, index, columns)
df2 = df.iloc[:-1]
df2_am2 = df2._as_manager(""array"").copy()

def workload():
    for i in range(20):
        df2_am1.reindex(idx2)
        
    df2_am2.unstack()
    
runtimes = timeit.repeat(workload, number=1, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.6809505595942028
Before SD: 0.022657732133781028
After Mean: 0.28632162664725913
After SD: 0.017625450372798335
Improvement: -57.95%",,870,docker.io/sweperf/sweperf:pandas-dev__pandas-44666,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44666,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44666 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-11-29 7:40:44,7b78b730aee122bb7d6e90723c4208da234de19e,1.3
,APPROVED,pandas-dev__pandas-44758,https://github.com/pandas-dev/pandas/pull/44758,"import timeit
import statistics

import numpy as np
import pandas as pd
import string

m = 100
n = 50

levels = np.arange(m)
index = pd.MultiIndex.from_product([levels] * 2)
columns = np.arange(n)

indices = np.random.randint(0, 52, size=(m * m, n))
values = np.take(list(string.ascii_letters), indices)
values = [pd.Categorical(v) for v in values.T]

df = pd.DataFrame(
    {i: cat for i, cat in enumerate(values)}, index, columns
)
df2 = df.iloc[:-1]

def workload():
    df2.unstack()

runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.21617150049016345
Before SD: 0.0012962666949724187
After Mean: 0.05914513009344228
After SD: 0.0003303132087174095
Improvement: -72.64%",,18,docker.io/sweperf/sweperf:pandas-dev__pandas-44758,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44758,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44758 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-12-04 19:29:39,e6091f5ffbf9592aa6449ed2dea0e7f05f30c694,1.3
,APPROVED,pandas-dev__pandas-44827,https://github.com/pandas-dev/pandas/pull/44827,"import timeit
import statistics

import pandas as pd

n = int(1e6)
df = pd.DataFrame({""A"": [.0]*n})
arr = df.to_records(index=False)

def workload():
    pd.DataFrame(arr)

runtimes = timeit.repeat(workload, number=1, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.459243340822286
Before SD: 0.009999407024579847
After Mean: 0.0006677385373041034
After SD: 0.00019262057187595407
Improvement: -99.95%",,13,docker.io/sweperf/sweperf:pandas-dev__pandas-44827,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44827,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44827 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-12-09 12:50:22,a3702e2207af106939804ceb193bf4fae3e23a31,1.3
,APPROVED,pandas-dev__pandas-44832,https://github.com/pandas-dev/pandas/pull/44832,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 10 ** 3

object_df = pd.DataFrame(""foo"", index=range(N), columns=range(N))
object_df_nan = object_df.copy()
object_df_nan.iloc[-1, -1] = np.nan

nonunique_cols = object_df.copy()
nonunique_cols.columns = [""A""] * len(nonunique_cols.columns)
nonunique_cols_nan = nonunique_cols.copy()
nonunique_cols_nan.iloc[-1, -1] = np.nan

dfT = nonunique_cols.T

def workload():
    dfT.equals(dfT)
    
runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.043924932688241825
Before SD: 0.0008987562632072413
After Mean: 0.028727944411220962
After SD: 0.00031135833486044343
Improvement: -34.60%",,607,docker.io/sweperf/sweperf:pandas-dev__pandas-44832,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44832,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44832 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-12-10 2:08:36,b7991da3612de3f8119841d46f95c23148b0d928,1.3
,APPROVED,pandas-dev__pandas-44857,https://github.com/pandas-dev/pandas/pull/44857,"import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randn(10000, 1000))
df.iloc[50:1000, 20:50] = np.nan
df.iloc[2000:3000] = np.nan
df.iloc[:, 60:70] = np.nan

def workload():
    df.dropna(how='any', axis=0)

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.08341210420825519
Before SD: 0.001396775852645156
After Mean: 0.061948523783765266
After SD: 0.0022219768817042167
Improvement: -25.73%",,871,docker.io/sweperf/sweperf:pandas-dev__pandas-44857,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44857,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44857 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-12-12 19:00:25,ee1d839751664178129550534def7b952b155bbf,1.3
,APPROVED,pandas-dev__pandas-44908,https://github.com/pandas-dev/pandas/pull/44908,"import timeit
import statistics

import pandas as pd

n = 100_000
def setup():
    global df
    df = pd.DataFrame().assign(timestamp=pd.date_range('2000',  periods=n, freq='S'), col1=1).set_index('timestamp')

def workload():
    global df
    df.to_csv(date_format='%Y-%m-%d %H:%M:%S')
    
runtimes = timeit.repeat(workload, number=1, repeat=50, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.812842396433698
Before SD: 0.004677461571221365
After Mean: 0.29974971555406227
After SD: 0.0022554457623176795
Improvement: -63.12%",,30,docker.io/sweperf/sweperf:pandas-dev__pandas-44908,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44908,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44908 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-12-15 19:05:32,85c221a050d548fcb0541f3153372b8ca3aee70e,1.3
,APPROVED,pandas-dev__pandas-44943,https://github.com/pandas-dev/pandas/pull/44943,"import timeit
import statistics

import pandas as pd
import numpy as np

import os
import tempfile

def _create_df(rows, cols):
    index_cols = {
        ""index1"": np.random.randint(0, rows, rows),
        ""index2"": np.full(rows, 1, dtype=np.int32),
        ""index3"": np.full(rows, 1, dtype=np.int32),
    }
    data_cols = {
        f""col{i}"": np.random.uniform(0, 100000.0, rows) for i in range(cols)
    }
    df = pd.DataFrame({**index_cols, **data_cols})
    return df

ROWS = 100000
COLS = 5
HEAD_ROW_MULTIPLIER = 10

temp_path = tempfile.NamedTemporaryFile(suffix="".csv"", delete=False).name

df_custom_index_then_head = (
    _create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)
    .set_index([""index1"", ""index2"", ""index3""])
    .head(ROWS)
)

def setup():
    if os.path.exists(temp_path):
        os.remove(temp_path)

def workload():
    df_custom_index_then_head.to_csv(temp_path)

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

os.remove(temp_path)


# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.6814861488062889
Before SD: 0.007938078052263655
After Mean: 0.6088635988009627
After SD: 0.00636211436771935
Improvement: -63.79%",,30,docker.io/sweperf/sweperf:pandas-dev__pandas-44943,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44943,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-44943 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2021-12-17 11:46:03,adfc78b1a0ebd3083f4b725772b07b4db1454957,1.3
,APPROVED,pandas-dev__pandas-45242,https://github.com/pandas-dev/pandas/pull/45242,"import timeit
import statistics

import numpy as np
import pandas as pd

df = pd.DataFrame(range(10**6), dtype=np.int32)
mask = np.ones(df.shape, dtype=bool)

def workload():
    df.where(mask, -1)
    
runtimes = timeit.repeat(workload, number=5, repeat=10**3)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.009949573497928214
Before SD: 0.00014095265373632117
After Mean: 0.003886746780271642
After SD: 0.000122124774578305
Improvement: -60.94%",,874,docker.io/sweperf/sweperf:pandas-dev__pandas-45242,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45242,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45242 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-01-07 5:31:58,fa3dfdb41f0a75c937e85059a5983da5e5d5aac6,1.3
,APPROVED,pandas-dev__pandas-45247,https://github.com/pandas-dev/pandas/pull/45247,"import timeit
import statistics

import pandas as pd
import numpy as np
import itertools

try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm


f_list = [max, min, sum]
keys_list = [""jim"", [""jim"", ""joe""]]

def workload():
    for f, keys in itertools.product(f_list, keys_list):
        df = pd.DataFrame(np.random.randint(1, 50, (1000, 2)), columns=[""jim"", ""joe""])
        df[""jolie""] = np.random.randn(1000)

        gb = df.groupby(keys)

        fname = f.__name__
        result = gb.apply(f)
        ngroups = len(df.drop_duplicates(subset=keys))

        assert_msg = f""invalid frame shape: {result.shape} (expected ({ngroups}, 3))""
        assert result.shape == (ngroups, 3), assert_msg

        npfunc = getattr(np, fname)  # numpy's equivalent function
        if f in [max, min]:
            warn = FutureWarning
        else:
            warn = None
        msg = ""scalar (max|min) over the entire DataFrame""
        with tm.assert_produces_warning(warn, match=msg, check_stacklevel=False):
            expected = gb.apply(npfunc)
        tm.assert_frame_equal(result, expected)

        with tm.assert_produces_warning(None):
            expected2 = gb.apply(lambda x: npfunc(x, axis=0))
        tm.assert_frame_equal(result, expected2)

        if f != sum:
            expected = gb.agg(fname).reset_index()
            expected.set_index(keys, inplace=True, drop=False)
            tm.assert_frame_equal(result, expected, check_dtype=False)

        tm.assert_series_equal(getattr(result, fname)(), getattr(df, fname)())

runtimes = timeit.repeat(workload, number=1, repeat=5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.9684859600034543
Before SD: 0.05000569706391111
After Mean: 1.7148533321043942
After SD: 0.016324268238135563
Improvement: -56.79%",,225,docker.io/sweperf/sweperf:pandas-dev__pandas-45247,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45247,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45247 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-01-07 14:15:55,fa3dfdb41f0a75c937e85059a5983da5e5d5aac6,1.3
,APPROVED,pandas-dev__pandas-45387,https://github.com/pandas-dev/pandas/pull/45387,"import timeit
import statistics

import numpy as np
from pandas import DataFrame

n = 1000
df = DataFrame(
    np.random.randn(n, n),
    index=np.random.choice(range(10), n),
)

def workload():
    df.groupby(level=0).transform(lambda x: np.max(x, axis=0))

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.30061695230077023
Before SD: 0.0015466865272675582
After Mean: 0.042595122730126604
After SD: 0.0009356885554348227
Improvement: -85.83%",,8,docker.io/sweperf/sweperf:pandas-dev__pandas-45387,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45387,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45387 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-01-15 20:08:35,9e4c59ba415172462da104df8531976fa951cf52,1.3
,APPROVED,pandas-dev__pandas-45571,https://github.com/pandas-dev/pandas/pull/45571,"import timeit
import statistics

import pandas as pd

tdi = pd.timedelta_range(""1 second"", periods=10**5, freq=""s"")

def workload():
    tdi.astype(object)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.2941820461588213
Before SD: 0.0016104208377841105
After Mean: 0.24465388732147403
After SD: 0.001318170416943635
Improvement: -16.84%",,217,docker.io/sweperf/sweperf:pandas-dev__pandas-45571,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45571,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45571 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-01-23 16:24:19,2db3b0a0378487e269997700b14777af70838e95,1.4
,APPROVED,pandas-dev__pandas-45708,https://github.com/pandas-dev/pandas/pull/45708,"import timeit
import statistics

import numpy as np
import pandas as pd

N = 1_000_000

df = pd.DataFrame(
    data=np.random.rand(N, 3),
    index=np.random.randint(0, 5, N)
)

def workload():
    df.groupby(level=0).transform(lambda x: np.max(x, axis=0))
    
runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.2935421537875664
Before SD: 0.002716354461704055
After Mean: 0.12803276351070964
After SD: 0.002188143540732894
Improvement: -56.38%",,8,docker.io/sweperf/sweperf:pandas-dev__pandas-45708,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45708,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45708 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-01-30 3:45:53,5e40ff55ae2a4e2a1eaab0c924e5c369c591523d,1.4
,APPROVED,pandas-dev__pandas-45854,https://github.com/pandas-dev/pandas/pull/45854,"import timeit
import statistics

import numpy as np
import pandas as pd

N = 1_000_000

def workload():
    pd.DataFrame({""A"": pd.NA, ""B"": 1.0}, index=range(N), dtype=pd.Float64Dtype())
    pd.Series(pd.NA, index=range(N), dtype=pd.Float64Dtype())
    pd.Series(1, index=range(N), dtype='Int64')
    
runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.133291546953842
Before SD: 0.0030923468205038968
After Mean: 0.024992236513644458
After SD: 0.0010805697799273276
Improvement: -97.79%",,269,docker.io/sweperf/sweperf:pandas-dev__pandas-45854,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45854,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45854 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-02-07 4:03:08,a0779adb183345a8eb4be58b3ad00c223da58768,1.4
,APPROVED,pandas-dev__pandas-45931,https://github.com/pandas-dev/pandas/pull/45931,"import timeit
import statistics

import numpy as np
import pandas as pd

n1 = 10 ** 7
n2 = 10

mi = pd.MultiIndex.from_product([np.arange(n1), np.arange(n2)])

def workload():
    mi.get_locs([n1 - 1])

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.9005761946685379
Before SD: 0.04951549742171258
After Mean: 0.027387248646700755
After SD: 0.04825564216617621
Improvement: -96.96%",,107,docker.io/sweperf/sweperf:pandas-dev__pandas-45931,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45931,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45931 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-02-11 1:21:13,6f8d279be5cfa86cc9c6d5346e2c88d4b8d6d1f7,1.4
,APPROVED,pandas-dev__pandas-46040,https://github.com/pandas-dev/pandas/pull/46040,"import timeit
import statistics

import numpy as np
import pandas as pd

n1 = 10 ** 7
n2 = 10

lev0 = pd.date_range(""2000-01-01"", ""2020-12-31"", freq=""D"")
lev1 = np.arange(10000)
mi = pd.MultiIndex.from_product([lev0, lev1])

df = pd.DataFrame({""A"": 1.0}, index=mi)

def workload():
    df.loc[""2010-12-31"": ""2015-12-31""]

runtimes = timeit.repeat(workload, number=5, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.1036020518833538
Before SD: 0.0351623181799238
After Mean: 0.005026285428320989
After SD: 0.034340885622342394
Improvement: -99.54%",,19,docker.io/sweperf/sweperf:pandas-dev__pandas-46040,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46040,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46040 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-02-17 16:55:30,2fe0c7065665f25da66a9a0a0a2a27c681812cb2,1.4
,APPROVED,pandas-dev__pandas-46107,https://github.com/pandas-dev/pandas/pull/46107,"
import timeit
import statistics

import numpy as np
import pandas as pd

ser = pd.Series(range(10**5), dtype=""Int64"")
df = pd.DataFrame({""A"": 1, ""B"": ser})
gb = df.groupby(""A"")

def workload():
    gb.last()

runtimes = timeit.repeat(workload, number=5, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0035397473075950985
Before SD: 7.118559375113598e-05
After Mean: 0.003063418954022927
After SD: 6.567068349562101e-05
Improvement: -13.46%",,887,docker.io/sweperf/sweperf:pandas-dev__pandas-46107,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46107,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46107 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-02-21 21:35:50,ea0184e339b7dbf27eec53e6c01c6514bda1fc83,1.4
,APPROVED,pandas-dev__pandas-46109,https://github.com/pandas-dev/pandas/pull/46109,"

import timeit
import statistics

import numpy as np
import pandas as pd

arr = np.arange(10**5, dtype=""uint32"")
cat = pd.Categorical(np.arange(10**5))

def workload():
    pd.factorize(arr)
    cat.factorize()

runtimes = timeit.repeat(workload, number=5, repeat=10**3)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.026225741403584833
Before SD: 0.001141764527102483
After Mean: 0.008732024097815157
After SD: 0.00011362916068187786
Improvement: -66.70%",,887,docker.io/sweperf/sweperf:pandas-dev__pandas-46109,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46109,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46109 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-02-22 4:12:29,b5ce22c59c3e3afc2b2da2f5e9b972406211ce43,1.4
,APPROVED,pandas-dev__pandas-46174,https://github.com/pandas-dev/pandas/pull/46174,"import timeit
import statistics

import numpy as np
import pandas as pd

pearson_results = np.array([])
spearman_results = np.array([])
num_tests = 10
num_runs = 10

def setup():
    global df
    data = np.random.uniform(-1, 1, size=(100, 50000))
    df = pd.DataFrame(data)
    df.columns = [str(c) for c in df.columns]

def workload():
    global df
    df.corrwith(df['0'], axis=0, method='pearson')
    df.corrwith(df['0'], axis=0, method='spearman')

runtimes = timeit.repeat(workload, number=1, repeat=3, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 21.728906058613212
Before SD: 0.08085276554420523
After Mean: 5.374788319412619
After SD: 0.019866625334862026
Improvement: -75.26%",,8,docker.io/sweperf/sweperf:pandas-dev__pandas-46174,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46174,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46174 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-02-28 0:33:26,0ccad3840958cc7fff5aa358a08e33acca13dd00,1.4
,APPROVED,pandas-dev__pandas-46235,https://github.com/pandas-dev/pandas/pull/46235,"import timeit
import statistics

import numpy as np
import pandas as pd

mi = pd.MultiIndex.from_arrays(
  [np.arange(10**6)] * 2
)
mi2 = pd.MultiIndex.from_arrays(
  [np.arange(10**7)] * 2
)

df = pd.DataFrame({""A"": 1.0}, index=mi)

def workload():
    x = df.reindex(mi2.copy())

runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.8275737566850148
Before SD: 0.03333494698619826
After Mean: 0.5519860301935114
After SD: 0.008717052619520096
Improvement: -69.80%",,393,docker.io/sweperf/sweperf:pandas-dev__pandas-46235,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46235,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46235 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-03-04 23:51:17,980edae7e7a4ed0f5b2afc0162867e40a3692e24,1.4
,APPROVED,pandas-dev__pandas-46288,https://github.com/pandas-dev/pandas/pull/46288,"import timeit
import statistics

import numpy as np
import pandas as pd

mi = pd.MultiIndex.from_product(
    [ 
        pd.array(np.arange(10000), dtype=""Int64""),
        pd.date_range('2000-01-01', periods=1000),
    ]
)

df = pd.DataFrame({""A"": 1.0}, index=mi)

def workload():
    mi.copy().values

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 5.354271911113756
Before SD: 0.07642909086520502
After Mean: 0.8292068155831658
After SD: 0.026124695816423654
Improvement: -84.51%",,890,docker.io/sweperf/sweperf:pandas-dev__pandas-46288,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46288,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46288 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-03-09 1:31:35,48d515958d5805f0e62e34b7424097e5575089a8,1.4
,APPROVED,pandas-dev__pandas-46330,https://github.com/pandas-dev/pandas/pull/46330,"import timeit
import statistics

import numpy as np
import pandas as pd

nlevels = 2
mi1 = pd.MultiIndex.from_arrays([range(1000000)] * nlevels)
mi2 = pd.MultiIndex.from_product([range(1000)] * nlevels)
df1 = pd.DataFrame(np.random.randn(len(mi1)), index=mi1)
df2 = pd.DataFrame(np.random.randn(len(mi2)), index=mi2)
dfs = [df1, df2]

tgt_slice = slice(200, 800)
tgt_null_slice = slice(None)
tgt_list = list(range(0, 1000, 10))
tgt_scalar = 500

def workload():
    for df in dfs:
        target1 = (tgt_null_slice, tgt_slice)
        df.loc[target1, :]
        
        target2 = tuple([tgt_list] * nlevels)
        df.loc[target2, :]
        
runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.4209077364415862
Before SD: 0.002315129631281091
After Mean: 0.06297278098820243
After SD: 0.0016829426487888956
Improvement: -85.04%",,890,docker.io/sweperf/sweperf:pandas-dev__pandas-46330,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46330,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46330 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-03-11 20:59:28,663147edd35bc3e0362f7d637c8d5f5e597f961b,1.4
,APPROVED,pandas-dev__pandas-46349,https://github.com/pandas-dev/pandas/pull/46349,"import timeit
import statistics

import numpy as np
import pandas as pd

from itertools import permutations, chain
import string

string_values = chain(
    string.ascii_uppercase,
    permutations(string.ascii_uppercase, 2),
    permutations(string.ascii_uppercase, 3),
)

string_index = pd.Index(map(''.join, string_values)).astype('string')

df = pd.DataFrame({'ints': range(len(string_index))}, index=string_index)

subset_index = string_index[string_index.str.startswith('A')]

def workload():
    df.loc[subset_index]
    
runtimes = timeit.repeat(workload, number=1, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.0418672172020886
Before SD: 0.004495266776754686
After Mean: 0.0001657714881002903
After SD: 0.0001310879532136547
Improvement: -99.99%",,890,docker.io/sweperf/sweperf:pandas-dev__pandas-46349,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46349,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-46349 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-03-12 22:32:11,2fdeb072c5b08aafef51749f342503cbb142dbd8,1.4
,APPROVED,pandas-dev__pandas-47234,https://github.com/pandas-dev/pandas/pull/47234,"import timeit
import statistics

import numpy as np
import pandas as pd

idx = np.arange(100)[::-1]
idx = pd.Index(np.repeat(idx, 200), name=""key"")
df = pd.DataFrame(np.random.randn(len(idx), 10), index=idx)

def workload():
    df.groupby(""key"", group_keys=False).apply(lambda x: x)
    
runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.6815340894763358
Before SD: 0.11286720567632838
After Mean: 0.006473780437372625
After SD: 0.0009139753382350673
Improvement: -99.76%",,897,docker.io/sweperf/sweperf:pandas-dev__pandas-47234,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-47234,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-47234 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-06-04 18:58:16,df8acf4201466e77572cdb8125683e75c4715f91,1.4
,APPROVED,pandas-dev__pandas-47656,https://github.com/pandas-dev/pandas/pull/47656,"import timeit
import statistics

import pandas as pd

from pathlib import Path

ROOT = Path(""/testbed"") / ""pandas"" / ""tests"" / ""io"" / ""sas"" / ""data""

def workload():
    next(pd.read_sas(ROOT / ""0x00controlbyte.sas7bdat.bz2"", chunksize=11000))
    for i, _ in enumerate(
        pd.read_sas(ROOT / ""0x00controlbyte.sas7bdat.bz2"", chunksize=1000)
    ):
        if i == 10:
            break

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.21221550033369568
Before SD: 0.0016886651260616325
After Mean: 0.19282230269804132
After SD: 0.003523500571015405
Improvement: -9.14%",,3,docker.io/sweperf/sweperf:pandas-dev__pandas-47656,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-47656,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-47656 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-07-09 21:40:23,2ef8d147c51afa9dfb5d184c2407227cf9e661db,1.4
,APPROVED,pandas-dev__pandas-47781,https://github.com/pandas-dev/pandas/pull/47781,"import timeit
import statistics

import pandas as pd
import numpy as np
import pyarrow as pa
from pyarrow import parquet as pq
import tempfile
import os

n = 10000000
df = pd.DataFrame(
    {
        ""a"": np.random.choice([0, 1, None], n),
        ""b"": np.random.choice([0, 10, 90129, None], n),
        ""c"": np.random.choice([True, False, None], n),
        ""d"": np.random.choice([""a"", ""b"", None], n),
    },
    dtype=object,
)
df[""a""] = df[""a""].astype(""Int8"")
df = df.convert_dtypes()

temp_path = tempfile.NamedTemporaryFile(suffix="".parquet"", delete=False).name

table = pa.Table.from_pandas(df)
table = table.replace_schema_metadata()
pq.write_table(table, temp_path)

def workload():
    df = pd.read_parquet(temp_path, use_nullable_dtypes=True)

runtimes = timeit.repeat(workload, number=1, repeat=25)

os.remove(temp_path)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.971940186440479
Before SD: 0.0177559115818046
After Mean: 0.4939593852846883
After SD: 0.015544292807478278
Improvement: -49.18%",,3,docker.io/sweperf/sweperf:pandas-dev__pandas-47781,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-47781,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-47781 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-07-18 19:25:46,b69bd0755d654c0dba42042df7b2251918274327,1.4
,APPROVED,pandas-dev__pandas-48152,https://github.com/pandas-dev/pandas/pull/48152,"import timeit
import statistics

import pandas as pd
import numpy as np

ngroups = 1000
ncols = 2
size = ngroups * 2
rng = np.arange(ngroups).reshape(-1, 1)
rng = np.broadcast_to(rng, (len(rng), ncols))
taker = np.random.randint(0, ngroups, size=size)
values = rng.take(taker, axis=0)
key = np.random.randint(0, size, size=size)

cols = [f""values{n}"" for n in range(ncols)]
df = pd.DataFrame(values, columns=cols)
df[""key""] = key

def workload():
    df.groupby(""key"")[cols].var(ddof=0)

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.388293728394201
Before SD: 0.0014355511950106747
After Mean: 0.004364630582276732
After SD: 0.0001704884411753053
Improvement: -98.88%",,899,docker.io/sweperf/sweperf:pandas-dev__pandas-48152,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48152,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48152 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-08-19 12:03:10,838b04f09fd1cbac2e2ff9307941da6f47c8b792,1.4
,APPROVED,pandas-dev__pandas-48338,https://github.com/pandas-dev/pandas/pull/48338,"import timeit
import statistics

import pandas as pd
import numpy as np

ser = pd.Series([1, 2, pd.NA] + list(range(1_000_000)), dtype=""Int64"")
data = np.array(list(range(1_000_000)))

def workload():
    ser.value_counts(dropna=True)
    ser.value_counts(dropna=False)
    pd.Series(data, dtype=""Int64"")

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.42550725042528936
Before SD: 0.0035384445312208615
After Mean: 0.16562604571692646
After SD: 0.0019724063691641796
Improvement: -61.08%",,903,docker.io/sweperf/sweperf:pandas-dev__pandas-48338,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48338,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48338 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-08-31 21:44:46,5bcf4d532bbd40337e5fc4ad0f126266caf1e01a,1.4
,APPROVED,pandas-dev__pandas-48387,https://github.com/pandas-dev/pandas/pull/48387,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 1_000_000
df = pd.DataFrame(
    np.random.randint(0, high=100, size=(N, 10)),
    columns=list(""abcdefghij""),
    dtype=""Float64"",
)
df.loc[list(range(1, N, 5)), list(""abcdefghij"")] = pd.NA
df[""key""] = np.random.randint(0, 100, size=N)

def workload():
    df.groupby(""key"").agg(""median"")

runtimes = timeit.repeat(workload, number=1, repeat=50)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.268281364380091
Before SD: 0.008808458650611141
After Mean: 0.2318319257791154
After SD: 0.004657704276364213
Improvement: -13.59%",,903,docker.io/sweperf/sweperf:pandas-dev__pandas-48387,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48387,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48387 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-09-04 16:23:27,fa211d47604f5de7667440a842f7fbbb463de31d,1.4
,APPROVED,pandas-dev__pandas-48472,https://github.com/pandas-dev/pandas/pull/48472,"import timeit
import statistics

import pandas as pd
import numpy as np


idx_ea = pd.Index(np.arange(1_000_000), dtype=""Int64"")
indexer = np.arange(500, 1000)

def workload():
    idx_ea.get_indexer(indexer)

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.08211296945763752
Before SD: 0.0014464605672114036
After Mean: 0.0008689481191104278
After SD: 0.0011363234582571862
Improvement: -98.94%",,903,docker.io/sweperf/sweperf:pandas-dev__pandas-48472,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48472,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48472 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-09-08 19:13:49,047c11d7801ffd0cf679d606293af510e34d7b92,1.4
,APPROVED,pandas-dev__pandas-48502,https://github.com/pandas-dev/pandas/pull/48502,"import timeit
import statistics

import pandas as pd

from pathlib import Path

file_path = str(Path(""/testbed"") / ""pandas"" / ""tests"" / ""io"" / ""sas"" / ""data"" / ""test1.sas7bdat"")

def workload():
    pd.read_sas(file_path, format=""sas7bdat"")

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.020884487399598584
Before SD: 0.0027003431936884945
After Mean: 0.010229039308615028
After SD: 0.00234909384723015
Improvement: -51.02%",,3,docker.io/sweperf/sweperf:pandas-dev__pandas-48502,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48502,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48502 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-09-10 23:19:28,fe9e5d023e20304ad1bdfa1da53f3af452c72a00,1.4
,APPROVED,pandas-dev__pandas-48504,https://github.com/pandas-dev/pandas/pull/48504,"import timeit
import statistics

import pandas as pd
import numpy as np

n = 100_000
offset = 50_000

merge_types =[
    ""inner"",
    ""left"",
    ""right"",
]

df_pairs = []

for dtypes in [
    (""int64"", ""int64""),
    (""datetime64[ns]"", ""int64""),
    (""Int64"", ""Int64""),
]:
    mi1 = pd.MultiIndex.from_arrays(
    [
        pd.array(np.arange(n), dtype=dtypes[0]),
        pd.array(np.arange(n), dtype=dtypes[1]),
    ]
    )
    mi2 = pd.MultiIndex.from_arrays(
    [
        pd.array(np.arange(offset, n + offset), dtype=dtypes[0]),
        pd.array(np.arange(offset, n + offset), dtype=dtypes[1]),
    ]
    )

    df1 = pd.DataFrame({""col1"": 1}, index=mi1)
    df2 = pd.DataFrame({""col2"": 2}, index=mi2)

    df_pairs.append((df1, df2))


def workload():
    for merge_type in merge_types:
        for df1, df2 in df_pairs:
            df1 = df1.copy()
            df2 = df2.copy()
            pd.merge(df1, df2, how=merge_type, left_index=True, right_index=True)

runtimes = timeit.repeat(workload, number=1, repeat=200)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.7399858453171327
Before SD: 0.013094168853592996
After Mean: 0.3723532280413201
After SD: 0.005972684030758798
Improvement: -49.68%",,904,docker.io/sweperf/sweperf:pandas-dev__pandas-48504,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48504,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48504 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-09-11 3:02:05,ac648eeaf5c27ab957e8cd284eb7e49a45232f00,1.4
,APPROVED,pandas-dev__pandas-48609,https://github.com/pandas-dev/pandas/pull/48609,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 100_000
dti = pd.date_range(""1900-01-01"", periods=N)

list_of_timestamps = dti.tolist()
list_of_dates = dti.date.tolist()
list_of_datetimes = dti.to_pydatetime().tolist()
list_of_str = dti.strftime(""%Y-%m-%d"").tolist()

def workload():
    pd.DatetimeIndex(list_of_timestamps)
    pd.DatetimeIndex(list_of_dates)
    pd.DatetimeIndex(list_of_datetimes)
    pd.DatetimeIndex(list_of_str)

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.38161490724014585
Before SD: 0.006091974167979024
After Mean: 0.17553943075123243
After SD: 0.0018420154678821176
Improvement: -54.00%",,905,docker.io/sweperf/sweperf:pandas-dev__pandas-48609,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48609,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48609 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-09-17 18:08:00,5de24481d817339829911e61bd62170a8d0b2734,1.4
,APPROVED,pandas-dev__pandas-48611,https://github.com/pandas-dev/pandas/pull/48611,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 100_000
mi1 = pd.MultiIndex.from_arrays([np.arange(N)] * 4, names=[""a"", ""b"", ""c"", ""d""])
mi2 = pd.MultiIndex.from_arrays([np.arange(N)] * 2, names=[""a"", ""b""])
left = pd.DataFrame({""col1"": 1}, index=mi1)
right = pd.DataFrame({""col2"": 2}, index=mi2)

def workload():
    left.join(right)

runtimes = timeit.repeat(workload, number=1, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.02247095642919885
Before SD: 0.0008841304375572105
After Mean: 0.013096780854160897
After SD: 0.000471296180228197
Improvement: -41.72%",,7,docker.io/sweperf/sweperf:pandas-dev__pandas-48611,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48611,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48611 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-09-17 18:51:00,5de24481d817339829911e61bd62170a8d0b2734,1.4
,APPROVED,pandas-dev__pandas-48622,https://github.com/pandas-dev/pandas/pull/48622,"import timeit
import statistics

import pandas as pd
import numpy as np

try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm


N = 10**5
level1 = range(1000)

level2 = pd.date_range(start=""1/1/2000"", periods=N // 1000)
dates_midx = pd.MultiIndex.from_product([level1, level2])

level2 = range(N // 1000)
int_midx = pd.MultiIndex.from_product([level1, level2])

level2 = tm.makeStringIndex(N // 1000).values
str_midx = pd.MultiIndex.from_product([level1, level2])

data = {
    ""datetime"": dates_midx,
    ""int"": int_midx,
    ""string"": str_midx,
}

values = {
    ""datetime"": dates_midx[:100],
    ""int"": int_midx[:100],
    ""string"": str_midx[:100],
}

def workload():
    for k in data.keys():
        data[k].isin(values[k])

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.10226921798312105
Before SD: 0.003001628702499308
After Mean: 0.07254856816027314
After SD: 0.0010142474885191809
Improvement: -29.06%",,904,docker.io/sweperf/sweperf:pandas-dev__pandas-48622,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48622,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48622 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-09-18 14:32:08,85246fe460e93d2b891a1c116bcef3cb1a698664,1.4
,APPROVED,pandas-dev__pandas-48723,https://github.com/pandas-dev/pandas/pull/48723,"import timeit
import statistics


import pandas as pd
import numpy as np

mi = pd.MultiIndex.from_product(
    [
        pd.date_range('1970-01-01', periods=1000),
        np.arange(1000),
    ]
)

def workload():
    mi.copy().size

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.46050015989225357
Before SD: 0.006249273916023935
After Mean: 6.372463249135763e-05
After SD: 6.552576410067391e-06
Improvement: -99.99%",,905,docker.io/sweperf/sweperf:pandas-dev__pandas-48723,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48723,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48723 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-09-23 0:04:06,cda0f6bee2a6520729247f92eef9f722ad2487ec,1.4
,APPROVED,pandas-dev__pandas-48752,https://github.com/pandas-dev/pandas/pull/48752,"import timeit
import statistics

import pandas as pd

try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm

N = 10**5

dtypes = (""datetime"", ""int"", ""string"", ""ea_int"")

level1 = range(1000)

level2 = pd.date_range(start=""1/1/2000"", periods=N // 1000)
dates_left = pd.MultiIndex.from_product([level1, level2])

level2 = range(N // 1000)
int_left = pd.MultiIndex.from_product([level1, level2])

level2 = tm.makeStringIndex(N // 1000).values
str_left = pd.MultiIndex.from_product([level1, level2])

level2 = range(N // 1000)
ea_int_left = pd.MultiIndex.from_product([level1, pd.Series(level2, dtype=""Int64"")])

data = {
    ""datetime"": dates_left,
    ""int"": int_left,
    ""string"": str_left,
    ""ea_int"": ea_int_left,
}
data_non_monotonic = {k: mi[::-1] for k, mi in data.items()}

data = {k: {""left"": mi, ""right"": mi[:-1]} for k, mi in data.items()}
data_non_monotonic = {k: {""left"": mi, ""right"": mi[:-1]} for k, mi in data_non_monotonic.items()}

def workload():
    for dtype in dtypes:
        data[dtype]['left'].union(data[dtype]['right'])
        data_non_monotonic[dtype]['left'].union(data_non_monotonic[dtype]['right'])
        
runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.2035377869394142
Before SD: 0.016853061447521443
After Mean: 0.11548900521884206
After SD: 0.003738354129482239
Improvement: -43.26%",,18,docker.io/sweperf/sweperf:pandas-dev__pandas-48752,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48752,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48752 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-09-23 23:43:33,7aa391ead0f8761219add833045f77a40a25effe,1.4
,APPROVED,pandas-dev__pandas-48976,https://github.com/pandas-dev/pandas/pull/48976,"import timeit
import statistics

import pandas as pd

df = pd.DataFrame({
    ""key"": pd.Categorical(range(1_000_000 - 1, -1, -1), range(1_000_000))
})

def workload():
    df.groupby(""key"", sort=False) 
        
runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.48202702797832897
Before SD: 0.003002129389362049
After Mean: 0.06758447361993604
After SD: 0.0016332124293408363
Improvement: -85.98%",,16,docker.io/sweperf/sweperf:pandas-dev__pandas-48976,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48976,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-48976 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-10-06 18:34:36,5620f0e3dfcb4e9d612bc72ee7998188e34102c2,1.4
,APPROVED,pandas-dev__pandas-49177,https://github.com/pandas-dev/pandas/pull/49177,"import timeit
import statistics

import pandas as pd
import pyarrow as pa

data = [1, 2, 3] * 5000 + [None] * 500
arr = pd.arrays.ArrowExtensionArray(pa.array(data))

def workload():
    arr.factorize()
        
runtimes = timeit.repeat(workload, number=5, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.002486159963661339
Before SD: 5.8748533241171475e-05
After Mean: 0.0004523087469220627
After SD: 1.3685923500641022e-05
Improvement: -81.81%",,904,docker.io/sweperf/sweperf:pandas-dev__pandas-49177,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49177,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49177 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-10-18 23:49:51,8b503a8ca06c6370fc3fbd972fc6b0a621df9531,1.4
,APPROVED,pandas-dev__pandas-49577,https://github.com/pandas-dev/pandas/pull/49577,"import timeit
import statistics

import pandas as pd
import numpy as np

try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm


N = 10**5
level1 = range(1000)

level2 = pd.date_range(start=""1/1/2000"", periods=N // 1000)
dates_midx = pd.MultiIndex.from_product([level1, level2])

level2 = range(N // 1000)
int_midx = pd.MultiIndex.from_product([level1, level2])

level2 = tm.makeStringIndex(N // 1000).values
str_midx = pd.MultiIndex.from_product([level1, level2])

data = {
    ""datetime"": dates_midx,
    ""int"": int_midx,
    ""string"": str_midx,
}

values_small = {
    ""datetime"": dates_midx[:100],
    ""int"": int_midx[:100],
    ""string"": str_midx[:100],
}

values_large = {
    ""datetime"": dates_midx[100:],
    ""int"": int_midx[100:],
    ""string"": str_midx[100:],
}

def workload():
    for k in data.keys():
        data[k].isin(values_small[k])
        data[k].isin(values_large[k])

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.2152292378904531
Before SD: 0.0035502825012806486
After Mean: 0.03287824132537935
After SD: 0.0012208878043312695
Improvement: -84.72%",,896,docker.io/sweperf/sweperf:pandas-dev__pandas-49577,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49577,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49577 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-11-08 12:23:48,d47e052379826ab6085e145e6ee2c654b0d1c471,1.5
,APPROVED,pandas-dev__pandas-49596,https://github.com/pandas-dev/pandas/pull/49596,"import timeit
import statistics

import pandas as pd
import pandas._testing as tm

vals = pd.Series(tm.rands_array(10, 10**6), dtype=""string"")
df = pd.DataFrame({""cat"": vals.astype(""category"")})

def workload():
    df.groupby(""cat"").size()
    
runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.2680006485641935
Before SD: 0.012226411002468754
After Mean: 0.010287442991975695
After SD: 0.0013163983461513071
Improvement: -99.19%",,24,docker.io/sweperf/sweperf:pandas-dev__pandas-49596,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49596,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49596 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-11-09 2:14:34,d69e63d7b1e14b518a413fdff245e3329b92ceba,1.5
,APPROVED,pandas-dev__pandas-49772,https://github.com/pandas-dev/pandas/pull/49772,"import timeit
import statistics

import pandas as pd

def foo(df):
    for idx in df.index:
        df.at[idx, ""bar""] = 3

df = pd.DataFrame(range(10000))
df[""bar""] = 0

def workload():
    foo(df)
    
runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.31312064473284407
Before SD: 0.0010510057525230073
After Mean: 0.14031067764153704
After SD: 0.0004841690018924509
Improvement: -55.19%",,92,docker.io/sweperf/sweperf:pandas-dev__pandas-49772,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49772,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49772 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-11-18 14:53:55,3ece807d6d85663cb0f9811ccabb8426f506bb5d,1.5
,APPROVED,pandas-dev__pandas-49825,https://github.com/pandas-dev/pandas/pull/49825,"import timeit
import statistics

import pandas as pd
import pandas._testing as tm

s = pd.Series(tm.makeStringIndex(10**5), dtype=""string[pyarrow]"")

def workload():
    for i in s:
        pass
    
runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.16851377627579495
Before SD: 0.0007673209446269076
After Mean: 0.05615325432270765
After SD: 0.00022309917199578132
Improvement: -66.68%",,16,docker.io/sweperf/sweperf:pandas-dev__pandas-49825,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49825,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49825 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-11-22 0:56:20,a6d3e13b3a3c0d2b902c6229a7261bc299f36a03,1.5
,APPROVED,pandas-dev__pandas-49839,https://github.com/pandas-dev/pandas/pull/49839,"import timeit
import statistics

import pandas as pd

empty_list = []

def workload():
    pd._libs.lib.infer_dtype(empty_list, skipna=True)
    
runtimes = timeit.repeat(workload, number=5, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.5138917941367254e-05
Before SD: 3.424419389017521e-06
After Mean: 2.348568059387617e-06
After SD: 2.9091886891195017e-07
Improvement: -84.49%",,83,docker.io/sweperf/sweperf:pandas-dev__pandas-49839,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49839,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49839 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-11-22 14:53:17,80527f4865d68a147d82fc7953f809e446ac9510,1.5
,APPROVED,pandas-dev__pandas-49851,https://github.com/pandas-dev/pandas/pull/49851,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 10**5

dtypes = [
    ""boolean"",
    ""Int64"",
    ""Float64"",
]
data = {
    ""boolean"": pd.Series(np.repeat([True, False], N // 2), dtype=""boolean""),
    ""Int64"": pd.Series(np.arange(N), dtype=""Int64""),
    ""Float64"": pd.Series(np.random.randn(N), dtype=""Float64""),

}

def workload():
    for k, v in data.items():
        for e in v:
            pass
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.17746527078794316
Before SD: 0.0016378372052652335
After Mean: 0.058828662181622346
After SD: 0.0004271541968552396
Improvement: -66.85%",,32,docker.io/sweperf/sweperf:pandas-dev__pandas-49851,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49851,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-49851 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-11-23 1:29:51,b6736b449f3062cf05c224ad738c03cef62e248e,1.5
,APPROVED,pandas-dev__pandas-50078,https://github.com/pandas-dev/pandas/pull/50078,"import timeit
import statistics

import pandas as pd
import numpy as np
import pandas._testing as tm

N = 10**6
dtypes = [
    ""Float64"",
    ""Int64"",
    ""int64[pyarrow]"",
    ""string"",
    ""string[pyarrow]"",
]
method = None

# Prepare list of (Series, fill_value, dtype)
data_series = []

for dtype in dtypes:
    if dtype == ""datetime64[ns]"":
        data = pd.date_range(""2000-01-01"", freq=""S"", periods=N)
        na_value = pd.NaT
    elif dtype in (""float64"", ""Float64""):
        data = np.random.randn(N)
        na_value = np.nan
    elif dtype in (""Int64"", ""int64[pyarrow]""):
        data = np.arange(N)
        na_value = pd.NA
    elif dtype in (""string"", ""string[pyarrow]""):
        data = tm.rands_array(5, N)
        na_value = pd.NA

    fill_value = data[0]
    ser = pd.Series(data, dtype=dtype)
    ser[::2] = na_value
    data_series.append((ser, fill_value))

def workload():
    for ser, fill_value in data_series:
        ser.fillna(value=fill_value, method=None)
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.792284425116377
Before SD: 0.01652029550550107
After Mean: 0.41685231126262806
After SD: 0.007203069014138255
Improvement: -47.39%",,28,docker.io/sweperf/sweperf:pandas-dev__pandas-50078,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50078,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50078 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-12-06 0:26:36,1c71d7db926f4247798a7182f85aba1124fa894f,1.5
,APPROVED,pandas-dev__pandas-50089,https://github.com/pandas-dev/pandas/pull/50089,"import timeit
import statistics

import pandas as pd
import random

df = pd.Series([random.random() for _ in range(1000)], dtype=float)

def workload():
    df.to_dict()

runtimes = timeit.repeat(workload, number=1, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.00012549624929961283
Before SD: 5.599175856026274e-06
After Mean: 9.202701703936327e-05
After SD: 7.855732169847635e-06
Improvement: -26.67%",,15,docker.io/sweperf/sweperf:pandas-dev__pandas-50089,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50089,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50089 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-12-06 19:18:22,7c208c8907f5ab18f807366c0c5e26ae1dbca299,1.5
,APPROVED,pandas-dev__pandas-50168,https://github.com/pandas-dev/pandas/pull/50168,"import timeit
import statistics

import pandas as pd

dates = pd.date_range('1900', '2000').tz_localize('+01:00').strftime('%Y-%d-%m %H:%M:%S%z').tolist()
dates.append('2020-01-01 00:00:00+02:00')

def workload():
    pd.to_datetime(dates, format='%Y-%d-%m %H:%M:%S%z')
    
runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.37529026496224105
Before SD: 0.0024600243343824105
After Mean: 0.14975715583655982
After SD: 0.0013648864695319954
Improvement: -60.10%",,1,docker.io/sweperf/sweperf:pandas-dev__pandas-50168,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50168,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50168 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-12-10 18:33:01,5fad2e4e90be46c14e947ac1a7eba3275c4b656d,1.5
,APPROVED,pandas-dev__pandas-50306,https://github.com/pandas-dev/pandas/pull/50306,"import timeit
import statistics

import pandas as pd

ser = pd.Series(range(10_000_000))

def workload():
    ser + 1

runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.01582133123127278
Before SD: 0.001046454733574528
After Mean: 0.009464420339209028
After SD: 0.00023093142058980542
Improvement: -40.18%",,280,docker.io/sweperf/sweperf:pandas-dev__pandas-50306,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50306,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50306 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-12-16 23:24:50,e1dd15b41e02ec78ca61379dad74a99f5ec16aa0,1.5
,APPROVED,pandas-dev__pandas-50310,https://github.com/pandas-dev/pandas/pull/50310,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 10**5

ea_int_left = pd.Index(np.arange(N), dtype=""Int64"")
ea_int_right = ea_int_left[:-1]

def workload():
    ea_int_left.union(ea_int_right)
    ea_int_left.intersection(ea_int_right)
    
runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.05520703064044938
Before SD: 0.002680156582842153
After Mean: 0.024784566629678012
After SD: 0.00189930921423371
Improvement: -55.11%",,896,docker.io/sweperf/sweperf:pandas-dev__pandas-50310,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50310,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50310 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2022-12-17 11:38:34,22491dc041315d40e525b722a92202f656639957,1.5
,APPROVED,pandas-dev__pandas-50524,https://github.com/pandas-dev/pandas/pull/50524,"import timeit
import statistics

import pandas as pd
import numpy as np

data = np.random.randn(10**6)
data[0] = np.nan

arr = pd.array(data, dtype=""float64[pyarrow]"")

def workload():
    arr > 0
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.38768923001131045
Before SD: 0.001779825903999116
After Mean: 0.014323892173124478
After SD: 0.00016714601750027297
Improvement: -96.31%",,7,docker.io/sweperf/sweperf:pandas-dev__pandas-50524,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50524,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50524 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-01-02 1:45:46,a28cadbeb6f21da6c768b84473b3415e6efb3115,1.5
,APPROVED,pandas-dev__pandas-50620,https://github.com/pandas-dev/pandas/pull/50620,"import timeit
import statistics

import pandas as pd

N = 10_000
tuples = [(i, i + 1) for i in range(N)]

def workload():
    pd.arrays.IntervalArray.from_tuples(tuples)
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.06695583514211466
Before SD: 0.00036322127213685455
After Mean: 0.01030814438208472
After SD: 0.0002003837031194902
Improvement: -84.60%",,900,docker.io/sweperf/sweperf:pandas-dev__pandas-50620,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50620,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50620 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-01-07 12:30:22,76c39d547c42644f8ce42801d696334cd3e199a2,1.5
,APPROVED,pandas-dev__pandas-50623,https://github.com/pandas-dev/pandas/pull/50623,"

import timeit
import statistics

import pandas as pd
import numpy as np

methods = [""any"", ""all""]

ngroups = 1000
ncols = 1
size = ngroups * 2

cols = [f""values{n}"" for n in range(ncols)]

def setup():
    global df
    
    rng = np.arange(ngroups).reshape(-1, 1)
    rng = np.broadcast_to(rng, (len(rng), ncols))
    taker = np.random.randint(0, ngroups, size=size)
    values = rng.take(taker, axis=0)
    key = [""foo""] * size
    df = pd.DataFrame(values, columns=cols)
    df[""key""] = key

def workload():
    global df
    df.groupby(cols)[""key""].any()
    df.groupby(cols)[""key""].all()

runtimes = timeit.repeat(workload, number=5, repeat=100, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00980761858227197
Before SD: 0.00010859884308416428
After Mean: 0.004828637401806191
After SD: 9.223326010625832e-05
Improvement: -50.77%",,12,docker.io/sweperf/sweperf:pandas-dev__pandas-50623,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50623,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-50623 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-01-07 15:10:47,76c39d547c42644f8ce42801d696334cd3e199a2,1.5
,APPROVED,pandas-dev__pandas-51054,https://github.com/pandas-dev/pandas/pull/51054,"
import timeit
import statistics

import pandas as pd
import numpy as np

from pandas.api.types import infer_dtype

base_arr = np.arange(10_000_000)
x1 = np.array(base_arr)
x2 = pd.Series(base_arr)

x3 = pd.Series(base_arr, dtype=""Int32"")
x4 = pd.array(base_arr)

def workload():
    infer_dtype(x1)
    infer_dtype(x2)
    infer_dtype(x3)
    infer_dtype(x4)

runtimes = timeit.repeat(workload, number=1, repeat=10**4)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.7964556498918683e-05
Before SD: 2.2549705872937495e-06
After Mean: 1.944280503084883e-06
After SD: 7.991637331319506e-07
Improvement: -89.18%",,903,docker.io/sweperf/sweperf:pandas-dev__pandas-51054,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51054,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51054 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-01-29 12:20:05,0cedcbf6ec769fbc6075c3be1bed9087d85e2dec,1.5
,APPROVED,pandas-dev__pandas-51339,https://github.com/pandas-dev/pandas/pull/51339,"import timeit
import statistics

import pandas as pd
import numpy as np

idx = pd.IntervalIndex.from_breaks(np.arange(1000001))
monotonic = pd.Series(np.arange(1000000), index=idx)

def workload():
    monotonic.loc[80000:]
    
runtimes = timeit.repeat(workload, number=1, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.009402162064798176
Before SD: 0.00025405782982758585
After Mean: 0.0013328159933444113
After SD: 8.490702037770204e-05
Improvement: -85.82%",,91,docker.io/sweperf/sweperf:pandas-dev__pandas-51339,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51339,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51339 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-02-12 0:08:02,031e9bbc3a9db4ab78be8b477b15d7173a1f625e,1.5
,APPROVED,pandas-dev__pandas-51344,https://github.com/pandas-dev/pandas/pull/51344,"import timeit
import statistics

import numpy as np
import pandas as pd

n = 5 * 10**5
arr = [f""s{i:04d}"" for i in np.random.randint(0, n // 10, size=n)]
ts = pd.Series(arr).astype(""category"")

def workload():
    ts.cat.remove_categories(ts.cat.categories[::2])
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.1953604858578183
Before SD: 0.0034820578971526813
After Mean: 0.1311811228399165
After SD: 0.0023585546309284047
Improvement: -32.85%",,8,docker.io/sweperf/sweperf:pandas-dev__pandas-51344,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51344,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51344 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-02-12 1:17:01,031e9bbc3a9db4ab78be8b477b15d7173a1f625e,1.5
,APPROVED,pandas-dev__pandas-51439,https://github.com/pandas-dev/pandas/pull/51439,"import timeit
import statistics

import numpy as np
import pandas as pd

N = 10_000_000
dtype = ""int64[pyarrow]""
ser = pd.Series(np.random.randint(0, N, N), dtype=dtype)

def workload():
    ser.to_numpy(dtype=""int64"", na_value=1.5)
    
runtimes = timeit.repeat(workload, number=5, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 8.30667071341304e-05
Before SD: 4.52241476024994e-06
After Mean: 6.95057673897827e-05
After SD: 4.850977562591405e-06
Improvement: -16.33%",,908,docker.io/sweperf/sweperf:pandas-dev__pandas-51439,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51439,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51439 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-02-16 20:07:29,a131266c8ab7c83f73331b5be5ea49d9a628f075,1.5
,APPROVED,pandas-dev__pandas-51518,https://github.com/pandas-dev/pandas/pull/51518,"import timeit
import statistics

import pandas as pd

ser = pd.Series(0, index=range(10_000_000))

def workload():
    ser + range(len(ser))
    
runtimes = timeit.repeat(workload, number=1, repeat=50)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.6663323371566366
Before SD: 0.015852808660325384
After Mean: 0.024847857238491998
After SD: 0.0015805804135367839
Improvement: -96.27%",,224,docker.io/sweperf/sweperf:pandas-dev__pandas-51518,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51518,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51518 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-02-20 22:31:20,8d2a4e11d136af439de92ef1a970a1ae0edde4dc,1.5
,APPROVED,pandas-dev__pandas-51549,https://github.com/pandas-dev/pandas/pull/51549,"import timeit
import statistics

import pandas as pd
import numpy as np

dtypes = [""float"", ""Float64"", ""float64[pyarrow]""]

dfs = []
for dtype in dtypes:
    df = pd.DataFrame(
        np.random.randn(100000, 2),
        columns=list(""AB""),
        dtype=dtype,
    )
    df.iloc[:100, 0] = None
    df.iloc[:200, 1] = None
    df.iloc[-100:, 0] = None
    df.iloc[-200:, 1] = None
    dfs.append(df)

def workload():
    for df in dfs:
        df.first_valid_index()
        df.last_valid_index()
        
runtimes = timeit.repeat(workload, number=5, repeat=50)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.36663965788378844
Before SD: 0.007228786989413735
After Mean: 0.015659905402862932
After SD: 0.00030499625049761037
Improvement: -95.73%",,908,docker.io/sweperf/sweperf:pandas-dev__pandas-51549,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51549,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51549 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-02-22 1:46:50,14a315cfd5e0b23228dc568d73eb1c568cf6fc46,1.5
,APPROVED,pandas-dev__pandas-51574,https://github.com/pandas-dev/pandas/pull/51574,"import timeit
import statistics

import pandas as pd
import numpy as np

dtypes = [""float64"", ""Float64"", ""float64[pyarrow]""]

dfs_and_masks = []
for dtype in dtypes:
    df = pd.DataFrame(np.random.randn(100_000, 10), dtype=dtype)
    mask = df < 0
    dfs_and_masks.append((df, mask))

def workload():
    for df, mask in dfs_and_masks:
        for inplace in [True, False]:
            df.where(mask, other=0.0, inplace=inplace)

runtimes = timeit.repeat(workload, number=5, repeat=50)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.0187906428182032
Before SD: 0.004747004886429792
After Mean: 0.3715902622335125
After SD: 0.003636768498867217
Improvement: -63.53%",,908,docker.io/sweperf/sweperf:pandas-dev__pandas-51574,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51574,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51574 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-02-23 0:21:36,b99e2961e1aa89f80dbc9561d8ed47afbe4bc822,1.5
,APPROVED,pandas-dev__pandas-51592,https://github.com/pandas-dev/pandas/pull/51592,"
import timeit
import statistics

import pandas as pd
import numpy as np
import pandas._testing as tm
import itertools

m = 50
n = 1000
cols = [""jim"", ""joe"", ""jolie"", ""joline"", ""jolia""]

vals = [
    np.random.randint(0, 10, n),
    np.random.choice(list(""abcdefghij""), n),
    np.random.choice(pd.date_range(""20141009"", periods=10).tolist(), n),
    np.random.choice(list(""ZYXWVUTSRQ""), n),
    np.random.randn(n),
]
vals = list(map(tuple, zip(*vals)))

# bunch of keys for testing
keys = [
    np.random.randint(0, 11, m),
    np.random.choice(list(""abcdefghijk""), m),
    np.random.choice(pd.date_range(""20141009"", periods=11).tolist(), m),
    np.random.choice(list(""ZYXWVUTSRQP""), m),
]
keys = list(map(tuple, zip(*keys)))
keys += list(map(lambda t: t[:-1], vals[:: n // m]))


# covers both unique index and non-unique index
df = pd.DataFrame(vals, columns=cols)
a = pd.concat([df, df])
b = df.drop_duplicates(subset=cols[:-1])


def validate(mi, df, key):
    # check indexing into a multi-index before & past the lexsort depth

    mask = np.ones(len(df)).astype(""bool"")

    # test for all partials of this key
    for i, k in enumerate(key):
        mask &= df.iloc[:, i] == k

        if not mask.any():
            assert key[: i + 1] not in mi.index
            continue

        assert key[: i + 1] in mi.index
        right = df[mask].copy()

        if i + 1 != len(key):  # partial key
            return_value = right.drop(cols[: i + 1], axis=1, inplace=True)
            assert return_value is None
            return_value = right.set_index(cols[i + 1 : -1], inplace=True)
            assert return_value is None
            tm.assert_frame_equal(mi.loc[key[: i + 1]], right)

        else:  # full key
            return_value = right.set_index(cols[:-1], inplace=True)
            assert return_value is None
            if len(right) == 1:  # single hit
                right = pd.Series(
                    right[""jolia""].values, name=right.index[0], index=[""jolia""]
                )
                tm.assert_series_equal(mi.loc[key[: i + 1]], right)
            else:  # multi hit
                tm.assert_frame_equal(mi.loc[key[: i + 1]], right)


def workload():
    for lexsort_depth, key, frame in itertools.product(list(range(5)), keys, [a, b]):
        if lexsort_depth == 0:
            df = frame.copy()
        else:
            df = frame.sort_values(by=cols[:lexsort_depth])
        
        mi = df.set_index(cols[:-1])
        assert not mi.index._lexsort_depth < lexsort_depth
        validate(mi, df, key)

runtimes = timeit.repeat(workload, number=1, repeat=3)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 20.00204855632425
Before SD: 0.03506428002807868
After Mean: 10.35007483131873
After SD: 0.047930397963624714
Improvement: -48.25%",,908,docker.io/sweperf/sweperf:pandas-dev__pandas-51592,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51592,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51592 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-02-23 17:43:34,ade04183a0148a0b9b579938c13d1bdf87743457,1.5
,APPROVED,pandas-dev__pandas-51630,https://github.com/pandas-dev/pandas/pull/51630,"import timeit
import statistics

import pandas as pd
import numpy as np

dtype = 'float64[pyarrow]'
data = np.random.randn(10000, 1000)
data[:, 600:800] = np.nan
data[800:1000, 4000:5000] = np.nan
df = pd.DataFrame(data, dtype=dtype)

def workload():
    df.isna()

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.11742900296347215
Before SD: 0.0014020298992823306
After Mean: 0.03256968887755647
After SD: 0.0015426197597146567
Improvement: -72.26%",,61,docker.io/sweperf/sweperf:pandas-dev__pandas-51630,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51630,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51630 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-02-25 14:32:05,f94386498f45de70d743a08ebcc334a3ef7c198d,1.5
,APPROVED,pandas-dev__pandas-51722,https://github.com/pandas-dev/pandas/pull/51722,"import timeit
import statistics

import numpy as np
import pandas as pd

nrows = 10**7
ncols=10
ngroups = 6

qs = [0.5, 0.75]
arr = np.random.randn(nrows, ncols)
df = pd.DataFrame(arr)
df[""A""] = np.random.randint(ngroups, size=nrows)

gb = df.groupby(""A"")

def workload():
    v1 = gb.quantile(qs)
    
runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 29.74782665069215
Before SD: 0.44215799527938554
After Mean: 4.821423778106691
After SD: 0.06786296989144353
Improvement: -83.79%",,921,docker.io/sweperf/sweperf:pandas-dev__pandas-51722,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51722,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51722 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-01 21:27:33,d2d17e13cdbf7b2d343ae5917362a7a144946217,1.5
,APPROVED,pandas-dev__pandas-51738,https://github.com/pandas-dev/pandas/pull/51738,"import timeit
import statistics

import pandas as pd
import numpy as np

idx = pd.Index(np.arange(1_000_000))
idx.is_unique, idx.is_monotonic_increasing

def workload():
    idx[:].is_unique
    idx[:].is_monotonic_increasing
    idx[:].get_loc(999_999)

runtimes = timeit.repeat(workload, number=5, repeat=200)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.14744159606157337
Before SD: 0.001872408616727525
After Mean: 6.25751256593503e-05
After SD: 4.783471179078242e-06
Improvement: -99.96%",,638,docker.io/sweperf/sweperf:pandas-dev__pandas-51738,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51738,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51738 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-02 8:11:12,056edfaa6a4317280d9e10bb72e738ba5049ac37,1.5
,APPROVED,pandas-dev__pandas-51784,https://github.com/pandas-dev/pandas/pull/51784,"import timeit
import statistics

import pandas as pd
import numpy as np
from time import time

import string
import random

rows = 500000
temp = np.random.randint(10**6, size=(rows, 3))
symbols = string.ascii_uppercase + string.digits
string_col = [''.join(random.choices(symbols, k=16)) for _ in range(rows)]
res = np.concatenate((temp, np.array([string_col]).T), axis=1)

df = pd.DataFrame(res)

def _format(x):
    vals = x.values
    if len(vals) > 2:
        return '-'.join(map(str, vals[:-1]))
    return np.nan

gb = df.groupby(3, sort=False)
func = {""col1"": (2, _format), ""col2"": (1, _format)}

def workload():
   gb.agg(**func)
   
runtimes = timeit.repeat(workload, number=1, repeat=5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 9.830007454985752
Before SD: 0.04731529399706945
After Mean: 8.990286970406306
After SD: 0.040593561004120024
Improvement: -8.54%",,914,docker.io/sweperf/sweperf:pandas-dev__pandas-51784,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51784,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-51784 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-04 13:23:42,1f7a7f20b1a3aeb66527df0d9a3682159e56917e,1.5
,APPROVED,pandas-dev__pandas-52054,https://github.com/pandas-dev/pandas/pull/52054,"import timeit
import statistics

import pandas as pd
import numpy as np

arr = np.arange(1_000_000, dtype=""float32"")

def workload():
    pd.DataFrame(arr, dtype=""int32"", copy=True)
    
runtimes = timeit.repeat(workload, number=1, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.003746713061234914
Before SD: 0.00024498542464225785
After Mean: 0.001175644923292566
After SD: 0.00010110195603280783
Improvement: -68.62%",,341,docker.io/sweperf/sweperf:pandas-dev__pandas-52054,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52054,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52054 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-17 17:19:02,0baa925f8244fbe0c4735776be4e42e7b6c93418,1.5
,APPROVED,pandas-dev__pandas-52057,https://github.com/pandas-dev/pandas/pull/52057,"import timeit
import statistics

import pandas as pd
import numpy as np
from io import StringIO

rng = pd.date_range(""1/1/2000"", periods=1000)

dt_format = ""%Y-%m-%d %H:%M:%S""
string_data = ""\n"".join(rng.strftime(dt_format).tolist())

def workload():
    pd.read_csv(
        StringIO(string_data),
        header=None,
        names=[""foo""],
        parse_dates=[""foo""],
        infer_datetime_format=True,
    )

# Measure runtime
runtimes = timeit.repeat(workload, number=1, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00232518515966367
Before SD: 7.214034241141739e-05
After Mean: 0.0014779905966192017
After SD: 6.877721433463883e-05
Improvement: -36.44%",,22,docker.io/sweperf/sweperf:pandas-dev__pandas-52057,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52057,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52057 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-17 18:48:12,fb282b64331e48741660fbebd2bf948213fb2741,1.5
,APPROVED,pandas-dev__pandas-52109,https://github.com/pandas-dev/pandas/pull/52109,"
import timeit
import statistics

import pyarrow as pa
import pandas as pd
from pandas.core.internals.blocks import get_block_type

def workload():
    get_block_type(pd.ArrowDtype(pa.float64()))
    get_block_type(pd.Float64Dtype())

runtimes = timeit.repeat(workload, number=5, repeat=10**6)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.6551989031548145e-05
Before SD: 2.9688906508633322e-06
After Mean: 4.267836783430539e-06
After SD: 1.3307510591090577e-06
Improvement: -74.22%",,915,docker.io/sweperf/sweperf:pandas-dev__pandas-52109,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52109,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52109 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-21 22:13:26,f2cd62a0263ee51d036f23c76bc9df5c44fb33a9,1.5
,APPROVED,pandas-dev__pandas-52111,https://github.com/pandas-dev/pandas/pull/52111,"
import timeit
import statistics

import pandas as pd

rg = pd.date_range(""2020-01-01"", periods=100_000, freq=""s"")

ts_ns = pd.Timestamp(""1996-01-01 00:00:00.00000000000"")
ts_s = pd.Timestamp(""1996-01-01"")

def workload():
    rg < ts_s

runtimes = timeit.repeat(workload, number=5, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.022358149564883207
Before SD: 0.0001914971854908517
After Mean: 0.000595405220403336
After SD: 1.5584494091765188e-05
Improvement: -97.34%",,98,docker.io/sweperf/sweperf:pandas-dev__pandas-52111,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52111,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52111 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-21 23:02:11,f2cd62a0263ee51d036f23c76bc9df5c44fb33a9,1.5
,APPROVED,pandas-dev__pandas-52120,https://github.com/pandas-dev/pandas/pull/52120,"
import timeit
import statistics

import pandas as pd
import numpy as np

np.random.seed(94356)

arr = np.arange(5).repeat(10**5)
grps = np.random.randint(0, 3, size=arr.size)

cat = pd.Categorical(arr, ordered=True)
ser = pd.Series(cat)
gb = ser.groupby(grps)

def workload():
    gb.min()
    gb.first()

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.006380511379742529
Before SD: 0.0005028079751030553
After Mean: 0.0028703260975889862
After SD: 0.0001714512970069706
Improvement: -55.01%",,915,docker.io/sweperf/sweperf:pandas-dev__pandas-52120,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52120,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52120 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-22 17:56:21,57c49405f2bd31f797991f2a36dfa0036cb5adfe,1.5
,APPROVED,pandas-dev__pandas-52132,https://github.com/pandas-dev/pandas/pull/52132,"import timeit
import statistics

import pandas as pd

ser = pd.Series(range(3))

def workload():
    ser.copy()
    

# Measure runtime
runtimes = timeit.repeat(workload, number=1, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.1700225200154819e-05
Before SD: 1.9546266049096285e-06
After Mean: 8.282428999140394e-06
After SD: 1.670032555131723e-06
Improvement: -29.21%",,923,docker.io/sweperf/sweperf:pandas-dev__pandas-52132,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52132,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52132 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-23 3:07:30,445a76d6c85cafc399c7e4f862d1d79a9288f309,1.5
,APPROVED,pandas-dev__pandas-52145,https://github.com/pandas-dev/pandas/pull/52145,"
import timeit
import statistics

import pandas as pd

ser = pd.Series(range(300_000))

def workload():
    ser[:30]

runtimes = timeit.repeat(workload, number=1, repeat=10**5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.6806792423594744e-05
Before SD: 4.386037483159938e-06
After Mean: 1.0300697393249721e-05
After SD: 1.99233812273547e-06
Improvement: -38.71%",,915,docker.io/sweperf/sweperf:pandas-dev__pandas-52145,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52145,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52145 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-23 22:02:32,25c1942c394ecbd3281240382728006e50bc28dd,1.5
,APPROVED,pandas-dev__pandas-52256,https://github.com/pandas-dev/pandas/pull/52256,"import timeit
import statistics

import pandas as pd
import numpy as np
import pyarrow as pa

data = np.random.randn(10_000, 10)
dtype = pd.ArrowDtype(pa.float64())
df = pd.DataFrame(data, dtype=dtype)

def workload():
    df.T
    
# Measure runtime
runtimes = timeit.repeat(workload, number=1, repeat=200)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.15246597361256137
Before SD: 0.002434992982010155
After Mean: 0.12286899193102727
After SD: 0.0018223374976681836
Improvement: -19.41%",,914,docker.io/sweperf/sweperf:pandas-dev__pandas-52256,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52256,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52256 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-28 10:42:59,ac993e710b1c5c1adbff23ff62468ae551e3d0b6,1.5
,APPROVED,pandas-dev__pandas-52290,https://github.com/pandas-dev/pandas/pull/52290,"import timeit
import statistics

import numpy as np
import pandas as pd

a = np.random.randint(2000, 2100, size=1000)
b = np.random.randint(2000, 2100, size=1000)

x = pd.core.arrays.period_array(a, freq='B')
y = pd.core.arrays.period_array(b, freq='B')

def workload():
    x._concat_same_type([x, y])
    
# Measure runtime
runtimes = timeit.repeat(workload, number=5, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.0984299250412733e-05
Before SD: 4.030049174749572e-06
After Mean: 1.1814478894812055e-05
After SD: 3.401393477375716e-06
Improvement: -43.70%",,914,docker.io/sweperf/sweperf:pandas-dev__pandas-52290,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52290,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52290 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-03-29 23:05:45,097e70f3f0b89f21c547eb76f7dba0fa53c15afd,1.5
,APPROVED,pandas-dev__pandas-52341,https://github.com/pandas-dev/pandas/pull/52341,"import timeit
import statistics

import numpy as np
import pandas as pd

s = pd.Series(np.random.randint(0, 2, 100000)).astype(bool) 

def workload():
    s.any(skipna=True)
    
# Measure runtime
runtimes = timeit.repeat(workload, number=5, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 6.272789104899857e-05
Before SD: 5.195122836129907e-06
After Mean: 2.5918086133315227e-05
After SD: 3.2395990280195814e-06
Improvement: -58.68%",,916,docker.io/sweperf/sweperf:pandas-dev__pandas-52341,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52341,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52341 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-01 3:58:09,0d6787b32a1542f6877da5fd7d0e2b1712ad0356,1.5
,APPROVED,pandas-dev__pandas-52381,https://github.com/pandas-dev/pandas/pull/52381,"import timeit
import statistics

import numpy as np
import pandas as pd

s = pd.Series(np.random.randint(0, 2, 100000)).astype(bool) 

def workload():
    s.any(skipna=True)
    s.all(skipna=True)
    
# Measure runtime
runtimes = timeit.repeat(workload, number=5, repeat=10**5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 5.2380289225257e-05
Before SD: 4.5997181130694086e-06
After Mean: 3.496707305544987e-05
After SD: 3.825315362876034e-06
Improvement: -33.24%",,916,docker.io/sweperf/sweperf:pandas-dev__pandas-52381,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52381,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52381 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-03 20:20:44,523ab8c1c54fc4d512c22b0eccefab263e8fddaf,1.5
,APPROVED,pandas-dev__pandas-52430,https://github.com/pandas-dev/pandas/pull/52430,"import timeit
import statistics

import pandas as pd
import numpy as np

ser = pd.Series(np.random.randn(10_000_000))

def workload():
    ser.to_numpy(dtype=""float64"", na_value=np.nan, copy=False)

# Measure runtime
runtimes = timeit.repeat(workload, number=5, repeat=10**3)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.13842182098451303
Before SD: 0.0019563095883931045
After Mean: 1.0181482357438654e-05
After SD: 2.5308189186761858e-06
Improvement: -99.99%",,917,docker.io/sweperf/sweperf:pandas-dev__pandas-52430,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52430,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52430 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-05 0:03:05,3ce07cb46986ce59427b601c6878c81633e436eb,2
,APPROVED,pandas-dev__pandas-52469,https://github.com/pandas-dev/pandas/pull/52469,"import timeit
import statistics

import numpy as np
import pandas as pd
import tempfile
import os

n = 5000000

s_samples = [f""s_{i}"" for i in range(1, 101)]
i_samples = [f""i_{i}"" for i in range(1, 201)]
bool_samples = [True, False]

ssamples = np.random.choice(s_samples, n)
isamples = np.random.choice(i_samples, n)
d_values = np.random.randn(3, n)
b_values = np.random.choice(bool_samples, n)

df = pd.DataFrame(
    dict(s=ssamples, i=isamples, v1=d_values[0], v2=d_values[1], v3=d_values[2], f1=b_values, f2=b_values)
)

temp_path = tempfile.NamedTemporaryFile(suffix="".csv"", delete=False).name

df.to_csv(temp_path, index=None)

df_new = pd.read_csv(temp_path, engine=""pyarrow"", dtype_backend=""pyarrow"")

def workload():
    df_new.groupby(""s"")[""v1""].sum()

runtimes = timeit.repeat(workload, number=1, repeat=10)

os.remove(temp_path)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.29094323779572734
Before SD: 0.004550251052732346
After Mean: 0.1226489917084109
After SD: 0.0022502130739173714
Improvement: -57.84%",,917,docker.io/sweperf/sweperf:pandas-dev__pandas-52469,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52469,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52469 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-05 22:29:34,b6353699b847def984193296e778d166a5a5e464,2
,APPROVED,pandas-dev__pandas-52525,https://github.com/pandas-dev/pandas/pull/52525,"import timeit
import statistics

import numpy as np
import pandas as pd

N = 10_000_000
data = np.random.randn(N)
arr1 = pd.array(data, dtype=""float64[pyarrow]"")
arr2 = pd.array(data, dtype=""float64[pyarrow]"")
arr2[::1000] = None
arr3 = pd.array([None] * N, dtype=""null[pyarrow]"")

def workload():
    arr1.to_numpy(""float64"")
    arr2.to_numpy(""float64"", na_value=np.nan)
    arr3.to_numpy(""float64"", na_value=np.nan)

# Measure runtime
runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.9201210433989764
Before SD: 0.006137362973126843
After Mean: 0.2859882301674224
After SD: 0.0023855625543136487
Improvement: -85.11%",,918,docker.io/sweperf/sweperf:pandas-dev__pandas-52525,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52525,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52525 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-07 19:54:08,92f837fcbb941852b2754fbd83fc003f68348c15,2
,APPROVED,pandas-dev__pandas-52541,https://github.com/pandas-dev/pandas/pull/52541,"import timeit
import statistics

import numpy as np
import pandas as pd


N = 10_000
axis = 1
sort = False
structures = [""monotonic"", ""non_monotonic"", ""has_na""]
dtypes = [""int64[pyarrow]"", ""Int64""]


series_registry = []
for dtype in dtypes:
    for structure in structures:
        vals = np.arange(N, dtype=np.int64)
        idx = pd.Index(vals, dtype=dtype)

        if structure == ""monotonic"":
            idx = idx.sort_values()
        elif structure == ""non_monotonic"":
            idx = idx[::-1]
        elif structure == ""has_na"":
            if not idx._can_hold_na:
                continue
            idx = pd.Index([None], dtype=dtype).append(idx)
        else:
            continue

        series_list = [pd.Series(i, idx[:-i]) for i in range(1, 6)]
        series_registry.append((dtype, series_list))


# One single workload that runs all pyarrow concat cases
def workload():
    for dtype, series_list in series_registry:
        pd.concat(series_list, axis=axis, sort=sort)

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.2980660138500389
Before SD: 0.0023241641175667897
After Mean: 0.0685087961651152
After SD: 0.0013649634177927198
Improvement: -77.02%",,78,docker.io/sweperf/sweperf:pandas-dev__pandas-52541,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52541,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52541 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-08 17:19:14,3c447454c7daaa8d245b8386d7ba2b2da70f7e73,2
,APPROVED,pandas-dev__pandas-52548,https://github.com/pandas-dev/pandas/pull/52548,"import timeit
import statistics

import pandas as pd
import pyarrow as pa

import tempfile
import os

dr = pd.Series(pd.date_range(""2019-12-31"", periods=1_000_000, freq=""s"").astype(pd.ArrowDtype(pa.timestamp(unit=""ns""))), name=""a"")

temp_path = tempfile.NamedTemporaryFile(suffix="".csv"", delete=False).name
dr.to_csv(temp_path)

def workload():
    pd.read_csv(temp_path, engine=""pyarrow"", dtype_backend=""pyarrow"", parse_dates=[""a""])
    
runtimes = timeit.repeat(workload, number=1, repeat=10)

os.remove(temp_path)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.4443974757974503
Before SD: 0.01393992215214724
After Mean: 0.03913611331372522
After SD: 0.006262501332212352
Improvement: -98.40%",,76,docker.io/sweperf/sweperf:pandas-dev__pandas-52548,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52548,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52548 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-08 22:44:16,7187e675002fe88e639b8c9c62a8625a1dd1235b,2
,APPROVED,pandas-dev__pandas-52672,https://github.com/pandas-dev/pandas/pull/52672,"import timeit
import statistics

import numpy as np
import pandas as pd

num_rows = 100
num_cols = 25_000
num_dfs = 7

def generate_dataframes(num_dfs, num_rows, num_cols, all_cols):
    df_list = []
    for i in range(num_dfs):
        index = ['i%d'%i for i in range(i*num_rows, (i+1)*num_rows)]
        columns = np.random.choice(all_cols, num_cols, replace=False)
        values = np.random.uniform(-100, 100, [num_rows, num_cols])
        df_list.append(pd.DataFrame(values, index=index, columns=columns))
    return df_list

num_all_cols = num_cols * num_dfs * 4 // 5
all_cols = ['c%i'%i for i in range(num_all_cols)]
df_list = generate_dataframes(num_dfs, num_rows, num_cols, all_cols)

def workload():
    pd.concat(df_list)
    
runtimes = timeit.repeat(workload, number=1, repeat=5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 7.0008005423937
Before SD: 0.15949910587598373
After Mean: 6.216340103198308
After SD: 0.19333838289740093
Improvement: -11.21%",,148,docker.io/sweperf/sweperf:pandas-dev__pandas-52672,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52672,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52672 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-14 17:11:40,f9608250a32a3eddbd3c52741ed5dba250caeaa7,2
,APPROVED,pandas-dev__pandas-52685,https://github.com/pandas-dev/pandas/pull/52685,"import timeit
import statistics

import numpy as np
import pandas as pd

num_rows = 100
num_cols = 50_000
num_dfs = 7

def generate_dataframes(num_dfs, num_rows, num_cols, all_cols, dtype):
    df_list = []
    for i in range(num_dfs):
        index = ['i%d'%i for i in range(i*num_rows, (i+1)*num_rows)]
        columns = np.random.choice(all_cols, num_cols, replace=False)
        values = np.random.uniform(-100, 100, [num_rows, num_cols])
        df_list.append(pd.DataFrame(values, index=index, columns=columns, dtype=dtype))
    return df_list

num_all_cols = num_cols * num_dfs * 4 // 5
all_cols = ['c%i'%i for i in range(num_all_cols)]
df_list_float32 = generate_dataframes(num_dfs, num_rows, num_cols, all_cols, 'float32')
df_list_float64 = generate_dataframes(num_dfs, num_rows, num_cols, all_cols, 'float64')

def workload():
    pd.concat(df_list_float32)
    pd.concat(df_list_float64)
    
runtimes = timeit.repeat(workload, number=1, repeat=3)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 24.704105068417267
Before SD: 0.2923067799915068
After Mean: 1.4699527104035952
After SD: 0.024562768553883094
Improvement: -94.05%",,148,docker.io/sweperf/sweperf:pandas-dev__pandas-52685,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52685,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52685 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-15 19:04:29,9eee1073c2d0602569ca445b7509dedf906f4af5,2
,APPROVED,pandas-dev__pandas-52836,https://github.com/pandas-dev/pandas/pull/52836,"import timeit
import statistics

import pandas as pd
import numpy as np

values = np.random.randn(100000, 4)
values = values.astype(int)
df = pd.DataFrame(values).astype(""Int64"")

def workload():
    df.transpose()

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.5485611165000592
Before SD: 0.010908066406559957
After Mean: 0.6020124968956224
After SD: 0.015409352540048184
Improvement: -76.38%",,139,docker.io/sweperf/sweperf:pandas-dev__pandas-52836,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52836,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52836 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-21 18:53:59,dc830eab5516f6911c894abdb1e3782cb18c503e,2
,APPROVED,pandas-dev__pandas-52928,https://github.com/pandas-dev/pandas/pull/52928,"
import timeit
import statistics

import numpy as np
import pandas as pd
import tempfile
import os

n = 5000000

s_samples = [f""s_{i}"" for i in range(1, 101)]
i_samples = [f""i_{i}"" for i in range(1, 201)]
bool_samples = [True, False]

ssamples = np.random.choice(s_samples, n)
isamples = np.random.choice(i_samples, n)
d_values = np.random.randn(3, n)
b_values = np.random.choice(bool_samples, n)

df = pd.DataFrame(
    dict(s=ssamples, i=isamples, v1=d_values[0], v2=d_values[1], v3=d_values[2], f1=b_values, f2=b_values)
)

temp_path = tempfile.NamedTemporaryFile(suffix="".csv"", delete=False).name

df.to_csv(temp_path, index=None)

df_new = pd.read_csv(temp_path, engine=""pyarrow"", dtype_backend=""pyarrow"")
arr = df_new[""v1""].array._pa_array

def workload():
    pd.Float64Dtype().__from_arrow__(arr)

runtimes = timeit.repeat(workload, number=5, repeat=25)

os.remove(temp_path)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.19809342723805456
Before SD: 0.006601548507589056
After Mean: 0.10658200856531039
After SD: 0.0011800805842831588
Improvement: -46.20%",,8,docker.io/sweperf/sweperf:pandas-dev__pandas-52928,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52928,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-52928 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-26 11:13:35,d182a3495a95c7067c13690cfe037597c3714d5d,2
,APPROVED,pandas-dev__pandas-53013,https://github.com/pandas-dev/pandas/pull/53013,"
import timeit
import statistics

import pandas as pd
import numpy as np

arr = pd.array(np.arange(2), dtype=""Int32"")

def workload():
    arr.reshape(-1, 1)

runtimes = timeit.repeat(workload, number=5, repeat=10**5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.1415049917413852e-05
Before SD: 3.8706804279821824e-06
After Mean: 4.398451704182662e-06
After SD: 3.55598198670996e-07
Improvement: -61.47%",,921,docker.io/sweperf/sweperf:pandas-dev__pandas-53013,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53013,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53013 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-04-30 12:37:28,956b8008e90845093f57c581c97b15297c72090a,2
,APPROVED,pandas-dev__pandas-53088,https://github.com/pandas-dev/pandas/pull/53088,"
import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randint(1, 100, (5_000_000, 5)))
df.groupby([0, 1]).groups

def workload():
    df.groupby([0, 1]).groups

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 2.9569322556024416
Before SD: 0.023195222266561902
After Mean: 1.1267767391982488
After SD: 0.023642344764136167
Improvement: -61.89%",,919,docker.io/sweperf/sweperf:pandas-dev__pandas-53088,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53088,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53088 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-05-04 22:59:39,86a4ee01c7899ef454d35b95cde11e9593921c9d,2
,APPROVED,pandas-dev__pandas-53150,https://github.com/pandas-dev/pandas/pull/53150,"
import timeit
import statistics

import pandas as pd
import pandas._testing as tm
import pyarrow as pa

N = 1_000_000
s1 = pd.Series(tm.makeStringIndex(N), dtype=pd.ArrowDtype(pa.string()))
s2 = pd.Series(tm.makeStringIndex(N), dtype=pd.ArrowDtype(pa.string()))

def workload():
    s1 + s2
    s1 + ""abc""

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.15005914959590883
Before SD: 0.0012756770934504987
After Mean: 0.058485426239203664
After SD: 0.0005428187123229464
Improvement: -61.03%",,10,docker.io/sweperf/sweperf:pandas-dev__pandas-53150,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53150,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53150 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-05-09 0:44:40,824fc8304e6f6f202ee169c7118242374654a4a9,2
,APPROVED,pandas-dev__pandas-53152,https://github.com/pandas-dev/pandas/pull/53152,"import timeit
import statistics

import pandas as pd
import pandas._testing as tm
import pyarrow as pa

N = 1_000_000

ser = pd.Series(tm.makeStringIndex(N), dtype=pd.ArrowDtype(pa.string()))
def workload():
    ser.str.get(1)

runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.20920769709843443
Before SD: 0.00260333253381931
After Mean: 0.13673810637602582
After SD: 0.0006948997386019328
Improvement: -34.64%",,1,docker.io/sweperf/sweperf:pandas-dev__pandas-53152,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53152,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53152 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-05-09 10:43:27,94e868a76f5dfd30e84469b47a316699eb1f083d,2
,APPROVED,pandas-dev__pandas-53231,https://github.com/pandas-dev/pandas/pull/53231,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 10_000
unit_pairs = [
    (""ns"", ""ns""),
    (""ms"", ""ms""),
    (""ns"", ""ms""),
]
timezones = [None, ""Europe/Brussels""]

merge_registry = []

for units in unit_pairs:
    for tz in timezones:
        unit_left, unit_right = units
        keys = pd.Series(pd.date_range(""2012-01-01"", freq=""T"", periods=N, tz=tz))

        left = pd.DataFrame({
            ""key"": keys.sample(N * 10, replace=True).dt.as_unit(unit_left),
            ""value1"": np.random.randn(N * 10),
        })
        right = pd.DataFrame({
            ""key"": keys[:8000].dt.as_unit(unit_right),
            ""value2"": np.random.randn(8000),
        })

        merge_registry.append((left, right))


def workload():
    for left, right in merge_registry:
        pd.merge(left, right)


runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 1.3836005068203667
Before SD: 0.0070617969136500605
After Mean: 0.2506379101786297
After SD: 0.0061612867117170214
Improvement: -81.89%",,43,docker.io/sweperf/sweperf:pandas-dev__pandas-53231,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53231,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53231 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-05-15 8:20:31,a1f050aef65c218ebe1ca12adcf011b030553042,2
,APPROVED,pandas-dev__pandas-53368,https://github.com/pandas-dev/pandas/pull/53368,"import timeit
import statistics

import pandas as pd

N = 100_000

idx = pd.Index(range(N), dtype=""timestamp[s][pyarrow]"")
idx2 = idx[::2]

idx3 = pd.Index(range(N), dtype=""duration[s][pyarrow]"")
idx4 = idx[::2]

def workload():
    idx.get_indexer_for(idx2)
    idx3.get_indexer_for(idx4)

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 3.440856686948682
Before SD: 0.07367842730063268
After Mean: 2.9917026068095582
After SD: 0.009853168161682765
Improvement: -13.05%",,921,docker.io/sweperf/sweperf:pandas-dev__pandas-53368,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53368,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53368 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-05-24 10:40:07,f5a5c8d7f0d1501e5d8ff31b3b5f24c916137d9c,2
,APPROVED,pandas-dev__pandas-53585,https://github.com/pandas-dev/pandas/pull/53585,"import timeit
import statistics

import pandas as pd
import pyarrow as pa

N = 10_000
data = [""foo|bar|baz""] * N
ser = pd.Series(data, dtype=pd.ArrowDtype(pa.string()))
def workload():
    ser.str.split(""|"", expand=True)

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.1874286981485784
Before SD: 0.0011154238836082182
After Mean: 0.011322931525646708
After SD: 0.0001562706392398888
Improvement: -93.96%",,85,docker.io/sweperf/sweperf:pandas-dev__pandas-53585,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53585,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53585 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-06-10 10:05:04,7de7f1ccd22bb09328d40c7527e4b8c9af092082,2
,APPROVED,pandas-dev__pandas-53655,https://github.com/pandas-dev/pandas/pull/53655,"import timeit
import statistics

import pandas as pd
import pyarrow as pa

data = [""a|b|c"", ""a|b"", ""a|c"", ""b|c"", ""a"", ""b"", ""c""] * 1000
ser = pd.Series(data, dtype=pd.ArrowDtype(pa.string()))
def workload():
    ser.str.get_dummies() 

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.6790275571169332
Before SD: 0.001511354099442484
After Mean: 0.013628847289364785
After SD: 0.00038069340111314073
Improvement: -97.99%",,1,docker.io/sweperf/sweperf:pandas-dev__pandas-53655,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53655,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53655 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-06-13 22:17:42,abcd440e11d061171b0a4eeb058748629a288568,2
,APPROVED,pandas-dev__pandas-53731,https://github.com/pandas-dev/pandas/pull/53731,"
import timeit
import statistics

import pandas as pd
import numpy as np

N = 1_000_000
methods = ('sum', 'var', 'mean', 'max', 'min')

df = pd.DataFrame(np.random.randn(N, 10), columns=list(""abcdefghij""))
df[""key""] = np.random.randint(0, 100, size=N)

def workload():
    for method in methods:
        df.groupby(""key"").agg(method, engine=""numba"")
    
# Drop first run due to numba JIT.
runtimes = timeit.repeat(workload, number=1, repeat=11)[-10:]

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 52.13825033198227
Before SD: 0.02548914679012315
After Mean: 0.29314350719796495
After SD: 0.013804954228004363
Improvement: -99.44%",,920,docker.io/sweperf/sweperf:pandas-dev__pandas-53731,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53731,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53731 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-06-19 17:51:39,5a54a81dd5d79e8dbc83a2c1776552cf793f3e2c,2
,APPROVED,pandas-dev__pandas-53806,https://github.com/pandas-dev/pandas/pull/53806,"
import timeit
import statistics

import pandas as pd
import numpy as np

import pandas as pd
import numpy as np

mi = pd.MultiIndex.from_product([range(1000), range(1000)], names=[""A"", ""B""])
ser = pd.Series(np.random.randn(len(mi)), index=mi)
df = ser.to_frame(""value"").reset_index()

def workload():
    df.sort_values([""A"", ""B""])
    ser.sort_index()
    ser.groupby([""A"", ""B""]).size()
    ser.unstack()
    
# Drop first run due to numba JIT.
runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.4465285333921202
Before SD: 0.012969629197610565
After Mean: 0.20101281231618487
After SD: 0.006873761304984899
Improvement: -54.98%",,115,docker.io/sweperf/sweperf:pandas-dev__pandas-53806,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53806,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53806 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-06-22 23:31:08,af83376640ec7d86cb3166d0e01052dc6648bfdf,2
,APPROVED,pandas-dev__pandas-53955,https://github.com/pandas-dev/pandas/pull/53955,"import timeit
import statistics

import pandas as pd
import pandas._testing as tm


N = 10**5

level1 = range(1000)
level2_range = range(N // 1000)
level2_dates = pd.date_range(start=""1/1/2000"", periods=N // 1000)
level2_strings = tm.makeStringIndex(N // 1000).values
level2_ea_int = pd.Series(level2_range, dtype=""Int64"")

indexes = {
    ""datetime"": pd.MultiIndex.from_product([level1, level2_dates]),
    ""int"": pd.MultiIndex.from_product([level1, level2_range]),
    ""string"": pd.MultiIndex.from_product([level1, level2_strings]),
    ""ea_int"": pd.MultiIndex.from_product([level1, level2_ea_int]),
}

index_structures = [""monotonic"", ""non_monotonic""]
dtypes = [""datetime"", ""int"", ""string"", ""ea_int""]
methods = [""intersection"", ""union"", ""symmetric_difference""]
sort_options = [False, None]

operation_registry = []

for structure in index_structures:
    for dtype in dtypes:
        for method in methods:
            for sort in sort_options:
                idx = indexes[dtype]
                if structure == ""non_monotonic"":
                    idx = idx[::-1]

                left = idx
                right = idx[:-1] 

                # Save the operation config
                operation_registry.append((left, right, method, sort))

def workload():
    for left, right, method, sort in operation_registry:
        getattr(left, method)(right, sort=sort)

runtimes = timeit.repeat(workload, number=1, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.42769580419990233
Before SD: 0.06043554497161806
After Mean: 0.2503943733056076
After SD: 0.059578418289423445
Improvement: -41.46%",,65,docker.io/sweperf/sweperf:pandas-dev__pandas-53955,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53955,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-53955 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-07-01 0:18:23,457690995ccbfc5b8eee80a0818d62070d078bcf,2
,APPROVED,pandas-dev__pandas-54223,https://github.com/pandas-dev/pandas/pull/54223,"import timeit
import statistics

import pandas as pd
import pyarrow as pa

a = pd.ArrowDtype(pa.float64())
b = pd.ArrowDtype(pa.float64())

def workload():
    a == b

runtimes = timeit.repeat(workload, number=5, repeat=1_000_000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 4.14646962704137e-06
Before SD: 1.3800555815837752e-06
After Mean: 9.721279797959142e-07
After SD: 1.9934995025204265e-07
Improvement: -76.56%",,922,docker.io/sweperf/sweperf:pandas-dev__pandas-54223,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54223,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54223 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-07-22 0:12:28,af76d785ccae9383f5cf9b73e0bce79aa8ae8326,2
,APPROVED,pandas-dev__pandas-54224,https://github.com/pandas-dev/pandas/pull/54224,"
import timeit
import statistics

import pandas as pd
import pyarrow as pa
import numpy as np

values = np.random.randn(1000, 1000)
df = pd.DataFrame(values, dtype=pd.ArrowDtype(pa.float64()))


def workload():
    df.T

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.11581233839970081
Before SD: 0.002761025992180479
After Mean: 0.01829602865036577
After SD: 0.0009491922573181616
Improvement: -84.20%",,153,docker.io/sweperf/sweperf:pandas-dev__pandas-54224,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54224,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54224 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-07-22 0:34:35,3c01ce2af5099a8a830195b2050d3a4036d14ff3,2
,APPROVED,pandas-dev__pandas-54299,https://github.com/pandas-dev/pandas/pull/54299,"import timeit
import statistics

import numpy as np
import pandas as pd


dtype_combos = [
    ((""float64"", ""float64[pyarrow]""), False),
    ((""float64"", ""Float64""), False),
    ((""int64[pyarrow]"", ""float64[pyarrow]""), False),
    ((""int64[pyarrow]"", ""float64[pyarrow]""), True),
    ((""float64"", ""Float64""), True),
    ((""Int64"", ""Float64""), False),
    ((""Int64"", ""Float64""), True),
    ((""float64"", ""float64[pyarrow]""), True),
    ((""Float64"", ""Float64""), True),
    ((""float64[pyarrow]"", ""float64[pyarrow]""), True),
    ((""Float64"", ""Float64""), False),
    ((""float64[pyarrow]"", ""float64[pyarrow]""), False),
]

astype_registry = []

for (from_dtype, to_dtype), copy in dtype_combos:
    if from_dtype.startswith(""float"") or from_dtype in (""Float64"",):
        data = np.random.randn(100, 100)
    elif from_dtype.startswith(""int"") or from_dtype in (""Int64"",):
        data = np.random.randint(0, 1000, size=(100, 100))
    else:
        continue

    df = pd.DataFrame(data, dtype=from_dtype)
    astype_registry.append((df, to_dtype, copy))

def workload():
    for df, to_dtype, copy in astype_registry:
        df.astype(to_dtype, copy=copy)

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.5568005729810102
Before SD: 0.0029325651862389893
After Mean: 0.19812631999899166
After SD: 0.0025435674846405825
Improvement: -64.42%",,922,docker.io/sweperf/sweperf:pandas-dev__pandas-54299,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54299,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54299 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-07-29 0:35:57,d75e26b922ba1bc4f272f9ebf4e1d46572b1e183,2
,APPROVED,pandas-dev__pandas-54508,https://github.com/pandas-dev/pandas/pull/54508,"import timeit
import statistics

import pandas as pd
import numpy as np

data = np.random.randn(4, 10_000)

df_wide1 = pd.DataFrame(data, dtype=""float64[pyarrow]"")
df_wide2 = pd.DataFrame(data, dtype=""Float64"")

def workload():
    df_wide1.iloc[1]
    df_wide2.iloc[1]

runtimes = timeit.repeat(workload, number=1, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.32017961324600036
Before SD: 0.003384874703046074
After Mean: 0.06129630195791833
After SD: 0.002222772540537045
Improvement: -80.86%",,152,docker.io/sweperf/sweperf:pandas-dev__pandas-54508,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54508,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54508 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-08-12 1:41:30,62227895d26bfccfc78260ce0dddaebeab0672fe,2
,APPROVED,pandas-dev__pandas-54509,https://github.com/pandas-dev/pandas/pull/54509,"import timeit
import statistics

import pandas as pd
import numpy as np

df_wide = pd.DataFrame(np.random.randn(4, 10_000), dtype=""float64[pyarrow]"")

def workload():
    df_wide.sum()

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.7668205399881117
Before SD: 0.005411221355014594
After Mean: 0.5380923427001107
After SD: 0.0060703083181577544
Improvement: -29.83%",,100,docker.io/sweperf/sweperf:pandas-dev__pandas-54509,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54509,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54509 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-08-12 2:24:46,62227895d26bfccfc78260ce0dddaebeab0672fe,2
,APPROVED,pandas-dev__pandas-54765,https://github.com/pandas-dev/pandas/pull/54765,"import timeit
import statistics

import pandas as pd
import numpy as np


size = 5 * 10**5
rng = np.arange(0, 10**13, 10**7)

stamps = np.datetime64(""now"").view(""i8"") + rng

idx1 = np.sort(np.random.choice(stamps, size, replace=False))
idx2 = np.sort(np.random.choice(stamps, size, replace=False))
ts1 = pd.Series(np.random.randn(size), idx1)
ts2 = pd.Series(np.random.randn(size), idx2)

def workload():
    ts1 + ts2
    ts1.align(ts2, join=""left"")
        
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.21313562274794096
Before SD: 0.00786492272524998
After Mean: 0.2112933228316251
After SD: 0.003051702283007727
Improvement: -0.86%",,920,docker.io/sweperf/sweperf:pandas-dev__pandas-54765,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54765,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54765 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-08-26 1:45:57,48f5a961cb58b535e370c5688a336bc45493e404,2
,APPROVED,pandas-dev__pandas-54835,https://github.com/pandas-dev/pandas/pull/54835,"import timeit
import statistics

import pandas as pd
import pandas._testing as tm


N = 10**5

level1 = range(1000)
level2_range = range(N // 1000)
level2_dates = pd.date_range(start=""1/1/2000"", periods=N // 1000)
level2_strings = tm.makeStringIndex(N // 1000).values
level2_ea_int = pd.Series(level2_range, dtype=""Int64"")

indexes = {
    ""datetime"": pd.MultiIndex.from_product([level1, level2_dates]),
    ""int"": pd.MultiIndex.from_product([level1, level2_range]),
    ""string"": pd.MultiIndex.from_product([level1, level2_strings]),
    ""ea_int"": pd.MultiIndex.from_product([level1, level2_ea_int]),
}

index_structures = [""monotonic"", ""non_monotonic""]
dtypes = [""datetime"", ""int"", ""string"", ""ea_int""]
methods = [""intersection"", ""union"", ""symmetric_difference""]
sort_options = [None]

operation_registry = []

for structure in index_structures:
    for dtype in dtypes:
        for method in methods:
            for sort in sort_options:
                idx = indexes[dtype]
                if structure == ""non_monotonic"":
                    idx = idx[::-1]

                left = idx
                right = idx[:-1] 

                # Save the operation config
                operation_registry.append((left, right, method, sort))

def workload():
    for left, right, method, sort in operation_registry:
        getattr(left, method)(right, sort=sort)

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.8803832570859231
Before SD: 0.02910564810423502
After Mean: 0.49280859319493175
After SD: 0.02913071318839529
Improvement: -44.02%",,111,docker.io/sweperf/sweperf:pandas-dev__pandas-54835,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54835,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54835 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-08-29 2:12:34,3c041bc14ba88a6dd67ff3a032afa32379869332,2
,APPROVED,pandas-dev__pandas-54883,https://github.com/pandas-dev/pandas/pull/54883,"import timeit
import statistics

import pandas as pd
import numpy as np

mi = pd.MultiIndex.from_product([np.arange(1000)] * 2)
df = pd.DataFrame(np.random.randn(len(mi)), index=mi)

def workload():
    df.sort_index()
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.23109561274119186
Before SD: 0.0058068968992015715
After Mean: 0.002927001875359565
After SD: 0.00146551054039456
Improvement: -98.73%",,90,docker.io/sweperf/sweperf:pandas-dev__pandas-54883,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54883,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-54883 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-08-30 23:01:46,2bca01853c84d6b18b3e841f70e574de819857df,2
,APPROVED,pandas-dev__pandas-55084,https://github.com/pandas-dev/pandas/pull/55084,"import timeit
import statistics

import numpy as np
import pandas as pd
import pandas._testing as tm

N = 10_000
dtypes = [
    ""datetime64[ns]"",
    ""int64"",
    ""Int64"",
    ""int64[pyarrow]"",
    ""string[python]"",
    ""string[pyarrow]"",
]
structures = [""monotonic"", ""non_monotonic"", ""has_na""]
axes = [0, 1]
sorts = [True, False]

series_registry = []


for dtype in dtypes:
    for structure in structures:
        for axis in axes:
            for sort in sorts:
                if dtype == ""datetime64[ns]"":
                    vals = pd.date_range(""1970-01-01"", periods=N)
                elif dtype in (""int64"", ""Int64"", ""int64[pyarrow]""):
                    vals = np.arange(N, dtype=np.int64)
                elif dtype in (""string[python]"", ""string[pyarrow]""):
                    vals = tm.makeStringIndex(N)
                else:
                    continue

                idx = pd.Index(vals, dtype=dtype)

                if structure == ""monotonic"":
                    idx = idx.sort_values()
                elif structure == ""non_monotonic"":
                    idx = idx[::-1]
                elif structure == ""has_na"":
                    if not idx._can_hold_na:
                        continue
                    idx = pd.Index([None], dtype=dtype).append(idx)
                else:
                    continue

                # Build a list of Series
                series_list = [pd.Series(i, idx[:-i]) for i in range(1, 6)]
                series_registry.append((series_list, axis, sort))

        
def workload():
    for series_list, axis, sort in series_registry:
        pd.concat(series_list, axis=axis, sort=sort)
            
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.0846222105860943
Before SD: 0.01436798772222063
After Mean: 0.801979253544705
After SD: 0.013547719206888846
Improvement: -26.06%",,77,docker.io/sweperf/sweperf:pandas-dev__pandas-55084,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55084,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55084 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-09-11 1:26:52,723feb984e6516e3e1798d3c4440c844b12ea18f,2.1
,APPROVED,pandas-dev__pandas-55131,https://github.com/pandas-dev/pandas/pull/55131,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 1_000_000

df = pd.DataFrame(
    {
        ""group"": np.arange(N//1000).repeat(1000),
        ""timestamp"": pd.array(np.arange(N), dtype=""timestamp[ns][pyarrow]""),
        ""duration"": pd.array(np.arange(N), dtype=""duration[s][pyarrow]""),
    }
)

gb = df.groupby(""group"")

def workload():
    gb[""timestamp""].max()
    gb[""duration""].max()
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.7038666595780524
Before SD: 0.003702869334812056
After Mean: 0.038196630278253
After SD: 0.0015342011892131382
Improvement: -94.57%",,2,docker.io/sweperf/sweperf:pandas-dev__pandas-55131,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55131,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55131 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-09-13 22:04:06,13b132e7d154cee2b6daf3133a283d745fee4def,2.1
,APPROVED,pandas-dev__pandas-55515,https://github.com/pandas-dev/pandas/pull/55515,"
import timeit
import statistics

import pandas as pd
import numpy as np
import tempfile
import os

try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm


N = 10_000
C = 5000

temp_path = tempfile.NamedTemporaryFile(suffix="".dta"", delete=False).name


df = pd.DataFrame(
    np.random.randn(N, C),
    columns=[f""float{i}"" for i in range(C)],
    index=pd.date_range(""20000101"", periods=N, freq=""H""),
)
df[""object""] = tm.makeStringIndex(N)
df[""int8_""] = np.random.randint(np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N)
df[""int16_""] = np.random.randint(np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N)
df[""int32_""] = np.random.randint(np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N)
df[""float32_""] = np.array(np.random.randn(N), dtype=np.float32)

for i in range(10):
    missing_data = np.random.randn(N)
    missing_data[missing_data < 0] = np.nan
    df[f""missing_{i}""] = missing_data

convert_dates_arg = {""index"": ""tc""}
df.to_stata(temp_path, convert_dates=convert_dates_arg)


def workload():
    pd.read_stata(temp_path)


runtimes = timeit.repeat(workload, number=1, repeat=5)

os.remove(temp_path)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.2017833039863035
Before SD: 0.009410074889813522
After Mean: 0.8795856187934987
After SD: 0.010874655170799375
Improvement: -60.05%",,925,docker.io/sweperf/sweperf:pandas-dev__pandas-55515,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55515,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55515 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-10-14 5:06:49,0021d241c6aa1b8db91151361b48d7864201fd01,2.1
,APPROVED,pandas-dev__pandas-55736,https://github.com/pandas-dev/pandas/pull/55736,"import timeit
import statistics

import pandas as pd
try:
    import pandas._testing as tm
except ImportError:
    import pandas.util.testing as tm

def test(s):
    s.str.count(""A"")
    s.str.endswith(""A"")
    s.str.rfind(""[A-Z]+"")
    s.str.fullmatch(""A"")
    s.str.get(0)
    s.str.len()
    s.str.match(""A"")
    s.str.normalize(""NFC"")
    s.str.replace(""A"", ""\x01\x01"")
    s.str.slice(5, 15, 2)
    s.str.startswith(""A"")
    s.str.strip(""A"")
    s.str.rstrip(""A"")
    s.str.lstrip(""A"")
    s.str.upper()
    s.str.lower()
    s.str.zfill(10)
    s.str.isalpha()
    s.str.isdecimal()
    s.str.isdigit()
    s.str.islower()
    s.str.isnumeric()
    s.str.isspace()
    s.str.istitle()
    s.str.isupper()

series = []
for dtype in ['str', 'string[python]']:
    series.append(pd.Series(tm.makeStringIndex(10 ** 5), dtype=dtype))
    
def workload():
    for s in series:
        test(s)

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 4.070095866912743
Before SD: 0.01592645243833165
After Mean: 3.658759930592496
After SD: 0.013329541372446447
Improvement: -10.11%",,7,docker.io/sweperf/sweperf:pandas-dev__pandas-55736,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55736,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55736 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-10-27 20:10:06,ef52feaf66386e77436cd326b957b58cb33e0126,2.1
,APPROVED,pandas-dev__pandas-55811,https://github.com/pandas-dev/pandas/pull/55811,"import timeit
import statistics

import pandas as pd
import numpy as np

n_days = 300

N = 1_000_000

mi1 = pd.MultiIndex.from_arrays([np.ones(N), np.ones(N)])
mi2 = pd.MultiIndex.from_tuples([(1, 1)])

def workload():
    mi1.get_indexer_non_unique(mi2)
    
runtimes = timeit.repeat(workload, number=1, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.024345513922162353
Before SD: 0.003470414827768911
After Mean: 0.025157947600819172
After SD: 0.0037289493866084077
Improvement: 3.34%",,946,docker.io/sweperf/sweperf:pandas-dev__pandas-55811,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55811,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55811 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-11-03 13:29:32,7b32c179b8b3929a50c783dc8599e2067e56ad8e,2.1
,APPROVED,pandas-dev__pandas-55839,https://github.com/pandas-dev/pandas/pull/55839,"import timeit
import statistics

import pandas as pd
import numpy as np

mi_int = pd.MultiIndex.from_product(
    [np.arange(1000), np.arange(1000)], names=[""one"", ""two""]
)
obj_index = np.array(
    [
        (0, 10),
        (0, 11),
        (0, 12),
        (0, 13),
        (0, 14),
        (0, 15),
        (0, 16),
        (0, 17),
        (0, 18),
        (0, 19),
    ],
    dtype=object,
)
other_mi_many_mismatches = pd.MultiIndex.from_tuples(
    [
        (-7, 41),
        (-2, 3),
        (-0.7, 5),
        (0, 0),
        (0, 1.5),
        (0, 340),
        (0, 1001),
        (1, -4),
        (1, 20),
        (1, 1040),
        (432, -5),
        (432, 17),
        (439, 165.5),
        (998, -4),
        (998, 24065),
        (999, 865.2),
        (999, 1000),
        (1045, -843),
    ]
)

def workload():
    mi_int.get_indexer(other_mi_many_mismatches, method=""backfill"")
    mi_int.get_indexer(other_mi_many_mismatches, method=""pad"")
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.947718638102524
Before SD: 0.015361167993971962
After Mean: 0.21913744602003135
After SD: 0.006623799290349769
Improvement: -76.88%",,945,docker.io/sweperf/sweperf:pandas-dev__pandas-55839,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55839,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55839 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-11-05 23:13:14,6493d2a4bcf402d5fcb8b5349e70928d8dbf3344,2.1
,APPROVED,pandas-dev__pandas-55898,https://github.com/pandas-dev/pandas/pull/55898,"import timeit
import statistics

import pandas as pd
import numpy as np

vals = np.array([""2016-01-01 02:03:04.567""] * 10**4, dtype=object)
vals2 = np.array([pd.Timestamp(x) for x in vals], dtype=object)
vals3 = np.array([x + ""-01:00"" for x in vals], dtype=object)

fmt = ""%Y-%m-%d %H:%M:%S.%f""
def workload():
    pd.to_datetime(vals, format=fmt, cache=False)
    pd.to_datetime(vals2, format=fmt, cache=False)
    pd.to_datetime(vals3, format=fmt+""%z"", cache=False)
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.3975906438403763
Before SD: 0.0016037101513294392
After Mean: 0.22282188061100897
After SD: 0.0010077680361365025
Improvement: -43.96%",,106,docker.io/sweperf/sweperf:pandas-dev__pandas-55898,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55898,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-55898 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-11-09 20:30:36,38e29ab7d049015b428a880ed0a160b10418fae6,2.1
,APPROVED,pandas-dev__pandas-56061,https://github.com/pandas-dev/pandas/pull/56061,"import timeit
import statistics

import pandas as pd
import numpy as np

unique_values = np.arange(30000, dtype=np.int64)
data = np.random.choice(unique_values, size=1_000_000)
s = pd.Series(data)

fmt = ""%Y-%m-%d %H:%M:%S.%f""
def workload():
    s.groupby(s).nunique()
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.9567590932035819
Before SD: 0.006173551588755927
After Mean: 0.20615356688154862
After SD: 0.0025551321473290486
Improvement: -78.45%",,16,docker.io/sweperf/sweperf:pandas-dev__pandas-56061,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56061,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56061 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-11-19 15:15:03,7012d6a60724bf55d1fc0d03d6c50484aa19fb85,2.1
,APPROVED,pandas-dev__pandas-56062,https://github.com/pandas-dev/pandas/pull/56062,"import timeit
import statistics

import pandas as pd
import numpy as np

nlevels = 2

mi1 = pd.MultiIndex.from_arrays([range(1000000)] * nlevels)
mi2 = pd.MultiIndex.from_product([range(1000)] * nlevels)
df1 = pd.DataFrame(np.random.randn(len(mi1)), index=mi1)
df2 = pd.DataFrame(np.random.randn(len(mi2)), index=mi2)
dfs = [df1, df2]

def workload():
    for df in dfs:
        target = df.index[::10]
        df.loc[target]
        
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.20261503289220856
Before SD: 0.011597377617163819
After Mean: 0.11962009400886017
After SD: 0.009061375603534191
Improvement: -40.96%",,485,docker.io/sweperf/sweperf:pandas-dev__pandas-56062,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56062,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56062 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-11-19 15:57:20,8f0c4d2ca6856cc345917d62c3f989ada00617c0,2.1
,APPROVED,pandas-dev__pandas-56089,https://github.com/pandas-dev/pandas/pull/56089,"import timeit
import statistics

import numpy as np
import pandas as pd
import string

categories = list(string.ascii_letters[:12])
s = pd.Series(
    np.random.choice(categories, size=1000000),
    dtype=pd.CategoricalDtype(categories),
)

def workload():
    pd.get_dummies(s, sparse=False)
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.200867347678286
Before SD: 0.004722813477329899
After Mean: 0.03161978396645281
After SD: 0.0009596165596457049
Improvement: -84.26%",,4,docker.io/sweperf/sweperf:pandas-dev__pandas-56089,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56089,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56089 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-11-20 22:30:45,562523602b4ac10d1b30d813d7c2bfe02adc0469,2.1
,APPROVED,pandas-dev__pandas-56110,https://github.com/pandas-dev/pandas/pull/56110,"import timeit
import statistics

import pandas as pd
import pandas._testing as tm

s = pd.Series(tm.makeStringIndex(10**5), dtype=""string[pyarrow]"")
N = len(s) // 5
s = s[:N].str.join(""|"")

def workload():
    s.str.get_dummies(""|"")
    
runtimes = timeit.repeat(workload, number=1, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.3204293825244531
Before SD: 0.0023313455327651643
After Mean: 0.03144324188586325
After SD: 0.0006462300574442393
Improvement: -90.19%",,3,docker.io/sweperf/sweperf:pandas-dev__pandas-56110,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56110,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56110 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-11-22 0:55:26,34f39a9b053703e39f58ad1d1edc559c2465cf78,2.1
,APPROVED,pandas-dev__pandas-56128,https://github.com/pandas-dev/pandas/pull/56128,"import timeit
import statistics

import pandas as pd

N = 1_000_000

idx = pd._testing.makeStringIndex(N).sort_values()

def workload():
    idx.sort_values()
    idx.sort_values(ascending=False)

runtimes = timeit.repeat(workload, number=5, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 8.419418364501908
Before SD: 0.8110360835426209
After Mean: 0.0008822143176803366
After SD: 0.008298347380223437
Improvement: -99.99%",,55,docker.io/sweperf/sweperf:pandas-dev__pandas-56128,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56128,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56128 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-11-23 1:03:07,68ef1dac651f3012e6da0ec6cab00ac8f0160ed4,2.1
,APPROVED,pandas-dev__pandas-56345,https://github.com/pandas-dev/pandas/pull/56345,"import timeit
import statistics

import pandas as pd
import numpy as np

categories = [f""cat_{i:03}"" for i in range(1000)]

idx1 = pd.CategoricalIndex(np.repeat(categories, 1000), categories=categories)
idx2 = pd.CategoricalIndex(categories[100:200], categories=reversed(categories))

df1 = pd.DataFrame({""val1"": 1}, index=idx1)
df2 = pd.DataFrame({""val2"": 2}, index=idx2)

def workload():
    df1.join(df2)
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.27355116421997083
Before SD: 0.002785000961315163
After Mean: 0.04865476089180447
After SD: 0.0021258523289037425
Improvement: -82.21%",,953,docker.io/sweperf/sweperf:pandas-dev__pandas-56345,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56345,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56345 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-12-05 22:34:16,c99981a0266d12fb00eaa6a43d89322298425d7f,2.1
,APPROVED,pandas-dev__pandas-56508,https://github.com/pandas-dev/pandas/pull/56508,"import timeit
import statistics

import pandas as pd
import numpy as np

np.random.seed(0)

N = 100_000
data = np.arange(N) 
arr = pd.array(np.where(np.random.rand(N) > 0.1, data, np.nan), dtype=""Int32"")

def workload():
    arr._hash_pandas_object(encoding='utf-8', hash_key=""1000000000000000"", categorize=False)

runtimes = timeit.repeat(workload, number=5, repeat=1000)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.18333135525044053
Before SD: 0.00152090549267328
After Mean: 0.005286734436347615
After SD: 0.00018081531441534136
Improvement: -97.12%",,7,docker.io/sweperf/sweperf:pandas-dev__pandas-56508,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56508,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56508 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2023-12-14 21:06:33,1387c4fa09ca7bb13a7f1e13ecd171aebe8fef46,2.1
,APPROVED,pandas-dev__pandas-56806,https://github.com/pandas-dev/pandas/pull/56806,"
import timeit
import statistics

import pandas as pd

import numpy as np

N = 1_000_000
idx = pd.Index(np.arange(N))
indices = np.arange(N)

def workload():
    idx.take(indices)

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0027994717059773395
Before SD: 9.671040096409422e-05
After Mean: 0.0007112371190451086
After SD: 9.377573545875236e-06
Improvement: -74.59%",,954,docker.io/sweperf/sweperf:pandas-dev__pandas-56806,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56806,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56806 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-01-10 3:57:55,5fc2ed2703a1370207f4ebad834e665b6c2ad42f,2.1
,APPROVED,pandas-dev__pandas-56841,https://github.com/pandas-dev/pandas/pull/56841,"import timeit
import statistics

import pandas as pd
import numpy as np

left1 = pd.Index(np.arange(100_000)).repeat(10)
right1 = pd.Index(np.arange(100_000))

data = [f""i_{i:06}"" for i in range(100_000)]
left2 = pd.Index(data, ""string[pyarrow_numpy]"")
right2 = pd.Index(data, ""string[pyarrow_numpy]"").repeat(10)

def workload():
    left1.join(right1, how=""right"")
    left2.join(right2, how=""right"")
    
runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.100637177915778
Before SD: 0.03381811863052626
After Mean: 0.3683194831176661
After SD: 0.02111229001993244
Improvement: -66.54%",,953,docker.io/sweperf/sweperf:pandas-dev__pandas-56841,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56841,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56841 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-01-12 1:43:09,5789f15402a97bbaf590c8de2696ef94c22a6bf9,2.1
,APPROVED,pandas-dev__pandas-56902,https://github.com/pandas-dev/pandas/pull/56902,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 1000000
df = pd.DataFrame(
    {""group"": [1] * N + [2] * N, ""value"": [np.nan, 1.0] * N}
).set_index(""group"")
df = df.sample(N)

def workload():
    df.groupby(""group"").ffill()
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.1955954582709819
Before SD: 0.001995603894065192
After Mean: 0.08514414408884477
After SD: 0.0009317212646428003
Improvement: -56.47%",,954,docker.io/sweperf/sweperf:pandas-dev__pandas-56902,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56902,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56902 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-01-16 1:18:45,4921e0b2290f881e17bd21685289e46ae4894155,2.1
,APPROVED,pandas-dev__pandas-56919,https://github.com/pandas-dev/pandas/pull/56919,"import timeit
import statistics

import pandas as pd

data = [f""i-{i}"" for i in range(200_000)]
idx1 = pd.Index(data, dtype=""string[pyarrow_numpy]"")
idx2 = pd.Index(data[1:], dtype=""string[pyarrow_numpy]"")

def workload():
    idx1.join(idx2, how=""left"", sort=True)

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.6326995500759222
Before SD: 0.018857662415055054
After Mean: 0.3557975569553673
After SD: 0.015772510548799027
Improvement: -43.77%",,953,docker.io/sweperf/sweperf:pandas-dev__pandas-56919,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56919,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56919 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-01-17 1:21:42,0e11d6dfde943dd3c355aba178eb732c6e6d6223,2.1
,APPROVED,pandas-dev__pandas-56990,https://github.com/pandas-dev/pandas/pull/56990,"import timeit
import statistics

import pandas as pd

mi = pd.MultiIndex.from_product(
    [
        pd.date_range(""2000-01-01"", periods=1000),
        pd.RangeIndex(1000),
    ]
)
mi_deepcopy = mi.copy(deep=True)
idx_non_object = pd.RangeIndex(1)

def workload():
    mi.equals(mi_deepcopy)

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.14781323522212916
Before SD: 0.0024956871912935803
After Mean: 0.006013484379509464
After SD: 0.0001647908237424783
Improvement: -95.93%",,162,docker.io/sweperf/sweperf:pandas-dev__pandas-56990,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56990,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56990 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-01-21 1:52:17,53525ea1c333579ee612244ddea4958d900844fc,2.2
,APPROVED,pandas-dev__pandas-56997,https://github.com/pandas-dev/pandas/pull/56997,"import timeit
import statistics

import pandas as pd

N = 100_000
dtype = ""string[pyarrow_numpy]""

strings = [f""i-{i}"" for i in range(N)]

idx1 = pd.Index(strings[10:], dtype=dtype)
idx2 = pd.Index(strings[:-10], dtype=dtype)

def workload():
    idx1.get_indexer_for(idx2)
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.10302680858119856
Before SD: 0.00990390419995362
After Mean: 0.05377462206757627
After SD: 0.0015401571290147922
Improvement: -47.81%",,954,docker.io/sweperf/sweperf:pandas-dev__pandas-56997,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56997,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-56997 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-01-21 20:55:41,72814750548b5ead5b08cd9b90d56a23c9a520ea,2.2
,APPROVED,pandas-dev__pandas-57034,https://github.com/pandas-dev/pandas/pull/57034,"import timeit
import statistics

import pandas as pd
import numpy as np

N = 1_000_000

s1 = pd.Series(np.random.randn(N))
s1 = s1[::2].sample(frac=1.0)
s2 = pd.Series(np.random.randn(N))

# same index
s3 = pd.Series(np.random.randn(N))
s3[::2] = np.nan
s4 = pd.Series(np.random.randn(N))

def workload():
    s1.combine_first(s2)
    s3.combine_first(s4)
    
runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.92316575816134
Before SD: 0.08430291563913812
After Mean: 0.41349546388024466
After SD: 0.007851134217690287
Improvement: -78.50%",,13,docker.io/sweperf/sweperf:pandas-dev__pandas-57034,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57034,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57034 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-01-23 11:30:18,736868671044605b0f2c2cc23ab5ea09fbc9a2ac,2.2
,APPROVED,pandas-dev__pandas-57252,https://github.com/pandas-dev/pandas/pull/57252,"import timeit
import statistics

import pandas as pd
import numpy as np

idx = pd.RangeIndex(1000)

def workload():
    idx.append([idx] * 100_000)
    
runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.8491199793154374
Before SD: 0.00836590918069417
After Mean: 0.8041439833934418
After SD: 0.006451546549588531
Improvement: -5.30%",,86,docker.io/sweperf/sweperf:pandas-dev__pandas-57252,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57252,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57252 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-02-04 21:02:50,6725e37684a24afeaea2757fb3512c58d37cef86,2.2
,APPROVED,pandas-dev__pandas-57459,https://github.com/pandas-dev/pandas/pull/57459,"import timeit
import statistics

import numpy as np
import pandas as pd

n_rows, n_cols = 1_000_000, 10

# construct dataframe with 2 blocks
arr1 = np.random.randn(n_rows, n_cols // 2).astype(""f8"")
arr2 = np.random.randn(n_rows, n_cols // 2).astype(""f4"")
df = pd.concat([pd.DataFrame(arr1), pd.DataFrame(arr2)], axis=1, ignore_index=True)
df._consolidate_inplace()

arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(""f8"")
arr2 = np.random.randn(n_rows, n_cols // 2).astype(""i8"")
arr3 = np.random.randn(n_rows, n_cols // 4).astype(""f8"")
df2 = pd.concat(
    [pd.DataFrame(arr1), pd.DataFrame(arr2), pd.DataFrame(arr3)],
    axis=1,
    ignore_index=True,
)
df2._consolidate_inplace()

def workload():
    df > df2
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.052484076839173215
Before SD: 0.0009293868890646844
After Mean: 0.02248641977319494
After SD: 0.0006675973530832532
Improvement: -57.16%",,360,docker.io/sweperf/sweperf:pandas-dev__pandas-57459,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57459,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57459 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-02-16 17:01:18,c8646541e9a2e27cc14e550c722364ded1dcba5f,2.2
,APPROVED,pandas-dev__pandas-57534,https://github.com/pandas-dev/pandas/pull/57534,"import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randn(1000000, 2), columns=list(""AB""))

def workload():
    df.sort_values(by=""A"", ascending=True)
    df.sort_values(by=""A"", ascending=False)
    
runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.34780601049249527
Before SD: 0.011125511390387094
After Mean: 0.13828412832634057
After SD: 0.001655102648503026
Improvement: -60.24%",,949,docker.io/sweperf/sweperf:pandas-dev__pandas-57534,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57534,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57534 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-02-20 18:00:38,1625d5a9112a0143c1dc59eadab825536e7e1240,2.2
,APPROVED,pandas-dev__pandas-57560,https://github.com/pandas-dev/pandas/pull/57560,"import timeit
import statistics

import pandas as pd
import numpy as np

np.random.seed(123)

size = 1_000_000
ngroups = 1000

data = pd.Series(np.random.randint(0, ngroups, size=size))

def workload():
    data.groupby(data).groups
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.19816602758073715
Before SD: 0.0051621076325072315
After Mean: 0.1865524509124225
After SD: 0.004247952776987868
Improvement: -5.86%",,949,docker.io/sweperf/sweperf:pandas-dev__pandas-57560,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57560,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57560 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-02-21 23:28:26,654f9325b24b5d271fa7debcd173db2b4d440b4a,2.2
,APPROVED,pandas-dev__pandas-57812,https://github.com/pandas-dev/pandas/pull/57812,"import timeit
import statistics

import pandas as pd
import numpy as np

np.random.seed(123)

size = 1_000_000
ngroups = 1000

data = pd.Series(np.random.randint(0, ngroups, size=size))

def workload():
    data.groupby(data).groups
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.19490064007695765
Before SD: 0.004940752259753689
After Mean: 0.1572201870084973
After SD: 0.0027957805664246427
Improvement: -19.33%",,279,docker.io/sweperf/sweperf:pandas-dev__pandas-57812,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57812,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57812 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-03-11 18:34:44,cfe191db8b5e556a5e5995e7aa1305534122f972,2.2
,APPROVED,pandas-dev__pandas-57855,https://github.com/pandas-dev/pandas/pull/57855,"import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame({""A"": np.arange(100_000)})
df_empty = pd.DataFrame(columns=[""B"", ""C""], dtype=""int64"")

def workload():
    df_empty.join(df, how=""inner"")
    
runtimes = timeit.repeat(workload, number=5, repeat=10**4)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.008809550737030804
Before SD: 0.0003748705976804329
After Mean: 0.0011571930245147088
After SD: 4.644049404916634e-05
Improvement: -86.86%",,8,docker.io/sweperf/sweperf:pandas-dev__pandas-57855,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57855,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-57855 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-03-15 17:46:12,60c4ce6a8cf8faa7e6c3693af84998a1f8236580,2.2
,APPROVED,pandas-dev__pandas-58027,https://github.com/pandas-dev/pandas/pull/58027,"import timeit
import statistics

import pandas as pd
import numpy as np

dfs = []

for dtype in [""datetime64[ns, US/Pacific]"", ""Period[s]""]:
    lev = pd.Index(list(""ABCDEFGHIJ""))
    ri = pd.Index(range(1000))
    mi = pd.MultiIndex.from_product([lev, ri], names=[""foo"", ""bar""])

    index = pd.date_range(""2016-01-01"", periods=10000, freq=""s"", tz=""US/Pacific"")
    if dtype == ""Period[s]"":
        index = index.tz_localize(None).to_period(""s"")

    ser = pd.Series(index, index=mi)
    df = ser.unstack(""bar"")
    dfs.append(df)

for dtype in [""Int64"", ""Float64""]:
    lev = pd.Index(list(""ABCDEFGHIJ""))
    ri = pd.Index(range(1000))
    mi = pd.MultiIndex.from_product([lev, ri], names=[""foo"", ""bar""])

    values = np.random.randn(10_000).astype(int)

    ser = pd.Series(values, dtype=dtype, index=mi)
    df = ser.unstack(""bar"")
    dfs.append(df)
    
def workload():
    for df in dfs:
        df.stack()

runtimes = timeit.repeat(workload, number=5, repeat=25)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 4.186381063517183
Before SD: 0.010137387372920439
After Mean: 0.5890858478355221
After SD: 0.002554914756392203
Improvement: -85.93%",,29,docker.io/sweperf/sweperf:pandas-dev__pandas-58027,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-58027,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-58027 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-03-27 3:43:05,b552dc95c9fa50e9ca2a0c9f9cdb8757f794fedb,2.2
,APPROVED,pandas-dev__pandas-58992,https://github.com/pandas-dev/pandas/pull/58992,"import timeit
import statistics

import pandas as pd
import matplotlib.pyplot as plt

ts_index = pd.date_range('2020-01-01 00:00', periods=500_000, freq='10min')

s_a = pd.Series(data=1, index=ts_index)
s_b = pd.Series(data=2, index=ts_index)

def setup():
    global ax
    plt.clf()
    fig, ax = plt.subplots()
    
def workload():
    global ax
    s_a.plot(ax=ax)
    
runtimes = timeit.repeat(workload, number=1, repeat=6, setup=setup)[-5:]

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 13.843341277202125
Before SD: 0.01912511770688179
After Mean: 1.0124845795915463
After SD: 0.006712374689262484
Improvement: -92.69%",,16,docker.io/sweperf/sweperf:pandas-dev__pandas-58992,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-58992,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-58992 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-06-12 22:48:43,de5d7323cf6fcdd6fcb1643a11c248440787d960,2.2
,APPROVED,pandas-dev__pandas-59608,https://github.com/pandas-dev/pandas/pull/59608,"import timeit
import statistics

import pandas as pd
import tempfile
import os

NUM_ROWS = 100_000
NUM_COLS = 20

temp_path = tempfile.NamedTemporaryFile(suffix="".csv"", delete=False).name

# Example Multi-Index DataFrame
df = pd.DataFrame(
    {
        f""col_{col_idx}"": range(col_idx * NUM_ROWS, (col_idx + 1) * NUM_ROWS)
        for col_idx in range(NUM_COLS)
    }
)
df = df.set_index([""col_0"", ""col_1""], drop=False)

# Timing Operation A
def workload():
    df.to_csv(temp_path, index=False)

runtimes = timeit.repeat(workload, number=1, repeat=3)

os.remove(temp_path)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.45679346336207044
Before SD: 0.04728388254794414
After Mean: 0.36553830701935414
After SD: 0.012588867228949715
Improvement: -19.98%",,29,docker.io/sweperf/sweperf:pandas-dev__pandas-59608,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-59608,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-59608 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-08-26 10:13:13,360597c349f4309364af0d5ac3bab158fd83d9fa,2.2
,APPROVED,pandas-dev__pandas-59647,https://github.com/pandas-dev/pandas/pull/59647,"import timeit
import statistics

import pandas as pd

cdtype = pd.CategoricalDtype(categories=list(range(100_000)), ordered=True)
base_dtype = pd.CategoricalDtype(ordered=False)

def workload():
    base_dtype.update_dtype(cdtype)
    
runtimes = timeit.repeat(workload, number=5, repeat=10**6)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.8098428451339713e-05
Before SD: 1.837965756459168e-06
After Mean: 5.808742120454554e-06
After SD: 1.4759004713220451e-06
Improvement: -67.90%",,951,docker.io/sweperf/sweperf:pandas-dev__pandas-59647,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-59647,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-59647 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-08-28 20:47:52,350904cc8fd36feaf3dee47ac5fcf8a76d60c87b,2.2
,APPROVED,pandas-dev__pandas-60121,https://github.com/pandas-dev/pandas/pull/60121,"import timeit
import statistics

import pandas as pd
import numpy as np

df = pd.DataFrame(np.zeros((5000, 5000)))

def workload():
    _ = df.astype(""Float64"")
    
runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.260171967110364
Before SD: 0.013075804905917827
After Mean: 0.254130292206537
After SD: 0.004340523275295535
Improvement: -88.76%",,951,docker.io/sweperf/sweperf:pandas-dev__pandas-60121,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-60121,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-60121 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2024-10-29 3:26:39,e3a3a4a5fbc6451006822e08d1d54d991f6d2c3f,2.2
,APPROVED,pandas-dev__pandas-61014,https://github.com/pandas-dev/pandas/pull/61014,"import timeit
import statistics

import numpy as np
import pandas as pd

df = pd.DataFrame(np.random.randn(1, 1_000_000))

mask = df > 0.5

def workload():
    _ = df.where(mask)
    
runtimes = timeit.repeat(workload, number=1, repeat=5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.5607716413913295
Before SD: 0.005242655822837408
After Mean: 0.004940824606455863
After SD: 0.0010314351595806166
Improvement: -99.12%",,953,docker.io/sweperf/sweperf:pandas-dev__pandas-61014,docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-61014,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-61014 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pandas-dev/pandas,2025-02-27 2:35:03,f13cd4cee8f756a5b6745fac42fbccd2bd7aa9c8,2.2
,APPROVED,pydata__xarray-4740,https://github.com/pydata/xarray/pull/4740,"import timeit as timeit
import statistics

import xarray as xr
import numpy as np
import dask.array as da

def setup():
    global ds0
    a = np.arange(0, 2000)
    b = np.core.defchararray.add(""long_variable_name"", a.astype(str))
    coords = dict(time=da.array([0, 1]))
    data_vars = dict()
    for v in b:
        data_vars[v] = xr.DataArray(
            name=v,
            data=da.array([3, 4]),
            dims=[""time""],
            coords=coords
        )
    ds0 = xr.Dataset(data_vars)

def workload():
    global ds0
    ds0.interp(
        time=da.array([0, 0.5, 1]),
        assume_sorted=True,
        kwargs=dict(fill_value=None),
    )
    
runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 2.8775395602337084
Before SD: 0.025426707784638482
After Mean: 0.7952919595991261
After SD: 0.008703074079617056
Improvement: -72.36%",,3,docker.io/sweperf/sweperf:pydata__xarray-4740,docker.io/sweperf/sweperf_annotate:pydata__xarray-4740,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-4740 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2020-12-29 19:03:59,1c198a191127c601d091213c4b3292a8bb3054e1,0.12
,APPROVED,pydata__xarray-5661,https://github.com/pydata/xarray/pull/5661,"import timeit
import statistics

import numpy as np
import xarray as xr
import sys
import os

# silence command-line output temporarily
sys.stdout, sys.stderr = os.devnull, os.devnull

def setup():
    global ds0
    
    a = np.arange(0, 2000)
    data_vars = dict()
    for i in a:
        data_vars[f""long_variable_name_{i}""] = xr.DataArray(
            name=f""long_variable_name_{i}"",
            data=np.arange(0, 20),
            dims=[f""long_coord_name_{i}_x""],
            coords={f""long_coord_name_{i}_x"": np.arange(0, 20) * 2},
        )
    ds0 = xr.Dataset(data_vars)
    ds0.attrs = {f""attr_{k}"": 2 for k in a}

def workload():
    global ds0
    print(ds0)
    
# unsilence command-line output
sys.stdout, sys.stderr = sys.__stdout__, sys.__stderr__

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
 ","Before Mean: 4.677181837201351
Before SD: 0.034818625325130935
After Mean: 0.04982840229058638
After SD: 0.0004992342610722498
Improvement: -98.93%",,6,docker.io/sweperf/sweperf:pydata__xarray-5661,docker.io/sweperf/sweperf_annotate:pydata__xarray-5661,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-5661 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2021-08-01 8:44:17,c44b816bf4a858af1bb621d96e1d3482db3976da,0.19
,APPROVED,pydata__xarray-7374,https://github.com/pydata/xarray/pull/7374,"
import timeit
import statistics

import xarray as xr
import numpy as np
from dataclasses import dataclass
import os

@dataclass
class PerformanceBackendArray(xr.backends.BackendArray):
    filename_or_obj: str | os.PathLike | None
    shape: tuple[int, ...]
    dtype: np.dtype
    lock: xr.backends.locks.SerializableLock

    def __getitem__(self, key: tuple):
        return xr.core.indexing.explicit_indexing_adapter(
            key,
            self.shape,
            xr.core.indexing.IndexingSupport.BASIC,
            self._raw_indexing_method,
        )

    def _raw_indexing_method(self, key: tuple):
        raise NotImplementedError

@dataclass
class PerformanceStore(xr.backends.common.AbstractWritableDataStore):
    manager: xr.backends.CachingFileManager
    mode: str | None = None
    lock: xr.backends.locks.SerializableLock | None = None
    autoclose: bool = False

    def __post_init__(self):
        self.filename = self.manager._args[0]

    @classmethod
    def open(
        cls,
        filename: str | os.PathLike | None,
        mode: str = ""r"",
        lock: xr.backends.locks.SerializableLock | None = None,
        autoclose: bool = False,
    ):
        if lock is None:
            if mode == ""r"":
                locker = xr.backends.locks.SerializableLock()
            else:
                locker = xr.backends.locks.SerializableLock()
        else:
            locker = lock

        manager = xr.backends.CachingFileManager(
            xr.backends.DummyFileManager,
            filename,
            mode=mode,
        )
        return cls(manager, mode=mode, lock=locker, autoclose=autoclose)

    def load(self) -> tuple:
        """"""
        Load a bunch of test data quickly.

        Normally this method would've opened a file and parsed it.
        """"""
        n_variables = 2000

        # Important to have a shape and dtype for lazy loading.
        shape = (1,)
        dtype = np.dtype(int)
        variables = {
            f""long_variable_name_{v}"": xr.Variable(
                data=PerformanceBackendArray(
                    self.filename, shape, dtype, self.lock
                ),
                dims=(""time"",),
                fastpath=True,
            )
            for v in range(0, n_variables)
        }
        attributes = {}

        return variables, attributes

class PerformanceBackend(xr.backends.BackendEntrypoint):
    def open_dataset(
        self,
        filename_or_obj: str | os.PathLike | None,
        drop_variables: tuple[str] = None,
        *,
        mask_and_scale=True,
        decode_times=True,
        concat_characters=True,
        decode_coords=True,
        use_cftime=None,
        decode_timedelta=None,
        lock=None,
        **kwargs,
    ) -> xr.Dataset:
        filename_or_obj = xr.backends.common._normalize_path(filename_or_obj)
        store = PerformanceStore.open(filename_or_obj, lock=lock)

        store_entrypoint = xr.backends.store.StoreBackendEntrypoint()

        ds = store_entrypoint.open_dataset(
            store,
            mask_and_scale=mask_and_scale,
            decode_times=decode_times,
            concat_characters=concat_characters,
            decode_coords=decode_coords,
            drop_variables=drop_variables,
            use_cftime=use_cftime,
            decode_timedelta=decode_timedelta,
        )
        return ds

engine = PerformanceBackend

def workload():
    global ds
    xr.open_dataset(None, engine=engine, chunks=None)
    
runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.1195119862013962
Before SD: 0.0007257318486401459
After Mean: 0.08353344883711543
After SD: 0.0005032881222342841
Improvement: -30.10%",,55,docker.io/sweperf/sweperf:pydata__xarray-7374,docker.io/sweperf/sweperf_annotate:pydata__xarray-7374,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-7374 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2022-12-11 16:01:05,17933e7654d5502c2a580b1433c585241f915c18,2022.09
,APPROVED,pydata__xarray-7382,https://github.com/pydata/xarray/pull/7382,"import timeit
import statistics

import numpy as np
import pandas as pd
import xarray as xr

m = 100_000
i1 = np.repeat([1, 2, 3, 4], m) 
i2 = np.tile(np.arange(m), 4)
d3 = np.random.randint(0, 2, 4 * m).astype(bool)

ds = xr.Dataset(
    data_vars=dict(
        d3=(""row"", d3)  
    ),
    coords=dict(
        i1=(""row"", i1), 
        i2=(""row"", i2)
    ),
)
ds = ds.set_index(row=[""i1"", ""i2""]).rename({""row"": ""index""})

def workload():
    ds.assign(foo=~ds[""d3""])

runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.6325477061563288
Before SD: 0.010473847587611279
After Mean: 0.0037559053600998596
After SD: 0.00010317088969610446
Improvement: -99.41%",,27,docker.io/sweperf/sweperf:pydata__xarray-7382,docker.io/sweperf/sweperf_annotate:pydata__xarray-7382,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-7382 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2022-12-15 12:54:56,b93dae4079daf0fc4c042fd0d699c16624430cdc,2022.09
,APPROVED,pydata__xarray-7472,https://github.com/pydata/xarray/pull/7472,"import timeit
import statistics

import xarray as xr
import dask.array as da
import numpy as np

random_kws = dict(chunks=5000)

dim1 = 10_000
dim2 = 10_000

def setup():
    global ds
    ds = xr.Dataset(
        {
            ""x"": xr.DataArray(
                data=da.random.random((dim1, dim2), **random_kws),
                dims=[""dim1"", ""dim2""],
                coords={""dim1"": np.arange(0, dim1), ""dim2"": np.arange(0, dim2)},
            )
        }
    )

def workload():
    global ds
    ds.to_dask_dataframe()
    
runtimes = timeit.repeat(workload, number=1, repeat=20, setup = setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.4544732673530234
Before SD: 0.015778495599279237
After Mean: 0.009711345698451623
After SD: 0.013851903508596993
Improvement: -97.86%",,1,docker.io/sweperf/sweperf:pydata__xarray-7472,docker.io/sweperf/sweperf_annotate:pydata__xarray-7472,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-7472 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2023-01-24 0:15:01,3ee7b5a63bb65ce62eff3dafe4a2e90bca7a9eeb,2022.09
,APPROVED,pydata__xarray-7735,https://github.com/pydata/xarray/pull/7735,"import timeit
import statistics

import numpy as np
import xarray as xr

def setup():
    global da
    arr = np.random.randn(10, 10, 365*30)
    time = xr.date_range(""2000"", periods=30*365, calendar=""noleap"")
    da = xr.DataArray(arr, dims=(""y"", ""x"", ""time""), coords={""time"": time})

    xr.set_options(use_flox=True)

def workload():
    global da
    da.groupby(""time.year"").max(""time"")
    da.groupby(""time.year"").mean(""time"")

runtimes = timeit.repeat(workload, number=5, repeat=100, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.28209997720085084
Before SD: 0.11082106816011401
After Mean: 0.08464182113937568
After SD: 0.11137466621341778
Improvement: -70.00%",,37,docker.io/sweperf/sweperf:pydata__xarray-7735,docker.io/sweperf/sweperf_annotate:pydata__xarray-7735,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-7735 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2023-04-07 2:45:55,8e899adcd72295a138228056643a78cac6e2de57,2023.03
,APPROVED,pydata__xarray-7736,https://github.com/pydata/xarray/pull/7736,"import timeit
import statistics

import numpy as np
import xarray as xr

def setup():
    global da
    arr = np.random.randn(10, 10, 365*30)
    time = xr.date_range(""2000"", periods=30*365, calendar=""noleap"")
    da = xr.DataArray(arr, dims=(""y"", ""x"", ""time""), coords={""time"": time})

    xr.set_options(use_flox=True)

def workload():
    global da
    da.groupby(""time.year"").max(""time"")
    da.groupby(""time.year"").mean(""time"")

runtimes = timeit.repeat(workload, number=5, repeat=100, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.2829785472585354
Before SD: 0.10915587990286758
After Mean: 0.2110019281395944
After SD: 0.11238106593344957
Improvement: -25.44%",,39,docker.io/sweperf/sweperf:pydata__xarray-7736,docker.io/sweperf/sweperf_annotate:pydata__xarray-7736,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-7736 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2023-04-07 2:46:08,8e899adcd72295a138228056643a78cac6e2de57,2023.03
,APPROVED,pydata__xarray-7796,https://github.com/pydata/xarray/pull/7796,"import timeit
import statistics

import numpy as np
import xarray as xr

NTIME = 365 * 30

def setup():
    global das
    das = []
    calendars = [""standard"", ""noleap""]
    for calendar in calendars:
        time = xr.date_range(""2000"", periods=NTIME, calendar=calendar)
        data = np.ones((NTIME,))
        da = xr.DataArray(data, dims=""time"", coords={""time"": time})
    
        das.append(da)


def workload():
    global das
    for da in das:
        da.time.dt.dayofyear
        da.time.dt.year


runtimes = timeit.repeat(workload, number=1, repeat=100, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.006055535627529025
Before SD: 0.0001547273236102017
After Mean: 0.004666390981292352
After SD: 0.00013432009646396033
Improvement: -22.94%",,55,docker.io/sweperf/sweperf:pydata__xarray-7796,docker.io/sweperf/sweperf_annotate:pydata__xarray-7796,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-7796 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2023-04-29 4:22:10,2873831e5048fc630b1eaa5b3316d2e876e1afc7,2023.04
,APPROVED,pydata__xarray-7824,https://github.com/pydata/xarray/pull/7824,"import timeit
import statistics

import numpy as np
import xarray as xr

def setup():
    global datasets
    t_size = 8000
    t = np.arange(t_size)
    data = np.random.randn(t_size)

    dsA0 = xr.Dataset({""A"": xr.DataArray(data, coords={""T"": t}, dims=(""T""))})
    dsA1 = xr.Dataset({""A"": xr.DataArray(data, coords={""T"": t + t_size}, dims=(""T""))})

    datasets = [dsA0, dsA1]

def workload():
    global datasets
    xr.combine_by_coords(datasets)

runtimes = timeit.repeat(workload, number=5, repeat=100, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.025894589932868257
Before SD: 0.0005968520736288892
After Mean: 0.005930528320604935
After SD: 9.894141183029198e-05
Improvement: -77.10%",,56,docker.io/sweperf/sweperf:pydata__xarray-7824,docker.io/sweperf/sweperf_annotate:pydata__xarray-7824,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-7824 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2023-05-07 14:54:06,9909f90b4781be89e3f3ff7c87893928b3e3be6e,2023.04
,APPROVED,pydata__xarray-9001,https://github.com/pydata/xarray/pull/9001,"

import timeit
import statistics

import xarray
import subprocess

import zipfile
import os
import glob

# Download the dataset from: 
dataset_url = ""https://github.com/pydata/xarray/files/15213429/software_timestamp.zip""

# Download to /tmp/software_timestamp.zip
subprocess.run(['wget', dataset_url, '-O', '/tmp/software_timestamp.zip'])

# Unzip the dataset
with zipfile.ZipFile('/tmp/software_timestamp.zip', 'r') as zip_ref:
    zip_ref.extractall('/tmp')

def setup():
    global software_timestamp, N_frames

    dataset = xarray.open_dataset('/tmp/software_timestamp.nc', engine='h5netcdf')
    software_timestamp = dataset['software_timestamp'].compute()
    N_frames = dataset.sizes['frame_number']
    dataset.close()

def workload():
    global software_timestamp, N_frames
    for i in range(1000):
        software_timestamp.isel(frame_number=i % N_frames)

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

for filepath in glob.glob('/tmp/software_timestamp*'):
    os.remove(filepath)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.12650922629982234
Before SD: 0.001195230668165238
After Mean: 0.04844941809424199
After SD: 0.0005896483023727825
Improvement: -61.70%",,49,docker.io/sweperf/sweperf:pydata__xarray-9001,docker.io/sweperf/sweperf_annotate:pydata__xarray-9001,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-9001 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2024-05-05 14:51:22,8d728bf253f63c557ab8993d47c1cd0c3113277d,2023.07
,APPROVED,pydata__xarray-9002,https://github.com/pydata/xarray/pull/9002,"import timeit
import statistics

import xarray as xr
import numpy as np
import pandas as pd

nx = 2000
ny = 1000
nt = 500

def randn(shape, frac_nan=None, chunks=None, seed=0):
    rng = np.random.default_rng(seed)
    if chunks is None:
        x = rng.standard_normal(shape)
    else:
        import dask.array as da

        rng = da.random.default_rng(seed)
        x = rng.standard_normal(shape, chunks=chunks)

    if frac_nan is not None:
        inds = rng.choice(range(x.size), int(x.size * frac_nan))
        x.flat[inds] = np.nan

    return x

def randint(low, high=None, size=None, frac_minus=None, seed=0):
    rng = np.random.RandomState(seed)
    x = rng.randint(low, high, size)
    if frac_minus is not None:
        inds = rng.choice(range(x.size), int(x.size * frac_minus))
        x.flat[inds] = -1

    return x

ds = xr.Dataset(
        {
            ""var1"": ((""x"", ""y""), randn((nx, ny), frac_nan=0.1)),
            ""var2"": ((""x"", ""t""), randn((nx, nt))),
            ""var3"": ((""t"",), randn(nt)),
        },
        coords={
            ""x"": np.arange(nx),
            ""y"": np.linspace(0, 1, ny),
            ""t"": pd.date_range(""1970-01-01"", periods=nt, freq=""D""),
            ""x_coords"": (""x"", np.linspace(1.1, 2.1, nx)),
        },
    )

basic_indexes = {
    ""1scalar"": {""x"": 0},
    ""1slice"": {""x"": slice(0, 3)},
    ""1slice-1scalar"": {""x"": 0, ""y"": slice(None, None, 3)},
    ""2slicess-1scalar"": {""x"": slice(3, -3, 3), ""y"": 1, ""t"": slice(None, -3, 3)},
}

outer_indexes = {
    ""1d"": {""x"": randint(0, nx, 400)},
    ""2d"": {""x"": randint(0, nx, 500), ""y"": randint(0, ny, 400)},
    ""2d-1scalar"": {""x"": randint(0, nx, 100), ""y"": 1, ""t"": randint(0, nt, 400)},
}

def workload():
    for key in basic_indexes:
        ds.isel(**basic_indexes[key]).load()
    
    for key in outer_indexes:
        ds.isel(**outer_indexes[key]).load()


runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.015181063458439894
Before SD: 0.006030520518816813
After Mean: 0.014177881982177495
After SD: 0.006016377281333171
Improvement: -6.61%",,66,docker.io/sweperf/sweperf:pydata__xarray-9002,docker.io/sweperf/sweperf_annotate:pydata__xarray-9002,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-9002 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2024-05-05 16:05:11,938c8b6aa95a32568063f5e7cf005f8b478c3f61,2023.07
,APPROVED,pydata__xarray-9429,https://github.com/pydata/xarray/pull/9429,"import timeit
import statistics

import cftime
import numpy as np
import xarray as xr

from datetime import datetime

def setup():
    global da

    arr = np.random.randn(10, 10, 365 * 30)
    time = xr.date_range(""2000"", periods=30 * 365, use_cftime=True)

    labeled_time = [datetime(int(t.year), int(t.month), 1) for t in time.values]
    
    asda = xr.DataArray(time)
    labeled_time = []
    for year, month in zip(asda.dt.year, asda.dt.month):
        labeled_time.append(cftime.datetime(year, month, 1))

    da = xr.DataArray(
        arr,
        dims=(""y"", ""x"", ""time""),
        coords={""time"": time, ""time2"": (""time"", labeled_time)},
    )

def workload():
    da.groupby(""time.month"")
    for use_flox in [True, False]:
        with xr.set_options(use_flox=use_flox):
            da.groupby(""time.year"").mean()

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.42156128679635
Before SD: 0.2631569773242383
After Mean: 0.1122585647914093
After SD: 0.27131329549390637
Improvement: -73.37%",,13,docker.io/sweperf/sweperf:pydata__xarray-9429,docker.io/sweperf/sweperf_annotate:pydata__xarray-9429,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-9429 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2024-09-04 0:05:07,a8c989673d0ea0cd099ede136efa117eaeb7ae1d,2024.05
,APPROVED,pydata__xarray-9808,https://github.com/pydata/xarray/pull/9808,"import statistics
import timeit

import xarray as xr

def workload():
    xr.open_zarr(""gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3"")

runtimes = timeit.repeat(workload, number=1, repeat=3)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 149.91336881668153
Before SD: 18.13039147421969
After Mean: 115.74431956033611
After SD: 14.867856215122492
Improvement: -22.79%",,67,docker.io/sweperf/sweperf:pydata__xarray-9808,docker.io/sweperf/sweperf_annotate:pydata__xarray-9808,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:pydata__xarray-9808 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",pydata/xarray,2024-11-21 18:33:28,ad5c7ed52310efb11a70f3e06f93dfc289e23b0e,2024.05
,APPROVED,scikit-learn__scikit-learn-10610,https://github.com/scikit-learn/scikit-learn/pull/10610,"import timeit
import statistics
import numpy as np

from sklearn.datasets import fetch_mldata
from sklearn.manifold import TSNE
from sklearn.utils import check_array
from sklearn.utils import shuffle as _shuffle
from sklearn.neighbors import NearestNeighbors

def load_mnist(dtype=np.float32, order='C', shuffle=True, seed=0):
    """"""Load the data, then cache and memmap the train/test split""""""
    data = fetch_mldata('MNIST original')

    X = check_array(data['data'], dtype=dtype, order=order)
    y = data[""target""]

    if shuffle:
        X, y = _shuffle(X, y, random_state=seed)

    # Normalize features
    X /= 255
    return X, y

def make_tsne_model():
    return TSNE(n_components=2, init=""pca"", perplexity=30, verbose=0, n_iter=1000, method='barnes_hut')

X, _ = load_mnist()
data = X[:10000]

def setup():
    global tsne_model
    tsne_model = make_tsne_model()
    
def workload():
    global tsne_model
    tsne_model.fit_transform(data)

runtimes = timeit.repeat(workload, number=1, repeat=3, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 191.83623662069053
Before SD: 0.24267485491800456
After Mean: 151.54500339067695
After SD: 7.468323132613518
Improvement: -21.00%",,1,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-10610,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-10610,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-10610 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2018-02-09 11:57:22,116c96c7cc3e340099a811ed0c985c8db61a3f6a,0.2
,APPROVED,scikit-learn__scikit-learn-13290,https://github.com/scikit-learn/scikit-learn/pull/13290,"import timeit
import statistics

from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import SGDClassifier

import numpy as np
from numpy.random import rand

def build_x_y(ntrain, nfeat):
    """"""Creates a random classification problem with ntrain
    rows and nfeat features.""""""
    X_train = np.empty((ntrain, nfeat))
    X_train[:, :] = rand(ntrain, nfeat)[:, :]
    X_trainsum = X_train.sum(axis=1)
    eps = rand(ntrain) - 0.5
    X_trainsum_ = X_trainsum + eps
    y_train = (X_trainsum_ >= X_trainsum).ravel().astype(int)
    return X_train, y_train



def setup():
    global model, Xs, ys
    model = make_pipeline(PolynomialFeatures(), SGDClassifier())
    X_init, y_init = build_x_y(1000, 50)
    model.fit(X_init, y_init)
    
    Xs = []
    ys = []
    for i in range(100):
        X_init, y_init = build_x_y(1000, 50)
        Xs.append(X_init)
        ys.append(y_init)


def workload():
    global model, Xs, ys
    for X, y in zip(Xs, ys):
        X2 = model.steps[0][1].transform(X)
        model.steps[1][1].partial_fit(X2, y)
    
runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
    ","Before Mean: 1.660355247205589
Before SD: 0.10933688085412219
After Mean: 0.6277309200027957
After SD: 0.02564751600137387
Improvement: -62.19%",,2,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-13290,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-13290,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-13290 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2019-02-26 17:10:47,3f25ea034cca6fa719dec024e0cbba608bce07e6,0.22
,APPROVED,scikit-learn__scikit-learn-13310,https://github.com/scikit-learn/scikit-learn/pull/13310,"import timeit
import statistics

import numpy as np

from sklearn.metrics import pairwise_distances

X = np.random.randn(10000, 100)
n_jobs = 2
metrics = ['euclidean', 'manhattan', 'cosine']

def workload():
    for metric in metrics:
        pairwise_distances(X, metric=metric, n_jobs=n_jobs)
        
runtimes = timeit.repeat(workload, number=1, repeat=5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
    ","Before Mean: 8.47296548220329
Before SD: 0.27932031585997447
After Mean: 4.021548388991505
After SD: 0.05665227756667394
Improvement: -52.54%",,5,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-13310,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-13310,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-13310 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2019-02-27 14:12:37,afc6cc58da7b8b45b845443ed54e75de5017087c,0.21
,APPROVED,scikit-learn__scikit-learn-13987,https://github.com/scikit-learn/scikit-learn/pull/13987,"import timeit
import statistics

import numpy as np

from sklearn.datasets import make_classification
from sklearn.preprocessing import StandardScaler

n_samples = 10000
n_features = 10000
n_classes = 10
dtype = np.float32

X, y = make_classification(
    n_samples=n_samples,
    n_features=n_features,
    n_classes=n_classes,
    random_state=0,
    n_informative=n_features,
    n_redundant=0,
)
X = X.astype(dtype, copy=False)
    
def workload():
    StandardScaler().fit_transform(X)

runtimes = timeit.repeat(workload, number=1, repeat=10)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
    ","Before Mean: 1.6323647787969093
Before SD: 0.014408780632642566
After Mean: 1.4919799095892814
After SD: 0.0018470552687454094
Improvement: -8.60%",,5,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-13987,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-13987,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-13987 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2019-05-30 8:56:24,3ed200292fe17ff78e388c307a721ed0e707ca76,0.22
,APPROVED,scikit-learn__scikit-learn-14075,https://github.com/scikit-learn/scikit-learn/pull/14075,"import timeit
import statistics
import numpy as np

from sklearn.datasets import fetch_openml
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import zero_one_loss
from sklearn.model_selection import train_test_split

# Setup: load and prepare MNIST data
print(""Loading and preparing dataset..."")
data = fetch_openml(""mnist_784"", version=1, as_frame=False)
X = data[""data""] / 255.0  # normalize to [0,1]
y = data[""target""]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=60000, test_size=10000, stratify=y, random_state=0)

def setup():
    global clf
    clf = MLPClassifier(
        hidden_layer_sizes=(100, 100),
        max_iter=50,
        alpha=1e-4,
        solver=""sgd"",
        learning_rate_init=0.2,
        momentum=0.9,
        verbose=1,
        tol=1e-4,
        random_state=1,
    )

def workload():
    clf.fit(X_train, y_train)

# Benchmark workload
runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 56.00598120099166
Before SD: 0.985512804424882
After Mean: 55.55707084080204
After SD: 5.6243893566112435
Improvement: -0.80%",,2,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-14075,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-14075,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-14075 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2019-06-12 15:01:29,19479d7af1711f1bb403eca1c02eebf212999091,0.23
,APPROVED,scikit-learn__scikit-learn-14479,https://github.com/scikit-learn/scikit-learn/pull/14479,"import timeit
import statistics

import numpy as np 
from sklearn.cluster.k_means_ import _k_init 

X = np.random.RandomState(0).random_sample((10000, 100)) 
xx = (X**2).sum(axis=1) 

def workload():
    _k_init(X, 100, xx, np.random.RandomState(0)) 
    
# Benchmark workload
runtimes = timeit.repeat(workload, number=1, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.11790300077700522
Before SD: 0.00108084321327771
After Mean: 0.11363131144258659
After SD: 0.0006603553449761211
Improvement: -3.62%",,5,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-14479,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-14479,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-14479 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2019-07-26 12:58:12,5b88807df9c06b49138bedf2dcb1ea614bef0888,0.22
,APPROVED,scikit-learn__scikit-learn-15049,https://github.com/scikit-learn/scikit-learn/pull/15049,"import timeit
import statistics

from scipy.sparse import random

from sklearn.metrics.pairwise import manhattan_distances

prova = random(2000, 1000, 0.001, ""csr"")

def workload():
    manhattan_distances(prova)
    
runtimes = timeit.repeat(workload, number=5, repeat=20)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.5889883248414844
Before SD: 0.001728902771685783
After Mean: 0.06257477978768293
After SD: 0.00029950764911886415
Improvement: -98.26%",,2,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-15049,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-15049,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-15049 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2019-09-21 16:14:56,3046990e76c7c90a1150c26770572c8d76ee00de,0.22
,APPROVED,scikit-learn__scikit-learn-15257,https://github.com/scikit-learn/scikit-learn/pull/15257,"import timeit
import statistics

import time

import numpy as np
import scipy.sparse as sp

from sklearn.decomposition.nmf import _special_sparse_dot

def generate_values():
    n_samples = 1000
    n_features = 50
    n_components = 30
    rng = np.random.mtrand.RandomState(42)
    X = rng.randn(n_samples, n_features)
    np.clip(X, 0, None, out=X)
    X_csr = sp.csr_matrix(X)

    W = np.abs(rng.randn(n_samples, n_components))
    H = np.abs(rng.randn(n_components, n_features))
    return W, H, X_csr

W, H, X_csr = generate_values()

def workload():
    _special_sparse_dot(W, H, X_csr)
    
runtimes = timeit.repeat(workload, number=5, repeat=100)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.028397090557264165
Before SD: 0.002481386705322766
After Mean: 0.011407640946563333
After SD: 7.5239131894213e-05
Improvement: -59.83%",,1,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-15257,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-15257,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-15257 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2019-10-15 9:12:17,d0d8f204675fd2718d373f8cde5ae12707521061,0.22
,APPROVED,scikit-learn__scikit-learn-15615,https://github.com/scikit-learn/scikit-learn/pull/15615,"import timeit
import statistics

import numpy as np
from sklearn.datasets import fetch_california_housing
from sklearn.metrics.pairwise import nan_euclidean_distances
import pandas as pd

calhousing = fetch_california_housing()

X = pd.DataFrame(calhousing.data, columns=calhousing.feature_names)
y = pd.Series(calhousing.target, name='house_value')

rng = np.random.RandomState(42)

density = 4  # one in 10 values will be NaN

mask = rng.randint(density, size=X.shape) == 0
X_na = X.copy()
X_na.values[mask] = np.nan

def workload():
    nan_euclidean_distances(X_na)
    
runtimes = timeit.repeat(workload, number=1, repeat=5)

# Print runtime mean and std deviation.
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 17.93120629497571
Before SD: 0.03133612272437449
After Mean: 15.607489893212914
After SD: 0.09166748938761221
Improvement: -12.96%",,2,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-15615,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-15615,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-15615 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2019-11-13 10:56:09,db6c12fc117500a751799a3082d1503b65183920,0.22
,APPROVED,scikit-learn__scikit-learn-15762,https://github.com/scikit-learn/scikit-learn/pull/15762,"import timeit
import statistics

from itertools import product

from sklearn.preprocessing import OneHotEncoder
import numpy as np

rng = np.random.RandomState(42)

n_features_list = [50, 100]
n_samples_list = [200_000, 500_000]

def setup():
    global work
    work = []

    for n_samples, n_features in product(n_samples_list, n_features_list):
        enc = OneHotEncoder(categories='auto')
        X = rng.randint(0, 75, size=(n_samples, n_features))
        
        work.append((enc, X))

def workload():
    global work
    
    for enc, X in work:
        enc.fit(X)

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 4.40868357050349
Before SD: 0.033392025275371315
After Mean: 4.343423677393003
After SD: 0.05747708866306178
Improvement: -1.48%",,3,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-15762,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-15762,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-15762 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2019-12-02 21:51:56,cc88ec97b49387c9653934188667b45fc2d27a7d,0.23
,APPROVED,scikit-learn__scikit-learn-15834,https://github.com/scikit-learn/scikit-learn/pull/15834,"import timeit
import statistics

from sklearn.datasets import fetch_20newsgroups

dataset = fetch_20newsgroups(subset=""all"")

from time import time
from sklearn.feature_extraction.text import CountVectorizer

n_doc = 2000

def setup():
    global cv
    cv = CountVectorizer(
        input=""content"",
        analyzer=""char"",
        lowercase=False,
        ngram_range=(1, 6),
        min_df=8,
    )
            
def workload():
    global cv
    cv.fit(dataset.data[:n_doc])

runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 15.38633046458708
Before SD: 0.15753989528248613
After Mean: 10.470053804805502
After SD: 0.10245377063242177
Improvement: -31.95%",,2,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-15834,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-15834,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-15834 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2019-12-08 16:06:39,54da2f00fcec7458974dfb3d48f8881c715850f8,0.23
,APPROVED,scikit-learn__scikit-learn-16499,https://github.com/scikit-learn/scikit-learn/pull/16499,"import timeit
import statistics
import numpy as np
from sklearn.cluster import KMeans

n_samples = 10_000
n_features = 500
n_clusters = 500

X = np.random.rand(n_samples, n_features).astype(np.float32)

def setup():
    global clf
    clf = KMeans(
        n_clusters=n_clusters,
        init='k-means++',
        n_init=1,
        max_iter=1,
        random_state=0
    )

def workload():
    global clf
    clf.fit(X)

runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 9.285565400600898
Before SD: 0.14962006215636423
After Mean: 6.943650184199214
After SD: 0.0907594163519935
Improvement: -25.22%",,5,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-16499,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-16499,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-16499 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2020-02-20 17:22:52,93776b9f529b7c26950e517deae4aa3ccdd9fe1a,0.23
,APPROVED,scikit-learn__scikit-learn-17235,https://github.com/scikit-learn/scikit-learn/pull/17235,"import timeit
import statistics

import sklearn.cluster
from sklearn import datasets

data = datasets.load_iris()['data']

def workload():
    sklearn.cluster.KMeans(n_clusters=2).fit(data)
    
# Run benchmark
runtimes = timeit.repeat(workload, number=10, repeat=100)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.3424081509781536
Before SD: 0.007812565586484976
After Mean: 0.08141581036848948
After SD: 0.0008252071274631522
Improvement: -76.22%",,5,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-17235,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17235,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17235 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2020-05-15 11:10:19,90d00daa76d1c6848a60554c7eba15f1e351ed46,0.24
,APPROVED,scikit-learn__scikit-learn-17606,https://github.com/scikit-learn/scikit-learn/pull/17606,"import timeit
import statistics

from sklearn.datasets import load_digits
from sklearn.neural_network import MLPClassifier


digits = load_digits(return_X_y=True)
X = digits[0][:,:10]
y = digits[0][:,11]

def setup():
    global clf
    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,
                        hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000)

def workload():
    global clf
    clf.fit(X, y)

# Run benchmark
runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.6389671390003059
Before SD: 0.0012918913039775082
After Mean: 0.635466310189804
After SD: 0.006698845996419871
Improvement: -0.55%",,1,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-17606,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17606,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17606 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2020-06-16 2:29:15,f38d381094e40c6ca809b0c50a9a4171cbb81fee,0.24
,APPROVED,scikit-learn__scikit-learn-17609,https://github.com/scikit-learn/scikit-learn/pull/17609,"import timeit
import statistics

from sklearn.datasets import load_digits
from sklearn.neural_network import MLPClassifier

digits = load_digits(return_X_y=True)
X = digits[0][:,:10]
y = digits[0][:,11]

def setup():
    global clf
    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,
                        hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000)

def workload():
    global clf, X, y
    clf.fit(X, y)

runtimes = timeit.repeat(workload, number=1, repeat=6, setup=setup)[-5:]

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.6455564183881506
Before SD: 0.00556912588040615
After Mean: 0.6106296611949802
After SD: 0.0029928479306040915
Improvement: -5.41%",,1,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-17609,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17609,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17609 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2020-06-16 6:10:45,211ab3e8a3be76fb0ad021752c1b0f6230da015c,0.24
,APPROVED,scikit-learn__scikit-learn-17633,https://github.com/scikit-learn/scikit-learn/pull/17633,"import timeit
import statistics

from sklearn.datasets import load_digits
from sklearn.neural_network import MLPClassifier

digits = load_digits(return_X_y=True)
X = digits[0][:,:10]
y = digits[0][:,11]

def setup():
    global clf
    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,
                        hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000)

def workload():
    global clf
    clf.fit(X, y)

# Run benchmark
runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.6173506392049604
Before SD: 0.010921413046663173
After Mean: 0.6168741895875428
After SD: 0.014194628063490429
Improvement: -0.08%",,6,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-17633,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17633,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17633 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2020-06-18 16:42:38,8ab0064579a20b175400b05a33ededaa4f57d062,0.24
,APPROVED,scikit-learn__scikit-learn-17661,https://github.com/scikit-learn/scikit-learn/pull/17661,"import timeit
import statistics

from sklearn.datasets import load_digits
from sklearn.neural_network import MLPClassifier


digits = load_digits(return_X_y=True)
X = digits[0][:,:50]
y = digits[0][:,51]

clf = MLPClassifier(solver='lbfgs', alpha=1e-5,
                    hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000)
clf.fit(X, y)

def workload():
    global clf
    clf.predict([[x for x in range(50)] for y in range(50)])

# Run benchmark
runtimes = timeit.repeat(workload, number=1, repeat=100)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0003007107600569725
Before SD: 2.7423168495259698e-05
After Mean: 0.00029180383600760254
After SD: 2.4021201295430234e-05
Improvement: -2.96%",,1,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-17661,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17661,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17661 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2020-06-22 23:08:20,430c2080e81dbf9aacc99dfd83d958030a7c4d07,0.24
,APPROVED,scikit-learn__scikit-learn-17737,https://github.com/scikit-learn/scikit-learn/pull/17737,"import timeit
import statistics

from sklearn import linear_model
from sklearn.datasets import load_digits
import numpy as np

X, y = load_digits(return_X_y=True)
X = np.tile(X, (8, 8))
y = np.tile(y, 8)

# np.random.seed(0)
# X = np.random.rand(20000, 30)
# y = np.random.rand(20000)

def setup():
    global clf
    clf = linear_model.BayesianRidge()

def workload():
    clf.fit(X, y)

# Run benchmark
runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.775971079878509
Before SD: 0.11024135469743747
After Mean: 0.6904314538370818
After SD: 0.013501609028492333
Improvement: -11.02%",,3,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-17737,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17737,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17737 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2020-06-26 5:37:18,1e08459c742537517bb8fc4c9d4621b9d6d227bf,0.24
,APPROVED,scikit-learn__scikit-learn-17878,https://github.com/scikit-learn/scikit-learn/pull/17878,"import timeit
import statistics

from sklearn.feature_selection._mutual_info import _compute_mi_cd
import numpy as np

x = np.random.random(size=1000000)
y = np.random.choice(['a', 'b'], size=1000000)

def workload():
    mi = _compute_mi_cd(x, y, 3)

runtimes = timeit.repeat(workload, number=1, repeat=25)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 12.106760331557599
Before SD: 0.2055017701727635
After Mean: 9.370293179035652
After SD: 0.05275690507227871
Improvement: -22.60%",,2,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-17878,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17878,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-17878 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2020-07-09 22:31:09,0cfe98b9f81463143675793e5b4b11268b2cf857,0.24
,APPROVED,scikit-learn__scikit-learn-19473,https://github.com/scikit-learn/scikit-learn/pull/19473,"import timeit
import statistics

from sklearn.neighbors import KDTree, BallTree
import numpy as np

test_cases = {
    ""random"": lambda n: np.random.rand(n),
    ""ordered"": lambda n: np.arange(n, dtype=float),
    ""reverse_ordered"": lambda n: np.arange(n, 0, -1, dtype=float),
    ""duplicated"": lambda n:  np.zeros([n], dtype=float)
}
n = 1000
leaf_size = 100

test_data = {
    matrix_type: np.expand_dims(test_cases[matrix_type](n), -1) for matrix_type in test_cases
}

def workload():
    for data in test_data.values():
        KDTree(data, leaf_size=leaf_size)
        
runtimes = timeit.repeat(workload, number=1, repeat=5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0031142155989073218
Before SD: 0.00014329579831420575
After Mean: 0.0004271768033504486
After SD: 0.00010793385128673078
Improvement: -86.28%",,1,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-19473,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-19473,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-19473 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2021-02-16 22:48:49,9cfacf1540a991461b91617c779c69753a1ee4c0,1
,APPROVED,scikit-learn__scikit-learn-19571,https://github.com/scikit-learn/scikit-learn/pull/19571,"import timeit
import statistics

from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification

n_samples = 100_000
n_features = 100
n_informative = 10
n_classes = 10

X, y = make_classification(
    n_samples=n_samples,
    n_features=n_features,
    n_informative=n_informative,
    n_classes=n_classes,
    random_state=0
)

def setup():
    global clf
    clf = LogisticRegression(
        solver='newton-cg',
        max_iter=20,
    )

def workload():
    global clf
    clf.fit(X, y)

# Run benchmark
runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 4.324709565890953
Before SD: 0.026496300815689103
After Mean: 5.192308922408847
After SD: 2.36627115275578
Improvement: 20.06%",,1,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-19571,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-19571,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-19571 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2021-02-26 14:59:58,94abe05b4b96de2ca30d998fb9adb2fbd3eb1bde,1
,APPROVED,scikit-learn__scikit-learn-19606,https://github.com/scikit-learn/scikit-learn/pull/19606,"import timeit
import statistics

from sklearn.linear_model import ElasticNet
from sklearn.datasets import make_regression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import numpy as np

def _synth_regression_dataset(n_samples=100000, n_features=100,
                              dtype=np.float32):
    X, y = make_regression(n_samples=n_samples, n_features=n_features,
                           n_informative=n_features // 10, noise=50,
                           random_state=0)
    X = X.astype(dtype, copy=False)
    X = StandardScaler().fit_transform(X)

    X, X_val, y, y_val = train_test_split(X, y, test_size=0.1, random_state=0)
    return X, X_val, y, y_val

X, _, y, _ = _synth_regression_dataset(n_samples=5000, n_features=10000) 

def setup():
    global estimator
    estimator = ElasticNet(precompute=False, alpha=100, random_state=0) 

def workload():
    estimator.fit(X, y)
        
runtimes = timeit.repeat(workload, number=1, repeat=20, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.8195643452025252
Before SD: 0.04875772925680725
After Mean: 0.3215922302508261
After SD: 0.02205097062897235
Improvement: -60.76%",,17,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-19606,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-19606,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-19606 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2021-03-03 12:52:04,28ee486b44f8e7e6440f3439e7315ba1e6d35e43,1
,APPROVED,scikit-learn__scikit-learn-19934,https://github.com/scikit-learn/scikit-learn/pull/19934,"import timeit
import statistics

import numpy as np
from sklearn.datasets import make_blobs
from sklearn.preprocessing import KBinsDiscretizer
from sklearn.cluster import KMeans


N = 50_000
n_features = 5
n_bins = 10
eps = 1e-3
random_state = 42

X, _ = make_blobs(n_samples=N, n_features=n_features, random_state=random_state)

def setup():
    global kbd
    kbd = KBinsDiscretizer(n_bins=n_bins, strategy='kmeans')

def workload():
    global kbd
    kbd.fit(X)

# Run benchmark
runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

    ","Before Mean: 0.23197872560122051
Before SD: 0.35261213313298045
After Mean: 0.23075405108975247
After SD: 0.5176133574098619
Improvement: -0.53%",,3,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-19934,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-19934,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-19934 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2021-04-20 16:52:20,ce217db386aaddfa5b5dde3fe47d42a1964120a0,1
,APPROVED,scikit-learn__scikit-learn-21837,https://github.com/scikit-learn/scikit-learn/pull/21837,"import timeit
import statistics

import numpy as np
from sklearn.feature_selection import chi2

X = np.random.rand(13000, 300)
Y1 = np.random.randint(0, high=4616, size=13000)
Y2 = np.random.randint(0, high=3, size=13000)

def workload():
    chi2(X, Y1)
    chi2(X, Y2)
    
# Run benchmark
runtimes = timeit.repeat(workload, number=1, repeat=100)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.5096628800965846
Before SD: 0.03550945859421393
After Mean: 0.0487310960405739
After SD: 0.004810723598465791
Improvement: -90.44%",,2,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-21837,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-21837,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-21837 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2021-11-30 16:10:30,49043fc769d0affc92e3641d2d5f8f8de2421611,1.1
,APPROVED,scikit-learn__scikit-learn-22106,https://github.com/scikit-learn/scikit-learn/pull/22106,"import timeit
import statistics

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.utils import parallel_backend

num_estimators = 100
x, y = make_classification(n_samples=50_000)

def setup():
    global rf
    rf = RandomForestClassifier(n_estimators=num_estimators, random_state=0, warm_start=True, n_jobs=-1)
    with parallel_backend('loky'):
        rf.fit(x, y)
    
    rf.n_estimators += num_estimators

def workload():
    global rf
    with parallel_backend('loky'):
        rf.fit(x, y)

# Run benchmark
runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 9.599628746263333
Before SD: 0.10080986915861301
After Mean: 6.775445157102077
After SD: 0.013736280133279632
Improvement: -29.42%",,8,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-22106,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-22106,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-22106 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2021-12-31 11:41:08,c010d9a5a7e1f1b6dc77609eae09f28585e0ec5f,1.1
,APPROVED,scikit-learn__scikit-learn-22206,https://github.com/scikit-learn/scikit-learn/pull/22206,"import timeit
import statistics

from sklearn.datasets import make_regression
from sklearn.linear_model import QuantileRegressor

X, y = make_regression(n_samples=10_000, n_features=50, random_state=0, noise=1.0)

def workload():
    QuantileRegressor(solver=""highs"").fit(X, y)
    
# Run benchmark
runtimes = timeit.repeat(workload, number=1, repeat=10)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 5.057025083492045
Before SD: 0.01887978722295244
After Mean: 2.445835139893461
After SD: 0.017414498836669113
Improvement: -51.63%",,28,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-22206,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-22206,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-22206 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2022-01-13 22:34:42,8d6217107f02d6f52d2f8c8908958fe82778c7cc,1.1
,APPROVED,scikit-learn__scikit-learn-22235,https://github.com/scikit-learn/scikit-learn/pull/22235,"import timeit
import statistics

import pandas as pd
import numpy as np
import sklearn
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

n = 100_000
features = 100
num_classes = 100

X_array = np.random.randint(0, 2, size=(n, features), dtype=bool)
y = np.random.randint(0, num_classes, size=(n,), dtype=int)

def workload():
    chi2(X_array, y)
    
# Run benchmark
runtimes = timeit.repeat(workload, number=1, repeat=25)

# Output results
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 6.893791971518658
Before SD: 0.03736675243867229
After Mean: 0.17217932476196438
After SD: 0.01134497193027927
Improvement: -97.50%",,2,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-22235,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-22235,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-22235 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2022-01-17 18:03:28,0c65bbfe8ce816a181780d2a249c94dd653e115a,1.1
,APPROVED,scikit-learn__scikit-learn-23149,https://github.com/scikit-learn/scikit-learn/pull/23149,"import timeit
import statistics

from sklearn.datasets import make_classification
from scipy.sparse import csc_matrix
from sklearn.ensemble import IsolationForest

X, y = make_classification(n_samples=50000, n_features=1000)
X = csc_matrix(X)
X.sort_indices()

def workload():
    IsolationForest(n_estimators=10, max_samples=256, n_jobs=1).fit(X)

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 3.4602039300021716
Before SD: 0.020322918142918686
After Mean: 2.356701209512539
After SD: 0.022003666467164493
Improvement: -31.89%",,5,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-23149,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-23149,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-23149 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2022-04-17 14:26:27,65ae1a8586fc366c78ec053b275588183b6791da,1.1
,APPROVED,scikit-learn__scikit-learn-24856,https://github.com/scikit-learn/scikit-learn/pull/24856,"import os
from urllib.request import urlretrieve
from gzip import GzipFile
import numpy as np
import pandas as pd
from time import time
from joblib import Memory
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.ensemble._hist_gradient_boosting.utils import get_equivalent_estimator
import timeit
import statistics

# === Fixed configuration (replacing argparse) ===
n_leaf_nodes = 31
n_trees = 100
learning_rate = 1.0
max_bins = 255
cache_loc = ""/tmp""

HERE = os.path.dirname(__file__)
URL = ""https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz""
m = Memory(location=cache_loc, mmap_mode=""r"")

@m.cache
def load_data():
    filename = os.path.join(HERE, URL.rsplit(""/"", 1)[-1])
    if not os.path.exists(filename):
        print(f""Downloading {URL} to {filename} (2.6 GB)..."")
        urlretrieve(URL, filename)
        print(""done."")

    print(f""Parsing {filename}..."")
    tic = time()
    with GzipFile(filename) as f:
        df = pd.read_csv(f, header=None, dtype=np.float32)
    toc = time()
    print(f""Loaded {df.values.nbytes / 1e9:0.3f} GB in {toc - tic:0.3f}s"")
    return df


def fit(est, data_train, target_train, libname):
    print(f""Fitting a {libname} model..."")
    tic = time()
    est.fit(data_train, target_train)
    toc = time()
    print(f""fitted in {toc - tic:.3f}s"")

df = load_data()
target = df.values[:, 0]
data = np.ascontiguousarray(df.values[:, 1:])
data_train, data_test, target_train, target_test = train_test_split(
    data, target, test_size=0.2, random_state=0
)

n_samples, n_features = data_train.shape

def workload():
    interaction_cst = [[i] for i in range(n_features)]
    base_est = HistGradientBoostingClassifier(
        loss=""log_loss"",
        learning_rate=learning_rate,
        max_iter=n_trees,
        max_bins=max_bins,
        max_leaf_nodes=n_leaf_nodes,
        early_stopping=False,
        random_state=0,
        verbose=0,
        interaction_cst=interaction_cst,
    )
    fit(base_est, data_train, target_train, ""sklearn"")

runtimes = timeit.repeat(workload, number=1, repeat=3)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 27.662535973339498
Before SD: 0.08357566468774068
After Mean: 18.680509316017076
After SD: 0.06609260827051137
Improvement: -32.47%",,7,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-24856,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-24856,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-24856 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2022-11-07 20:11:30,f702e97907b69ebf47dc26398737fca7dd57faa2,1.2
,APPROVED,scikit-learn__scikit-learn-25186,https://github.com/scikit-learn/scikit-learn/pull/25186,"import timeit
import statistics

from sklearn.datasets import make_classification
from sklearn.ensemble import IsolationForest

from scipy.sparse import csc_matrix
import numpy as np

X, y = make_classification(n_samples=50000, n_features=100, random_state=0)
X = X.astype(np.float32)
X_sparse = csc_matrix(X)

def setup():
    global iso_forest, iso_forest_sparse
    iso_forest = IsolationForest(n_estimators=100, max_samples=256, n_jobs=1, random_state=0).fit(X)
    iso_forest_sparse = IsolationForest(n_estimators=100, max_samples=256, n_jobs=1, random_state=0).fit(X_sparse)

def workload():
    global iso_forest, iso_forest_sparse
    iso_forest.predict(X)
    iso_forest_sparse.predict(X_sparse)

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.257452732598176
Before SD: 0.03872206786221673
After Mean: 0.9360557617910672
After SD: 0.006626152133672018
Improvement: -71.26%",,2,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-25186,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-25186,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-25186 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2022-12-13 12:59:54,b2fe9746a862272a60ffc7d2c6563d28dd13a6c6,1.3
,APPROVED,scikit-learn__scikit-learn-25490,https://github.com/scikit-learn/scikit-learn/pull/25490,"import timeit
import statistics
from sklearn.decomposition import MiniBatchDictionaryLearning
from sklearn.datasets import make_sparse_coded_signal

n_samples, n_features, n_components = 1000, 100, 50
data, _, _ = make_sparse_coded_signal(
    n_samples=n_samples,
    n_components=n_components,
    n_features=n_features,
    n_nonzero_coefs=5,
    random_state=42
)
data = data.T  # shape: (n_samples, n_features)

def workload():
    model = MiniBatchDictionaryLearning(
        n_components=n_components,
        batch_size=1,    
        n_iter=30,       
        random_state=42
    )
    model.fit(data)

runtimes = timeit.repeat(workload, number=10, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.643945990378852
Before SD: 0.006789460429220628
After Mean: 0.6004590779403225
After SD: 0.0042391589318381785
Improvement: -6.75%",,3,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-25490,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-25490,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-25490 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2023-01-26 15:47:10,d92fba7b65b9fab22fb54b577edb26d98de0868c,1.3
,APPROVED,scikit-learn__scikit-learn-25713,https://github.com/scikit-learn/scikit-learn/pull/25713,"import timeit
import statistics

import numpy as np
from sklearn.metrics.cluster._expected_mutual_info_fast import expected_mutual_information
from sklearn.metrics.cluster import contingency_matrix

rng = np.random.default_rng(0)
n_samples = 100_000
x = np.array([x % 8000 for x in range(10_000)]) 
y = np.array([x % 7000 for x in range(10_000)])

contingency = contingency_matrix(x, y, sparse=True)
contingency = contingency.astype(np.float64, copy=False)

def workload():
    expected_mutual_information(contingency, n_samples)

runtimes = timeit.repeat(workload, number=1, repeat=3)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 104.65133754258859
Before SD: 0.5539418349162986
After Mean: 1.7512387480062899
After SD: 0.000460089867460505
Improvement: -98.33%",,3,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-25713,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-25713,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-25713 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2023-02-27 10:04:08,fabe1606daa8cc275222935769d855050cb8061d,1.3
,APPROVED,scikit-learn__scikit-learn-27344,https://github.com/scikit-learn/scikit-learn/pull/27344,"import timeit
import statistics

import numpy as np
from sklearn.preprocessing import QuantileTransformer
X = np.random.rand(10**5, 100)

def workload():
    QuantileTransformer().fit(X)

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.30526675999863073
Before SD: 0.002583894084666341
After Mean: 0.11780049103777855
After SD: 0.000899196182179245
Improvement: -61.41%",,32,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-27344,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-27344,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-27344 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2023-09-12 4:30:14,9b7d176b5a85d7dd681ffa69e55a82a3338096c5,1.5
,APPROVED,scikit-learn__scikit-learn-28064,https://github.com/scikit-learn/scikit-learn/pull/28064,"import timeit
import statistics

import numpy as np

from sklearn.datasets import make_classification
from sklearn.ensemble._hist_gradient_boosting.binning import _BinMapper

n_samples, n_features = 200_000, 20
n_bins = 256

X, y = make_classification(n_samples=n_samples, n_features=n_features)
categorical_remapped = np.zeros(n_features, dtype=bool)

def setup():
    global bin_mapper, bin_mapper_multithread
    bin_mapper = _BinMapper(
        n_bins=n_bins,
        is_categorical=categorical_remapped,
        known_categories=None,
        random_state=1,
        n_threads=1,
    )
    bin_mapper_multithread = _BinMapper(
        n_bins=n_bins,
        is_categorical=categorical_remapped,
        known_categories=None,
        random_state=1,
        n_threads=4,
    )

def workload():
    bin_mapper.fit(X) 
    bin_mapper.fit_transform(X)  
    bin_mapper_multithread.fit(X)  
    bin_mapper_multithread.fit_transform(X)
    
runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.2634158101922366
Before SD: 0.18599544721779207
After Mean: 1.6149811484967358
After SD: 0.20400766332517428
Improvement: -28.65%",,8,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-28064,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-28064,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-28064 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2024-01-04 19:58:37,619a1c1028335e9fa7abd4d7fb6477200a4bce67,1.6
,APPROVED,scikit-learn__scikit-learn-29060,https://github.com/scikit-learn/scikit-learn/pull/29060,"import timeit
import statistics

import numpy as np
from sklearn.datasets import fetch_california_housing
from sklearn.impute import KNNImputer
import pandas as pd

calhousing = fetch_california_housing()

X = pd.DataFrame(calhousing.data, columns=calhousing.feature_names)
y = pd.Series(calhousing.target, name='house_value')

rng = np.random.RandomState(42)
density = 10
mask = rng.randint(density, size=X.shape) == 0

X_na = X.copy()
X_na.values[mask] = np.nan
X_na.values[:, 0] = np.nan

def workload():
    KNNImputer().fit_transform(X_na)
    
runtimes = timeit.repeat(workload, number=1, repeat=5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
 ","Before Mean: 15.842732028814499
Before SD: 0.12909835606064698
After Mean: 11.240834431000986
After SD: 0.12063748305189903
Improvement: -29.05%",,4,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-29060,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-29060,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-29060 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2024-05-21 6:21:15,3b0c70b9c03a74835fe260b6b46b3f1ef6af8ba5,1.6
,APPROVED,scikit-learn__scikit-learn-29330,https://github.com/scikit-learn/scikit-learn/pull/29330,"import timeit
import statistics

import joblib

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import FunctionTransformer, Pipeline

import pandas as pd
import random

n_col = 40

def list_sum(df_col):
    series = df_col.squeeze(axis=1)
    return series.apply(sum).to_numpy().reshape(-1, 1)

df = pd.DataFrame({
    f""{i}"": [[random.random() for _ in range(random.randint(1, 5))]
             for _ in range(100_000)]
    for i in range(n_col)
})

def setup():
    global pipeline
    pipeline = Pipeline([
        (""transformer"",
         ColumnTransformer(
             [(f""{i}"",
               FunctionTransformer(list_sum, validate=False),
               [f""{i}""])
              for i in range(n_col)],
             n_jobs=2))
    ])
    
def workload():
    global pipeline
    with joblib.parallel_backend(backend=""loky"", mmap_mode=""r+""):
        pipeline.fit_transform(df)

runtimes = timeit.repeat(workload, number=1, repeat=4, setup=setup)[-3:]

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 85.64932707162806
Before SD: 1.239777115289879
After Mean: 2.0111690898076633
After SD: 0.1492270640164523
Improvement: -97.65%",,8,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-29330,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-29330,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-29330 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2024-06-21 10:28:32,a490ab19667988de62024eb98acd61117f8c292a,1.6
,APPROVED,scikit-learn__scikit-learn-29835,https://github.com/scikit-learn/scikit-learn/pull/29835,"import timeit
import statistics

import sklearn.covariance
import numpy as np
np.random.seed(1)

t = np.concatenate([np.random.randn(1000, 2), [2, 4] * np.random.randn(100, 2)])

def workload():
    sklearn.covariance.MinCovDet().fit(t).covariance_

runtimes = timeit.repeat(workload, number=1, repeat=25)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.3110930606839247
Before SD: 0.010282437278453281
After Mean: 0.27389741599326956
After SD: 0.007447711776727998
Improvement: -11.96%",,3,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-29835,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-29835,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-29835 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2024-09-11 23:15:03,bb6e76e679b54b8ba3452d823ae96faa49ad10d0,1.6
,APPROVED,scikit-learn__scikit-learn-9843,https://github.com/scikit-learn/scikit-learn/pull/9843,"import timeit
import statistics

import sklearn
import sklearn.metrics
import numpy as np

import itertools

dtype = ""int64""
n_inputs = [1000, 10000, 200000]
n_classes = [10, 100, 1000]

def make_inputs(n_input, n_classes, dtype=dtype, rng=np.random):
    y_true = (rng.rand(n_input) * n_classes).astype(dtype)
    y_pred = (rng.rand(n_input) * n_classes).astype(dtype)

    return y_true, y_pred

work = []
for n_input, n_class in itertools.product(n_inputs, n_classes):
    work.append(make_inputs(n_input, n_class))

def workload():
    for e in work:
        sklearn.metrics.confusion_matrix(*e)
        
runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.38644492521183565
Before SD: 0.0015289871073475947
After Mean: 0.1623365801811451
After SD: 0.0010351436931052916
Improvement: -57.99%",,21,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-9843,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-9843,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-9843 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2017-09-27 17:41:44,4beb0c27fc0439c12dad244fe4063e96f8983a52,1
,APPROVED,scikit-learn__scikit-learn-9858,https://github.com/scikit-learn/scikit-learn/pull/9858,"import timeit
import statistics

from sklearn.covariance import graph_lasso
import numpy as np

rng = np.random.RandomState(0)
X = rng.randn(2_000, 1_000)        # (n_samples, n_features)
emp_cov = np.dot(X.T, X) / X.shape[0]

def workload():
    """"""
    One full graphical-lasso solve.  Coordinate-descent (mode='cd') is the
    path that PR #9858 sped up.
    """"""
    # use a fairly loose alpha so the solver has to iterate a while
    graph_lasso(emp_cov, alpha=0.01, max_iter=100, mode=""cd"", tol=1e-4, verbose=False)


runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 15.2567854134948
Before SD: 0.20871026089858147
After Mean: 7.2707088610040955
After SD: 0.06796051143667903
Improvement: -52.34%",,1,docker.io/sweperf/sweperf:scikit-learn__scikit-learn-9858,docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-9858,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scikit-learn__scikit-learn-9858 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scikit-learn/scikit-learn,2017-09-30 22:19:14,4e6b403796238a1263b871a67d72d39ab61f2075,0.2
,APPROVED,scipy__scipy-10064,https://github.com/scipy/scipy/pull/10064,"import timeit
import statistics

import scipy.stats as stats
import numpy as np

np.random.seed(12345678)
dim = 200

def workload():
    stats.ortho_group.rvs(dim)
    stats.special_ortho_group.rvs(dim)


runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.1741504829001788
Before SD: 0.07859376295053777
After Mean: 0.33118705082527594
After SD: 0.019774950315335337
Improvement: -71.79%",,1,docker.io/sweperf/sweperf:scipy__scipy-10064,docker.io/sweperf/sweperf_annotate:scipy__scipy-10064,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-10064 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2019-04-14 17:27:06,bffff6e3447b459a99926561de267aac3d628271,1.2
,APPROVED,scipy__scipy-10393,https://github.com/scipy/scipy/pull/10393,"import timeit
import statistics
from numpy.random import rand
from numpy import arange, asarray, zeros, dot, exp, pi, double, cdouble
import numpy as np
import scipy.fft as scipy_fft

np.random.seed(0)

def random(size):
    return rand(*size)

def setup():
    global func, x
    x = random([313]).astype(cdouble)+random([313]).astype(cdouble)*1j
    module = scipy_fft
    func = getattr(module, 'fft')
    
def workload():
    global func, x
    func(x)

runtimes = timeit.repeat(workload, number=1, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 2.2419825388351454e-05
Before SD: 7.295625981436815e-07
After Mean: 1.278420247253962e-05
After SD: 6.486802035581048e-07
Improvement: -42.98%",,3,docker.io/sweperf/sweperf:scipy__scipy-10393,docker.io/sweperf/sweperf_annotate:scipy__scipy-10393,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-10393 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2019-07-04 12:07:39,1238d2d52eaf988cdd43b2173dd527c433d1818c,1.3
,APPROVED,scipy__scipy-10467,https://github.com/scipy/scipy/pull/10467,"import timeit
import statistics
import numpy as np
from scipy.spatial import SphericalVoronoi

def setup():
    global points
    np.random.seed(0)
    num_points = 10000
    phi = np.random.uniform(0, 2 * np.pi, num_points)
    cos_theta = np.random.uniform(-1, 1, num_points)
    theta = np.arccos(cos_theta)
    x = np.sin(theta) * np.cos(phi)
    y = np.sin(theta) * np.sin(phi)
    z = np.cos(theta)
    points = np.column_stack((x, y, z))
    

def workload():
    global points
    sv = SphericalVoronoi(points)

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.31272347076126605
Before SD: 0.002559021438871953
After Mean: 0.11504873721016338
After SD: 0.0007297008197024148
Improvement: -63.21%",,1,docker.io/sweperf/sweperf:scipy__scipy-10467,docker.io/sweperf/sweperf_annotate:scipy__scipy-10467,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-10467 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2019-07-15 18:41:27,c7038c0c85b41686a2c91007729ffd4ca94d57b5,1.3
,APPROVED,scipy__scipy-10477,https://github.com/scipy/scipy/pull/10477,"import timeit
import statistics
import numpy as np
from scipy.spatial import SphericalVoronoi

def setup():
    global points
    np.random.seed(0)
    num_points = 10000
    phi = np.random.uniform(0, 2 * np.pi, num_points)
    cos_theta = np.random.uniform(-1, 1, num_points)
    theta = np.arccos(cos_theta)
    x = np.sin(theta) * np.cos(phi)
    y = np.sin(theta) * np.sin(phi)
    z = np.cos(theta)
    points = np.column_stack((x, y, z))
    

def workload():
    global points
    sv = SphericalVoronoi(points)

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.11779062613029964
Before SD: 0.0009317990872830689
After Mean: 0.09303910901915514
After SD: 0.0006807842113073172
Improvement: -21.01%",,1,docker.io/sweperf/sweperf:scipy__scipy-10477,docker.io/sweperf/sweperf_annotate:scipy__scipy-10477,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-10477 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2019-07-17 14:28:24,35f86bc33016dc88fc4340e4dc3f23bf86e4f311,1.3
,APPROVED,scipy__scipy-10564,https://github.com/scipy/scipy/pull/10564,"import timeit
import statistics
import numpy as np
import scipy.linalg as sl

def setup():
    global x
    x = np.eye(1)
    
def workload():
    global x
    sl.blas.get_blas_funcs('gemm', dtype=float)
    sl.blas.get_blas_funcs(('gemm', 'axpy'), (x,x))
    sl.cholesky(x)

runtimes = timeit.repeat(workload, number=10, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 0.00014242155001746142
Before SD: 2.561229992398209e-06
After Mean: 6.528849580691895e-05
After SD: 1.5768414588447103e-06
Improvement: -54.16%",,19,docker.io/sweperf/sweperf:scipy__scipy-10564,docker.io/sweperf/sweperf_annotate:scipy__scipy-10564,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-10564 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2019-07-31 17:51:01,89bd367d79f02766be709a5c5c9b643628684d58,1.3
,APPROVED,scipy__scipy-10574,https://github.com/scipy/scipy/pull/10574,"import timeit
import statistics
import numpy as np
from scipy.linalg import hessenberg

def workload():
    hessenberg(np.eye(3))

runtimes = timeit.repeat(workload, number=1, repeat=20000)
print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 2.639245657774154e-05
Before SD: 1.2542443783299702e-06
After Mean: 1.724972540687304e-05
After SD: 9.934454192441932e-07
Improvement: -34.64%",,19,docker.io/sweperf/sweperf:scipy__scipy-10574,docker.io/sweperf/sweperf_annotate:scipy__scipy-10574,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-10574 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2019-08-01 18:34:52,dc072e7fbaf9967e789ae1198b0726376bbdef2b,1.3
,APPROVED,scipy__scipy-10921,https://github.com/scipy/scipy/pull/10921,"import timeit
import statistics

import scipy.sparse

A = scipy.sparse.random(10**4, 10**4, density=0.5, format='lil')

def workload():
    A.tocsr()

runtimes = timeit.repeat(workload, number=1, repeat=5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 6.509075605403632
Before SD: 0.11964195461706163
After Mean: 4.988600977411261
After SD: 0.11590698781325073
Improvement: -23.36%",,1,docker.io/sweperf/sweperf:scipy__scipy-10921,docker.io/sweperf/sweperf_annotate:scipy__scipy-10921,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-10921 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2019-10-12 12:15:45,f3d61214ca3af4f8999bff9b61c2a1a282213a6e,1.3
,APPROVED,scipy__scipy-10939,https://github.com/scipy/scipy/pull/10939,"import timeit
import statistics

import scipy
from numpy import ones, array, asarray, empty, random
from scipy.sparse import dia_matrix

def poisson2d(N, dtype='d', format=None):
    if N == 1:
        diags = asarray([[4]], dtype=dtype)
        return dia_matrix((diags, [0]), shape=(1, 1)).asformat(format)

    offsets = array([0, -N, N, -1, 1])

    diags = empty((5, N**2), dtype=dtype)

    diags[0] = 4  
    diags[1:] = -1  

    diags[3, N-1::N] = 0  
    diags[4, N::N] = 0  

    return dia_matrix((diags, offsets), shape=(N**2, N**2)).asformat(format)

base_format = ""lil""
base = poisson2d(100, format=base_format)
to_formats = [""dok"", ""dia"", ""csr"", ""bsr"", ""coo""]
conversion_lambdas = [
    getattr(base, 'to' + to_format) for to_format in to_formats
]

def workload():
    for convert in conversion_lambdas:
        _ = convert()

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.10567825335811358
Before SD: 0.0005741140138510774
After Mean: 0.047167232048872396
After SD: 0.0006125318438943478
Improvement: -55.37%",,1,docker.io/sweperf/sweperf:scipy__scipy-10939,docker.io/sweperf/sweperf_annotate:scipy__scipy-10939,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-10939 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2019-10-17 19:37:29,5f7733316df2c4a0cad5b735f4773d4bb8d900f7,1.3
,APPROVED,scipy__scipy-11358,https://github.com/scipy/scipy/pull/11358,"import timeit
import statistics

from scipy.optimize._linprog_util import _presolve, _clean_inputs, _LPProblem
from scipy.sparse import csr_matrix
import numpy as np
import os

meth = ""sparse""
prob = ""80BAU3B""

dir_path = os.path.dirname(""benchmarks/benchmarks/"")
datafile = os.path.join(dir_path, ""linprog_benchmark_files"",
                        prob + "".npz"")
data = np.load(datafile, allow_pickle=True)

c, A_eq, A_ub, b_ub, b_eq = (data[""c""], data[""A_eq""], data[""A_ub""],
                                data[""b_ub""], data[""b_eq""])
bounds = np.squeeze(data[""bounds""])
x0 = np.zeros(c.shape)

A_eq = csr_matrix(A_eq)
A_ub = csr_matrix(A_ub)

def setup():
    global lp_cleaned
    lp = _LPProblem(c, A_ub, b_ub, A_eq, b_eq, bounds, x0)
    lp_cleaned = _clean_inputs(lp)

def workload():
    global lp_cleaned
    _presolve(lp_cleaned, rr=False, tol=1e-9)

runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.4967294121615123
Before SD: 0.002219301745277715
After Mean: 0.015958753956947475
After SD: 0.0005166945958808974
Improvement: -96.79%",,1,docker.io/sweperf/sweperf:scipy__scipy-11358,docker.io/sweperf/sweperf_annotate:scipy__scipy-11358,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-11358 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2020-01-13 18:05:01,e53897db8416c0165b32883396023009d47cff22,1.4
,APPROVED,scipy__scipy-11478,https://github.com/scipy/scipy/pull/11478,"import timeit
import statistics
import numpy as np
import scipy.sparse as sp
import math
import gc

def setup():
    global A, B

    int32max = np.iinfo(np.int32).max
    limit_size = int(math.sqrt(int32max))
    density = 0.000000000000001
    gc.collect()
    N = limit_size
    data = np.array([np.arange(1, N+1)]).repeat(500, axis=0)
    offsets = np.arange(0, 500)
    A = sp.dia_matrix((data, offsets), shape=(N, N), dtype=np.int64).tocsr()
    B = sp.csr_matrix((N, N), dtype=np.int64)
    data = None
    offsets = None
    gc.collect()

    
def workload():
    global A, B
    A * B

runtimes = timeit.repeat(workload, number=1, repeat=40, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-20:]))
print(""Std Dev:"", statistics.stdev(runtimes[-20:]))","Before Mean: 0.06035097290005069
Before SD: 0.0021535533472914767
After Mean: 0.044701248398632744
After SD: 0.0002054733434569213
Improvement: -25.93%",,1,docker.io/sweperf/sweperf:scipy__scipy-11478,docker.io/sweperf/sweperf_annotate:scipy__scipy-11478,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-11478 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2020-02-06 20:56:12,1bee17531da6cc2c9b49785bf4f9359e5d74b645,1.4
,APPROVED,scipy__scipy-11517,https://github.com/scipy/scipy/pull/11517,"import timeit
import statistics

import scipy
from numpy import ones, array, asarray, empty, random
from scipy.sparse import dia_matrix

def poisson2d(N, dtype='d', format=None):
    if N == 1:
        diags = asarray([[4]], dtype=dtype)
        return dia_matrix((diags, [0]), shape=(1, 1)).asformat(format)

    offsets = array([0, -N, N, -1, 1])

    diags = empty((5, N**2), dtype=dtype)

    diags[0] = 4  
    diags[1:] = -1  

    diags[3, N-1::N] = 0  
    diags[4, N::N] = 0  

    return dia_matrix((diags, offsets), shape=(N**2, N**2)).asformat(format)

base_format = ""lil""
base = poisson2d(100, format=base_format)
to_formats = [""dok"", ""dia"", ""csr"", ""bsr"", ""coo""]
conversion_lambdas = [
    getattr(base, 'to' + to_format) for to_format in to_formats
]

def workload():
    for convert in conversion_lambdas:
        _ = convert()

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.04809004701609956
Before SD: 0.0007285407184013321
After Mean: 0.029658586282545002
After SD: 0.001208173468004867
Improvement: -38.33%",,1,docker.io/sweperf/sweperf:scipy__scipy-11517,docker.io/sweperf/sweperf_annotate:scipy__scipy-11517,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-11517 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2020-02-13 15:09:03,566ce19b81478df7418f6bf73641491a7b8937cb,1.4
,APPROVED,scipy__scipy-11757,https://github.com/scipy/scipy/pull/11757,"import timeit
import statistics

import scipy.stats
import numpy as np

inp = np.random.rand(9999).reshape(3,3333)*200

subbin_x_edges = np.arange(0, 200, dtype=np.float32)
subbin_y_edges = np.arange(0, 200, dtype=np.float64)

def workload():
    stat = 'std'
    binned_stat, _, _, binnumbers = scipy.stats.binned_statistic_2d(
        inp[0], inp[1], values=inp[2], statistic=stat,
        bins=[subbin_x_edges, subbin_y_edges], expand_binnumbers=True)

runtimes = timeit.repeat(workload, number=1, repeat=50)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.07099908509815578
Before SD: 0.0002812296778757681
After Mean: 0.03605785507941619
After SD: 0.00025463707561427205
Improvement: -49.21%",,1,docker.io/sweperf/sweperf:scipy__scipy-11757,docker.io/sweperf/sweperf_annotate:scipy__scipy-11757,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-11757 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2020-03-30 13:16:02,411fbbda0f942fcce3e4b314efb11c4553baaa7c,1.4
,APPROVED,scipy__scipy-11982,https://github.com/scipy/scipy/pull/11982,"import timeit
import statistics

import numpy as np
from scipy.cluster.vq import kmeans2

N = 1000
data = np.random.uniform(0., 1., (N, 4))

n_clusters = 50

def workload():
    centroid, labels1 = kmeans2(
        data, n_clusters, minit='++', iter=10, thresh=1.e-4)

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.329787013994064
Before SD: 0.009836633798138377
After Mean: 0.007932318199891597
After SD: 0.00016521343204212928
Improvement: -99.66%",,1,docker.io/sweperf/sweperf:scipy__scipy-11982,docker.io/sweperf/sweperf_annotate:scipy__scipy-11982,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-11982 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2020-04-30 20:46:39,0cae03b559b3459787b5c3a6aea727aeb3890b93,1.4
,APPROVED,scipy__scipy-12001,https://github.com/scipy/scipy/pull/12001,"
import timeit
import statistics
import numpy as np
from scipy.stats import maxwell

def setup():
    global data
    data = maxwell.rvs(loc=2.0, scale=3.0, size=100000, random_state=42)
    
def workload():
    global data
    _ = maxwell.fit(data)

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))
","Before Mean: 0.1465453120804159
Before SD: 0.004639901153919244
After Mean: 0.09456285839929478
After SD: 0.0030516411312583617
Improvement: -35.47%",,15,docker.io/sweperf/sweperf:scipy__scipy-12001,docker.io/sweperf/sweperf_annotate:scipy__scipy-12001,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-12001 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2020-05-02 20:35:35,fa612823f2d8b27f495192a77859c664c7f8a811,1.4
,APPROVED,scipy__scipy-12474,https://github.com/scipy/scipy/pull/12474,"import timeit
import statistics

import scipy.linalg
import numpy as np

mat = np.random.normal(size=(1000,1000))
mat = mat@mat.T

def workload():
    scipy.linalg.logm(mat)
    scipy.linalg.sqrtm(mat)

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 3.136666501304717
Before SD: 0.09674751495446701
After Mean: 2.7986764967034103
After SD: 0.12737711519153472
Improvement: -10.78%",,1,docker.io/sweperf/sweperf:scipy__scipy-12474,docker.io/sweperf/sweperf_annotate:scipy__scipy-12474,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-12474 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2020-07-02 15:05:27,2ea67057b1bbce3a253af89a92ee93ffc9c97525,1.5
,APPROVED,scipy__scipy-12587,https://github.com/scipy/scipy/pull/12587,"import timeit
import statistics

from scipy import stats
import numpy as np
sn = 500

np.random.seed(765456)

def workload():
    stats.gengamma.rvs(a=1.5, c=1.0, loc=0.0, scale=1.0, size=sn)

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.0005987636140489485
Before SD: 2.5678936052118128e-05
After Mean: 4.987826716387644e-05
After SD: 5.228756482182028e-06
Improvement: -91.67%",,15,docker.io/sweperf/sweperf:scipy__scipy-12587,docker.io/sweperf/sweperf_annotate:scipy__scipy-12587,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-12587 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2020-07-20 6:59:28,8bc35a85e8d495d337314409f033359cb59f87b5,1.5
,APPROVED,scipy__scipy-13107,https://github.com/scipy/scipy/pull/13107,"import timeit
import statistics

from scipy.optimize import linear_sum_assignment
import numpy as np

matrix_size = 8
cost_matrix = matrix_size * \
            np.random.random((matrix_size, matrix_size))

def workload():
    row_ind, column_ind = linear_sum_assignment(cost_matrix)

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 1.5699575014878065e-05
Before SD: 4.0894500936019995e-06
After Mean: 3.2887139823287725e-06
After SD: 1.3717984398586073e-06
Improvement: -79.05%",,2,docker.io/sweperf/sweperf:scipy__scipy-13107,docker.io/sweperf/sweperf_annotate:scipy__scipy-13107,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-13107 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2020-11-21 20:56:27,3a8a3a1d4657254a6611e77e9c28feafa26e6645,1.5
,APPROVED,scipy__scipy-13388,https://github.com/scipy/scipy/pull/13388,"import timeit
import statistics
import numpy as np
import scipy.stats as stats

def setup():
    global x
    np.random.random(1234)
    x = np.random.random(1000)
    
def workload():
    global x
    stats.kurtosis(x, bias=True)
    stats.skew(x, bias=True)

runtimes = timeit.repeat(workload, number=1, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 0.00017610069161164575
Before SD: 6.0575702949687095e-06
After Mean: 0.00010951923479151446
After SD: 2.575815238569035e-06
Improvement: -37.81%",,4,docker.io/sweperf/sweperf:scipy__scipy-13388,docker.io/sweperf/sweperf_annotate:scipy__scipy-13388,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-13388 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2021-01-14 18:17:21,5a42f061686fb9d2e899b183c16d1eacc2f2d036,1.6
,APPROVED,scipy__scipy-13566,https://github.com/scipy/scipy/pull/13566,"import scipy.stats as stats
import timeit
import statistics
import numpy as np
from numpy import float_, int_, ndarray
import numpy.ma as ma
from scipy.stats.distributions import norm, beta, t, binom

def setup():
    global n, x
    n = 10000
    x = np.random.normal(size=(n,))
    
def workload():
    global n, x
    _ = stats.mstats.hdquantiles_sd(x, prob=0.5)

runtimes = timeit.repeat(workload, number=1, repeat=4, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 12.288604574503552
Before SD: 0.03049704852302419
After Mean: 0.05797668375453213
After SD: 0.0004045604343105445
Improvement: -99.53%",,1,docker.io/sweperf/sweperf:scipy__scipy-13566,docker.io/sweperf/sweperf_annotate:scipy__scipy-13566,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-13566 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2021-02-15 20:07:06,bf7a9cc689bd1f81966b464caa725d2c02d02dd7,1.6
,APPROVED,scipy__scipy-13611,https://github.com/scipy/scipy/pull/13611,"import timeit
import statistics
import numpy as np
import scipy.ndimage as ndimage
from scipy.stats._distn_infrastructure import argsreduce

def setup():
    global g, loc, cond
    n = 1000000
    g = 500
    loc = 300
    cond = np.random.rand(n) > 0.3
    
def workload():
    global g, loc, cond
    g_, loc_ = argsreduce(cond, g, loc)
    _ = (1 - g_ ** 2) / np.sqrt(2 * np.pi)

runtimes = timeit.repeat(workload, number=1, repeat=2000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 0.019949894019431667
Before SD: 0.0005101324920087239
After Mean: 3.368211988708936e-05
After SD: 9.723308233864493e-06
Improvement: -99.83%",,18,docker.io/sweperf/sweperf:scipy__scipy-13611,docker.io/sweperf/sweperf_annotate:scipy__scipy-13611,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-13611 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2021-02-25 12:05:47,d55d3a0d197bfa40bc40c5542c980973797471f3,1.6
,APPROVED,scipy__scipy-13759,https://github.com/scipy/scipy/pull/13759,"import timeit
import statistics
import numpy as np
from scipy.integrate import simpson

def setup():
    global x, y
    x = np.linspace(1, 2001, 20001)
    y = np.random.random((1001, 20001))
    
def workload():
    global x, y
    _ = simpson(y, x, axis=-1);

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))
","Before Mean: 0.17143508714428754
Before SD: 0.004650280492473454
After Mean: 0.11835847006877884
After SD: 0.0016645536737262216
Improvement: -30.96%",,1,docker.io/sweperf/sweperf:scipy__scipy-13759,docker.io/sweperf/sweperf_annotate:scipy__scipy-13759,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-13759 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2021-03-28 6:03:18,d380fb7f640280c026cf7f253669d68c15373275,1.6
,APPROVED,scipy__scipy-13786,https://github.com/scipy/scipy/pull/13786,"import timeit
import statistics
import numpy as np
from scipy.spatial.distance import cdist

def setup():
    global a, w
    a = np.random.rand(100, 10)
    w = np.random.rand(10)
    
def workload():
    global a, w
    cdist(a, a, w=w, metric='chebyshev')

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.09956059888849268
Before SD: 0.00033465268970966303
After Mean: 8.144157996866852e-05
After SD: 3.8830099383362485e-06
Improvement: -99.92%",,8,docker.io/sweperf/sweperf:scipy__scipy-13786,docker.io/sweperf/sweperf_annotate:scipy__scipy-13786,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-13786 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2021-04-01 19:54:17,374e5bfec63e530c34514a08d9311352138182f3,1.6
,APPROVED,scipy__scipy-14004,https://github.com/scipy/scipy/pull/14004,"import timeit
import statistics
import numpy as np
from scipy.sparse import diags, dia_matrix

def setup():
    global M1, M2, M3
    N = 100000
    M1 = diags(diagonals = [np.random.random(N-1), np.random.random(N), np.random.random(N-1)], offsets = [-1, 0, 1])
    M2 = diags(diagonals = [np.random.random(N-1), np.random.random(N), np.random.random(N-1)], offsets = [-1, 0, 1])
    M3 = diags(diagonals = [np.random.random(N-1), np.random.random(N), np.random.random(N-1)], offsets = [-1, 0, 1])

def workload():
    global M1, M2, M3
    
    _ = M1 + M2 + M3

runtimes = timeit.repeat(workload, number=1, repeat=2000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 0.021750678218522806
Before SD: 0.0006339725787644856
After Mean: 0.0022210057891497853
After SD: 0.0008071594656876471
Improvement: -89.79%",,1,docker.io/sweperf/sweperf:scipy__scipy-14004,docker.io/sweperf/sweperf_annotate:scipy__scipy-14004,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-14004 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2021-05-09 8:08:20,617ee9fdf458b53ed5f57cb51a8f189fa40f24f4,1.6
,APPROVED,scipy__scipy-14085,https://github.com/scipy/scipy/pull/14085,"import timeit
import statistics
import numpy as np
from scipy.spatial import distance

def setup():
    global xd

    class XdistWeighted:
        params = (
            [10, 20, 100],
            ['euclidean', 'minkowski', 'cityblock', 'sqeuclidean', 'cosine',
             'correlation', 'hamming', 'jaccard', 'chebyshev', 'canberra',
             'braycurtis', 'yule', 'dice', 'kulczynski1', 'rogerstanimoto',
             'russellrao', 'sokalmichener', 'sokalsneath', 'minkowski-P3'])
        param_names = ['num_points', 'metric']

        def setup(self, num_points, metric):
            rng = np.random.default_rng(123)
            self.points = rng.random((num_points, 3))
            self.metric = metric
            if metric == 'minkowski-P3':
                # p=2 is just the euclidean metric, try another p value as well
                self.kwargs = {'p': 3.0}
                self.metric = 'minkowski'
            else:
                self.kwargs = {}
            self.weights = np.ones(3)

    xd = XdistWeighted()
    xd.setup(100, 'canberra')

def workload():
    global xd
    distance.pdist(xd.points, xd.metric, w=xd.weights, **xd.kwargs)
    distance.cdist(xd.points, xd.points, xd.metric, w=xd.weights, **xd.kwargs)

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))

","Before Mean: 0.2707862485406804
Before SD: 0.00208467236842253
After Mean: 6.496348039945587e-05
After SD: 2.5740330588724652e-06
Improvement: -99.98%",,8,docker.io/sweperf/sweperf:scipy__scipy-14085,docker.io/sweperf/sweperf_annotate:scipy__scipy-14085,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-14085 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2021-05-19 0:41:19,bf9443281a7bc2335ea51119f1ca5913494ef200,1.6
,APPROVED,scipy__scipy-14625,https://github.com/scipy/scipy/pull/14625,"import timeit
import statistics
import numpy as np
from scipy import stats

def setup():
    global data, l, b
    mu = np.array([0., 1.])
    sigma = np.array([[1., -0.5],[-0.5, 1.5]])
    multinormal = stats.multivariate_normal(mu, sigma)
    data = multinormal.rvs(size=600, random_state=235412)
    N = 60
    x = np.linspace(-3, 3, N)
    y = np.linspace(-3, 4, N)
    l = np.arange(600)
    b = [x, y]
    
def workload():
    global data, l, b
    _ = stats.binned_statistic_dd(data, l , bins = b ,statistic='min')
    _ = stats.binned_statistic_dd(data, l , bins = b ,statistic='max')
    _ = stats.binned_statistic_dd(data, l , bins = b ,statistic='median')

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.00989377124060411
Before SD: 6.103649497001311e-05
After Mean: 0.0007604185401578434
After SD: 1.8590331912393952e-05
Improvement: -92.31%",,1,docker.io/sweperf/sweperf:scipy__scipy-14625,docker.io/sweperf/sweperf_annotate:scipy__scipy-14625,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-14625 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2021-08-20 23:42:55,75ef7dbcbee1fa5114de86a3238333978350056a,1.7
,APPROVED,scipy__scipy-16449,https://github.com/scipy/scipy/pull/16449,"import timeit
import statistics
import numpy as np
from scipy.interpolate import RegularGridInterpolator

def setup():
    global interp, pts
    
    def f(x, y, z):
        return 2 * x**3 + 3 * y**2 - z
        
    x = np.linspace(1, 4, 11)
    y = np.linspace(4, 7, 22)
    z = np.linspace(7, 9, 33)
    xg, yg ,zg = np.meshgrid(x, y, z, indexing='ij', sparse=True)
    data = f(xg, yg, zg)
    interp = RegularGridInterpolator((x, y, z), data)
    pts = np.array([[2.1, 6.2, 8.3],[3.3, 5.2, 7.1]])
    
def workload():
    global interp, pts
    _ = interp(pts)

runtimes = timeit.repeat(workload, number=1, repeat=20, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10:]))","Before Mean: 0.00019021769694518297
Before SD: 2.954102363955421e-06
After Mean: 0.00014206640189513565
After SD: 1.057916036862758e-06
Improvement: -25.31%",,1,docker.io/sweperf/sweperf:scipy__scipy-16449,docker.io/sweperf/sweperf_annotate:scipy__scipy-16449,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-16449 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2022-06-21 19:53:05,5f92e82876e876bb8132c6ad9ed53c500e05f93e,1.8
,APPROVED,scipy__scipy-16599,https://github.com/scipy/scipy/pull/16599,"import timeit
import statistics

from scipy.stats import truncnorm
import numpy as np

beta = np.array([-1.25,  -1,  -0.5])
x1 = np.random.uniform(-2.0,  2.0, size=900 * 3).reshape(900,  -1)
x1[:,  0] = 1

def workload():
    truncnorm(-x1@beta, np.inf, loc=x1@beta).rvs()

runtimes = timeit.repeat(workload, number=1, repeat=50)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.03638261064188555
Before SD: 0.0005573182061887917
After Mean: 0.0011716527008684351
After SD: 7.629699596193581e-05
Improvement: -96.78%",,3,docker.io/sweperf/sweperf:scipy__scipy-16599,docker.io/sweperf/sweperf_annotate:scipy__scipy-16599,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-16599 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2022-07-14 7:24:52,bd608529707806dac87f9b66c15b805989ffa920,1.9
,APPROVED,scipy__scipy-16790,https://github.com/scipy/scipy/pull/16790,"import timeit
import statistics
from scipy import stats

def setup():
    global m, s, se
    m = 2./2.001
    s = 2.001
    se = 0.9643504
    
def workload():
    global m, s, se
    _ = stats.invgauss(mu=m, scale=s).ppf(se)

runtimes = timeit.repeat(workload, number=1, repeat=2000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 0.0014892340661317575
Before SD: 2.3790378460525456e-05
After Mean: 0.00048166589130414647
After SD: 1.6160138338823244e-05
Improvement: -67.66%",,26,docker.io/sweperf/sweperf:scipy__scipy-16790,docker.io/sweperf/sweperf_annotate:scipy__scipy-16790,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-16790 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2022-08-05 23:14:28,ac729b8f96a018b9156a0e5679e18b5d6e2e70a7,1.9
,APPROVED,scipy__scipy-16840,https://github.com/scipy/scipy/pull/16840,"import timeit
import statistics
import numpy as np
from scipy.interpolate import BSpline

def setup():
    global x, t, k
    k=3
    x = np.linspace(0, 9, 100_000)
    t = np.r_[-3, -2, -1, np.linspace(-1, 9, 40), 10, 11, 12]
    
def workload():
    global x, t, k
    BSpline.design_matrix(x, t, k)

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.12909844153851735
Before SD: 0.0008911069492186719
After Mean: 0.013781209611042868
After SD: 0.000288049166343574
Improvement: -89.33%",,12,docker.io/sweperf/sweperf:scipy__scipy-16840,docker.io/sweperf/sweperf_annotate:scipy__scipy-16840,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-16840 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2022-08-15 18:51:52,ac729b8f96a018b9156a0e5679e18b5d6e2e70a7,1.9
,APPROVED,scipy__scipy-18211,https://github.com/scipy/scipy/pull/18211,"import timeit
import statistics
import numpy as np
import scipy.sparse as sp

def setup():
    global N, A, L
    N = 10**4
    A = sp.diags(np.ones(N))
    L = sp.lil_matrix((N,N))

    
def workload():
    global N, A, L
    L += A

runtimes = timeit.repeat(workload, number=1, repeat=20, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10:]))","Before Mean: 1.4036083996994422
Before SD: 0.0069026516969304405
After Mean: 0.007591458002571017
After SD: 1.9727102150590584e-05
Improvement: -99.46%",,2,docker.io/sweperf/sweperf:scipy__scipy-18211,docker.io/sweperf/sweperf_annotate:scipy__scipy-18211,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-18211 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2023-03-29 4:57:31,bd6423f6332ddbfb6d27ab20898018c5aafff7e5,1.1
,APPROVED,scipy__scipy-18799,https://github.com/scipy/scipy/pull/18799,"
import timeit
import statistics
import numpy as np
from scipy import stats

def setup():
    global gh, x
    a, b, c, z = 1.5, 2.5, 2, 0

    gh = stats.gausshyper(a=a, b=b, c=c, z=z)

    x = np.linspace(0, 1, 1000)
        
def workload():
    global gh, x
    _ = gh.cdf(x)
    _ = gh.rvs(size=1000)
    
runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10:]))","Before Mean: 8.529020080898771
Before SD: 0.05384049214632222
After Mean: 6.761991870997008
After SD: 0.15681205560148012
Improvement: -20.72%",,1,docker.io/sweperf/sweperf:scipy__scipy-18799,docker.io/sweperf/sweperf_annotate:scipy__scipy-18799,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-18799 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2023-06-30 18:29:57,31d8948250aaa3c67df77b237d4126592343a6e6,1.11
,APPROVED,scipy__scipy-18850,https://github.com/scipy/scipy/pull/18850,"import timeit
import statistics

from scipy.spatial import SphericalVoronoi
import numpy as np

num_points = 10000
ndim = 2

def generate_circle_points(num_points):
    angles = np.linspace(0, 1.9999 * np.pi, num_points)
    points = np.empty(shape=(num_points, 2))
    points[..., 0] = np.cos(angles)
    points[..., 1] = np.sin(angles)
    return points

center = np.zeros(2)
points = generate_circle_points(num_points)

def setup():
    global sv
    sv = SphericalVoronoi(points, radius=1,
                          center=center)
    
def workload():
    global sv
    sv.calculate_areas()

runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))
","Before Mean: 0.001688537521258695
Before SD: 2.295674032860525e-05
After Mean: 0.0007942560049705208
After SD: 3.781032058884875e-05
Improvement: -52.96%",,1,docker.io/sweperf/sweperf:scipy__scipy-18850,docker.io/sweperf/sweperf_annotate:scipy__scipy-18850,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-18850 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2023-07-09 20:48:00,64a533e511753e71b21956dc2c71f89eb9c28c19,1.11
,APPROVED,scipy__scipy-18917,https://github.com/scipy/scipy/pull/18917,"import timeit
import statistics

import scipy.signal

# Generate a large array to compute the spline on.
import numpy as np

data = np.random.rand(1000000)  # Adjust size as needed
    
def workload():
    scipy.signal.cspline1d(data)
    scipy.signal.qspline1d(data)

runtimes = timeit.repeat(workload, number=1, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.0537665090209338
Before SD: 0.004513079109404859
After Mean: 0.16560001798177837
After SD: 0.0016845501345679006
Improvement: -84.28%",,2,docker.io/sweperf/sweperf:scipy__scipy-18917,docker.io/sweperf/sweperf_annotate:scipy__scipy-18917,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-18917 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2023-07-19 20:35:45,defcb37766e99d77e1997728d65a890efe895074,1.11
,APPROVED,scipy__scipy-18996,https://github.com/scipy/scipy/pull/18996,"import timeit
import statistics
import numpy as np
from scipy.optimize import curve_fit

def setup():
    global x, y, func
    
    np.random.seed(0)
    x = np.arange(100)
    y = 2 * np.exp(-.1 * x) + .25 * np.random.rand(len(x))
    func = lambda x, a, b: a * np.exp(-b * x)
    
def workload():
    global x, y, func
    _ , _ = curve_fit(func, x, y)

runtimes = timeit.repeat(workload, number=1, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 0.0003104545739159221
Before SD: 8.74724190230862e-06
After Mean: 0.00024386610340734478
After SD: 1.0470613203818106e-05
Improvement: -21.45%",,1,docker.io/sweperf/sweperf:scipy__scipy-18996,docker.io/sweperf/sweperf_annotate:scipy__scipy-18996,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-18996 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2023-07-31 23:49:04,739f705bf6700c46b7b84833e80bf48b9d35114c,1.11
,APPROVED,scipy__scipy-19324,https://github.com/scipy/scipy/pull/19324,"import timeit
import statistics
import numpy as np
from scipy import integrate

def setup():
    global f
    def f(x):
        return np.sin(x) * np.exp(1j * x**2)
    
def workload():
    global f
    _ , _ = integrate.quad(f, 0, 1, complex_func=True)

runtimes = timeit.repeat(workload, number=1, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 8.670612360583618e-05
Before SD: 2.4234730124910107e-06
After Mean: 6.760434339521452e-05
After SD: 1.6911646384898189e-06
Improvement: -22.03%",,2,docker.io/sweperf/sweperf:scipy__scipy-19324,docker.io/sweperf/sweperf_annotate:scipy__scipy-19324,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-19324 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2023-09-29 10:44:50,8a3629ccdec913012c248657342391ab27fe2eff,1.11
,APPROVED,scipy__scipy-19583,https://github.com/scipy/scipy/pull/19583,"import timeit
import statistics
import numpy as np
import scipy.spatial

def setup():
    global x, y, w
    x = np.random.normal(size=512)
    y = np.random.normal(size=512)
    w = np.random.uniform(size=512)
    
def workload():
    global x, y, w
    scipy.spatial.distance.cosine(x, y)
    scipy.spatial.distance.cosine(x, y, w)
    scipy.spatial.distance.correlation(x, y)
    scipy.spatial.distance.correlation(x, y, w)
    
runtimes = timeit.repeat(workload, number=1, repeat=2000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 0.00013726252148626373
Before SD: 2.9992692827839912e-06
After Mean: 4.256376082776114e-05
After SD: 1.5921384888309588e-06
Improvement: -68.99%",,1,docker.io/sweperf/sweperf:scipy__scipy-19583,docker.io/sweperf/sweperf_annotate:scipy__scipy-19583,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-19583 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2023-11-24 2:38:20,ae9dc13161cb227d7651c58dc47971193510221d,1.11
,APPROVED,scipy__scipy-19589,https://github.com/scipy/scipy/pull/19589,"import timeit
import statistics
import numpy as np
import scipy.spatial

def setup():
    global x, y, w
    x = np.random.normal(size=512)
    y = np.random.normal(size=512)
    w = np.random.uniform(size=512)
    
def workload():
    global x, y, w
    scipy.spatial.distance.hamming(x, y, w)

runtimes = timeit.repeat(workload, number=1, repeat=200000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100000:]))","Before Mean: 1.610941714985529e-05
Before SD: 1.7218641408459703e-06
After Mean: 9.708716613822616e-06
After SD: 9.04965188698648e-07
Improvement: -39.73%",,1,docker.io/sweperf/sweperf:scipy__scipy-19589,docker.io/sweperf/sweperf_annotate:scipy__scipy-19589,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-19589 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2023-11-24 21:32:32,44ca7042b6f863b1a80b97bee2f09dbac870dabd,1.11
,APPROVED,scipy__scipy-19749,https://github.com/scipy/scipy/pull/19749,"
import timeit
import statistics
import numpy as np
from scipy import stats

def setup():
    global x, y
    rng = np.random.default_rng(2549824598234528)
    x = rng.integers(5, size=(10,1))
    y = rng.integers(5, size=(4000,20000))
    
def workload():
    global x, y
    _ = stats.mannwhitneyu(x, y)

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-5:]))
print(""Std Dev:"", statistics.stdev(runtimes[-5:]))","Before Mean: 25.1835427729995
Before SD: 0.11989253916688174
After Mean: 3.6584269520069936
After SD: 0.03429178527892171
Improvement: -85.47%",,32,docker.io/sweperf/sweperf:scipy__scipy-19749,docker.io/sweperf/sweperf_annotate:scipy__scipy-19749,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-19749 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2023-12-24 1:36:51,c77938cd5efc24c0a87867dbd5a37b85889e19cd,1.12
,APPROVED,scipy__scipy-19776,https://github.com/scipy/scipy/pull/19776,"import timeit
import statistics
from scipy.stats import rankdata
import numpy as np

def setup():
    global arr
    arr = np.random.randint(0, 100, size=(1000, 500), dtype=np.int64)

    
def workload():
    global arr
    _ = rankdata(arr)

runtimes = timeit.repeat(workload, number=1, repeat=2000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-1000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-1000:]))","Before Mean: 0.0239969837233366
Before SD: 0.0011285952159466107
After Mean: 0.01766783960466273
After SD: 0.0008027824622692934
Improvement: -26.37%",,8,docker.io/sweperf/sweperf:scipy__scipy-19776,docker.io/sweperf/sweperf_annotate:scipy__scipy-19776,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-19776 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2023-12-29 6:09:36,35e98491fff54cd0fab61988e0fee16e1521aeaf,1.12
,APPROVED,scipy__scipy-19962,https://github.com/scipy/scipy/pull/19962,"import timeit
import statistics
import numpy as np
from scipy.sparse import random, lil_matrix, lil_array
from scipy.sparse.linalg import spsolve
from numpy.linalg import solve, norm
from numpy.random import rand
from scipy.sparse import csr_matrix

def setup():
    global A, N
    
    N = 10000
    A = csr_matrix((N, N))
def workload():
    global A, N

    A._setdiag(np.arange(N), 0)
    

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))
","Before Mean: 0.06288794602092822
Before SD: 0.00046431296258194366
After Mean: 0.00017715080175548792
After SD: 3.301002769541719e-06
Improvement: -99.72%",,15,docker.io/sweperf/sweperf:scipy__scipy-19962,docker.io/sweperf/sweperf_annotate:scipy__scipy-19962,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-19962 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2024-01-25 2:39:54,c25db773fda5945314f000336bcf907eaa1a6843,1.12
,APPROVED,scipy__scipy-20325,https://github.com/scipy/scipy/pull/20325,"import timeit
import statistics
import numpy as np
import scipy.ndimage as ndimage

def setup():
    global data, structure
    data  = (np.random.rand(24, 20)+.5).astype(int)
    structure=np.array([[1,1,1]])
    
def workload():
    global data, structure
    ndimage.binary_erosion(data, structure)

runtimes = timeit.repeat(workload, number=1, repeat=20000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10000:]))","Before Mean: 1.577047994651366e-05
Before SD: 7.020388418651947e-07
After Mean: 1.1376060091424733e-05
After SD: 5.863832799742077e-07
Improvement: -27.86%",,1,docker.io/sweperf/sweperf:scipy__scipy-20325,docker.io/sweperf/sweperf_annotate:scipy__scipy-20325,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-20325 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2024-03-24 19:45:38,f4263c24524f0b5ac5078056aa51721b8ca46392,1.13
,APPROVED,scipy__scipy-21440,https://github.com/scipy/scipy/pull/21440,"import timeit
import statistics

import numpy as np
from scipy.linalg import funm
rng = np.random.default_rng(123456)
A = rng.random((100, 100))

def workload():
    funm(A, lambda x: x*x)

runtimes = timeit.repeat(workload, number=5, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 0.10417732631205581
Before SD: 0.0007137569782281631
After Mean: 0.042506447450723496
After SD: 0.0003453858296674933
Improvement: -59.20%",,1,docker.io/sweperf/sweperf:scipy__scipy-21440,docker.io/sweperf/sweperf_annotate:scipy__scipy-21440,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-21440 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2024-08-23 20:57:56,8542c166eb1b0e3845fb7d9a3572af902e4e9b83,1.14
,APPROVED,scipy__scipy-22610,https://github.com/scipy/scipy/pull/22610,"import timeit
import statistics

import scipy.stats
import numpy

df = 10
mean = 0
std = 1

def workload():
    # Create T-distribution and Normal distribution objects
    rv_t = scipy.stats.t(df, mean, std)
    rv_n = scipy.stats.norm(mean, std)

    # Evaluate their PDFs on a grid of x-values
    x_vals = numpy.linspace(-3, 3, 100)
    t_pdf = rv_t.pdf(x_vals)
    n_pdf = rv_n.pdf(x_vals)

runtimes = timeit.repeat(workload, number=5, repeat=100)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.005264186960121151
Before SD: 8.491466570142749e-05
After Mean: 0.0047640434696222655
After SD: 9.018058965369086e-05
Improvement: -9.50%",,3,docker.io/sweperf/sweperf:scipy__scipy-22610,docker.io/sweperf/sweperf_annotate:scipy__scipy-22610,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-22610 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2025-03-01 16:28:18,cea714d74ec578be07484dbb2ecfc2eb8178fcbb,1.15
,APPROVED,scipy__scipy-22660,https://github.com/scipy/scipy/pull/22660,"import timeit
import statistics

import numpy as np
from scipy import sparse
from scipy.optimize import linprog
from scipy.sparse import csr_matrix

def coherent_linear_quantile_regression(
    X,
    y,
    *,
    quantiles,
    sample_weight = None,
    coherence_buffer = 3,
):
    """"""Solve a Coherent Linear Quantile Regression problem.

    Minimizes the quantile loss:

        ∑ᵢ,ⱼ {
                 qⱼ (yᵢ - ŷ⁽ʲ⁾ᵢ) : yᵢ ≥ ŷ⁽ʲ⁾ᵢ,
            (1 - qⱼ)(ŷ⁽ʲ⁾ᵢ - yᵢ) : ŷ⁽ʲ⁾ᵢ > yᵢ
        }

    for the linear model ŷ⁽ʲ⁾ := Xβ⁽ʲ⁾, given an input dataset X, target y, and quantile ranks qⱼ.

    We achieve so-called 'coherent' quantiles by enforcing monotonicity of the predicted quantiles
    with the constraint Xβ⁽ʲ⁾ ≤ Xβ⁽ʲ⁺¹⁾ for each consecutive pair of quantile ranks in an extended
    set of quantile ranks that comprises the requested quantile ranks and a number of auxiliary
    quantile ranks in between.

    The optimization problem is formulated as a linear program by introducing the auxiliary residual
    vectors Δ⁽ʲ⁾⁺, Δ⁽ʲ⁾⁻ ≥ 0 so that Xβ⁽ʲ⁾ - y = Δ⁽ʲ⁾⁺ - Δ⁽ʲ⁾⁻. The objective then becomes
    ∑ᵢ,ⱼ qⱼΔ⁽ʲ⁾⁻ᵢ + (1 - qⱼ)Δ⁽ʲ⁾⁺ᵢ + αt⁽ʲ⁾ᵢ for t⁽ʲ⁾ := |β⁽ʲ⁾|. The L1 regularization parameter α is
    automatically determined to minimize the impact on the solution β.

    Parameters
    ----------
    X
        The feature matrix.
    y
        The target values.
    quantiles
        The quantiles to estimate (between 0 and 1).
    sample_weight
        The optional sample weight to use for each sample.
    coherence_buffer
        The number of auxiliary quantiles to introduce. Smaller is faster, larger yields more
        coherent quantiles.

    Returns
    -------
    β
        The estimated regression coefficients so that Xβ produces quantile predictions ŷ.
    β_full
        The estimated regression coefficients including all auxiliary quantiles.
    """"""
    # Learn the input dimensions.
    num_samples, num_features = X.shape
    # Add buffer quantile ranks in between the given quantile ranks so that we have an even stronger
    # guarantee on the monotonicity of the predicted quantiles.
    quantiles = np.interp(
        x=np.linspace(0, len(quantiles) - 1, (len(quantiles) - 1) * (1 + coherence_buffer) + 1),
        xp=np.arange(len(quantiles)),
        fp=quantiles,
    ).astype(quantiles.dtype)
    num_quantiles = len(quantiles)
    # Validate the input.
    assert np.array_equal(quantiles, np.sort(quantiles)), ""Quantile ranks must be sorted.""
    assert sample_weight is None or np.all(sample_weight >= 0), ""Sample weights must be >= 0.""
    # Normalise the sample weights.
    sample_weight = np.ones(num_samples, dtype=y.dtype) if sample_weight is None else sample_weight
    sample_weight /= np.sum(sample_weight)
    eps = np.finfo(y.dtype).eps
    α = eps**0.25 / (num_quantiles * num_features)
    # Construct the objective function ∑ᵢ,ⱼ qⱼΔ⁽ʲ⁾⁻ᵢ + (1 - qⱼ)Δ⁽ʲ⁾⁺ᵢ + αt⁽ʲ⁾ᵢ for t⁽ʲ⁾ := |β⁽ʲ⁾|.
    c = np.hstack(
        [
            np.zeros(num_quantiles * num_features, dtype=y.dtype),  # β⁽ʲ⁾ for each qⱼ
            α * np.ones(num_quantiles * num_features, dtype=y.dtype),  # t⁽ʲ⁾ for each qⱼ
            np.kron((1 - quantiles) / num_quantiles, sample_weight),  # Δ⁽ʲ⁾⁺ for each qⱼ
            np.kron(quantiles / num_quantiles, sample_weight),  # Δ⁽ʲ⁾⁻ for each qⱼ
        ]
    )
    # Construct the equalities Xβ⁽ʲ⁾ - y = Δ⁽ʲ⁾⁺ - Δ⁽ʲ⁾⁻ for each quantile rank qⱼ.
    A_eq = sparse.hstack(
        [
            # Xβ⁽ʲ⁾ for each qⱼ (block diagonal matrix)
            sparse.kron(sparse.eye(num_quantiles, dtype=X.dtype), X),
            # t⁽ʲ⁾ not used in this constraint
            csr_matrix((num_quantiles * num_samples, num_quantiles * num_features), dtype=X.dtype),
            # -Δ⁽ʲ⁾⁺ for each qⱼ (block diagonal matrix)
            -sparse.eye(num_quantiles * num_samples, dtype=X.dtype),
            # Δ⁽ʲ⁾⁻ for each qⱼ (block diagonal matrix)
            sparse.eye(num_quantiles * num_samples, dtype=X.dtype),
        ]
    )
    b_eq = np.tile(y, num_quantiles)
    # Construct the inequalities -t⁽ʲ⁾ <= β⁽ʲ⁾ <= t⁽ʲ⁾ for each quantile rank qⱼ so that
    # t⁽ʲ⁾ := |β⁽ʲ⁾|. Also construct the monotonicity constraint Xβ⁽ʲ⁾ <= Xβ⁽ʲ⁺¹⁾ for each qⱼ,
    # equivalent to Δ⁽ʲ⁾⁺ - Δ⁽ʲ⁾⁻ <= Δ⁽ʲ⁺¹⁾⁺ - Δ⁽ʲ⁺¹⁾⁻.
    zeros_Δ = csr_matrix(
        (num_quantiles * num_features, 2 * num_quantiles * num_samples), dtype=X.dtype
    )
    zeros_βt = csr_matrix(
        ((num_quantiles - 1) * num_samples, 2 * num_quantiles * num_features), dtype=X.dtype
    )
    A_ub = sparse.vstack(
        [
            sparse.hstack(
                [
                    sparse.eye(num_quantiles * num_features, dtype=X.dtype),  # β⁽ʲ⁾
                    -sparse.eye(num_quantiles * num_features, dtype=X.dtype),  # -t⁽ʲ⁾
                    zeros_Δ,  # Δ⁽ʲ⁾⁺ and Δ⁽ʲ⁾⁺ not used for this constraint
                ]
            ),
            sparse.hstack(
                [
                    -sparse.eye(num_quantiles * num_features, dtype=X.dtype),  # -β⁽ʲ⁾
                    -sparse.eye(num_quantiles * num_features, dtype=X.dtype),  # -t⁽ʲ⁾
                    zeros_Δ,  # Δ⁽ʲ⁾⁺ and Δ⁽ʲ⁾⁺ not used for this constraint
                ]
            ),
            sparse.hstack(
                [
                    zeros_βt,
                    sparse.kron(
                        sparse.diags(
                            diagonals=[1, -1],  # Δ⁽ʲ⁾⁺ - Δ⁽ʲ⁺¹⁾⁺
                            offsets=[0, 1],
                            shape=(num_quantiles - 1, num_quantiles),
                            dtype=X.dtype,
                        ),
                        sparse.eye(num_samples, dtype=X.dtype),
                    ),
                    sparse.kron(
                        sparse.diags(
                            diagonals=[-1, 1],  # -Δ⁽ʲ⁾⁻ + Δ⁽ʲ⁺¹⁾⁻
                            offsets=[0, 1],
                            shape=(num_quantiles - 1, num_quantiles),
                            dtype=X.dtype,
                        ),
                        sparse.eye(num_samples, dtype=X.dtype),
                    ),
                ]
            ),
        ]
    )
    b_ub = np.zeros(A_ub.shape[0], dtype=X.dtype)
    # Construct the bounds.
    bounds = (
        ([(None, None)] * num_quantiles * num_features)  # β⁽ʲ⁾ for each qⱼ
        + ([(0, None)] * num_quantiles * num_features)  # t⁽ʲ⁾ for each qⱼ
        + ([(0, None)] * num_quantiles * num_samples)  # Δ⁽ʲ⁾⁺ for each qⱼ
        + ([(0, None)] * num_quantiles * num_samples)  # Δ⁽ʲ⁾⁻ for each qⱼ
    )
    # Solve the Coherent Quantile Regression LP.
    result = linprog(c=c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=""highs"")
    # Extract the solution.
    β_full = result.x[: num_quantiles * num_features].astype(y.dtype)
    β_full = β_full.reshape(num_quantiles, num_features).T
    # Drop the buffer quantile ranks we introduced earlier.
    β = β_full[:, 0 :: (coherence_buffer + 1)]
    return β, β_full

np.random.seed(42)
n, d = 500, 5
X = np.random.randn(n, d)
y = np.random.randn(n)
quantiles = np.asarray((0.25, 0.5, 0.75))

def workload():
    coherent_linear_quantile_regression(X, y, quantiles=quantiles)

runtimes = timeit.repeat(workload, number=1, repeat=3)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))

","Before Mean: 33.84564793532869
Before SD: 0.06715501305965321
After Mean: 1.0454948906747934
After SD: 0.03822919011083646
Improvement: -96.91%",,2,docker.io/sweperf/sweperf:scipy__scipy-22660,docker.io/sweperf/sweperf_annotate:scipy__scipy-22660,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-22660 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2025-03-09 19:37:03,bb9fdc6e82d3663edb519753f3bf4d6df686c5b1,1.15
,APPROVED,scipy__scipy-22676,https://github.com/scipy/scipy/pull/22676,"import timeit
import statistics

import numpy as np
from scipy import stats

rng = np.random.default_rng(23458924958234563)

x = rng.integers(0, 10, size=1_000_000)
y = x.reshape(100000, 10)

def workload():
    stats.mode(y, axis=-1)

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 1.7567660578992217
Before SD: 0.008889811558488805
After Mean: 0.032902968997950664
After SD: 0.0009738227557230196
Improvement: -98.13%",,37,docker.io/sweperf/sweperf:scipy__scipy-22676,docker.io/sweperf/sweperf_annotate:scipy__scipy-22676,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-22676 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2025-03-12 23:23:30,433abd63acbb0f91fb9b51619063557e1e4f7ad9,1.15
,APPROVED,scipy__scipy-8558,https://github.com/scipy/scipy/pull/8558,"import timeit
import statistics
import numpy as np
np.random.seed(42)

from scipy import stats

def measure(n):
    ""Measurement model, return two coupled measurements.""
    m1 = np.random.normal(size=n)
    m2 = np.random.normal(scale=0.5, size=n)
    return m1+m2, m1-m2

def setup():
    global kernel, positions
    m1, m2 = measure(2000)
    xmin = m1.min()
    xmax = m1.max()
    ymin = m2.min()
    ymax = m2.max()

    X, Y = np.mgrid[xmin:xmax:200j, ymin:ymax:200j]
    positions = np.vstack([X.ravel(), Y.ravel()])
    values = np.vstack([m1, m2])
    kernel = stats.gaussian_kde(values)

def workload():
    global kernel, positions
    kernel(positions)

runtimes = timeit.repeat(workload, number=1, repeat=20, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-10:]))
print(""Std Dev:"", statistics.stdev(runtimes[-10:]))","Before Mean: 1.2927865508041578
Before SD: 0.11194089398639237
After Mean: 0.7688063387031434
After SD: 0.0009107950556574929
Improvement: -40.53%",,1,docker.io/sweperf/sweperf:scipy__scipy-8558,docker.io/sweperf/sweperf_annotate:scipy__scipy-8558,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-8558 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2018-03-15 18:08:00,98e28806dc0985fdb8749fdbbe3d78700f29fbe4,1
,APPROVED,scipy__scipy-9455,https://github.com/scipy/scipy/pull/9455,"import timeit
import statistics

import numpy as np
import scipy.linalg

n = 100
A = np.random.rand(n,n)
A_lu = scipy.linalg.lu_factor(A, check_finite=False)

def workload():
    f = np.random.rand(n)
    for i in range(50000):
        f = scipy.linalg.lu_solve(A_lu, f, check_finite=False)

runtimes = timeit.repeat(workload, number=1, repeat=5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.7088058171968441
Before SD: 0.001371813961632121
After Mean: 0.39792132480069997
After SD: 0.0012923947379579596
Improvement: -43.86%",,19,docker.io/sweperf/sweperf:scipy__scipy-9455,docker.io/sweperf/sweperf_annotate:scipy__scipy-9455,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-9455 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2018-11-08 1:29:45,55393009bbc1dfe07ecd50d45cbea9e95d83b603,1.1
,APPROVED,scipy__scipy-9766,https://github.com/scipy/scipy/pull/9766,"import timeit
import statistics

from scipy.ndimage.filters import _gaussian_kernel1d

def workload():
    _gaussian_kernel1d(5, 2, 20)

runtimes = timeit.repeat(workload, number=1, repeat=10000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.00027079838242498224
Before SD: 6.407474041388179e-05
After Mean: 1.6173898064880632e-05
After SD: 1.334709867347949e-06
Improvement: -94.03%",,2,docker.io/sweperf/sweperf:scipy__scipy-9766,docker.io/sweperf/sweperf_annotate:scipy__scipy-9766,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:scipy__scipy-9766 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",scipy/scipy,2019-02-05 19:30:23,9ebbd188f54b13bc6335210a54145de8a28ea0dc,1.2
,APPROVED,sympy__sympy-10621,https://github.com/sympy/sympy/pull/10621,"import timeit
import statistics
from sympy import factorial
from sympy.core.cache import clear_cache

n = 100

def setup():
    clear_cache()

def workload():
    _ = factorial(n)

runtimes = timeit.repeat(workload, number=1, repeat=200000, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100000:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100000:]))","Before Mean: 0.0002763033087097574
Before SD: 6.673457996556034e-06
After Mean: 2.6628858466283418e-05
After SD: 3.7302717612801113e-06
Improvement: -90.36%",,2,docker.io/sweperf/sweperf:sympy__sympy-10621,docker.io/sweperf/sweperf_annotate:sympy__sympy-10621,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-10621 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2016-02-17 22:57:51,ef47677483b2f29d0b8e6a0eb45de72b2e34477d,1
,APPROVED,sympy__sympy-10919,https://github.com/sympy/sympy/pull/10919,"import timeit
import statistics
from sympy import npartitions

a = 10**6

def workload():
    _ = npartitions(a)

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.8109946581884288
Before SD: 0.014306289233103325
After Mean: 0.022416855895426125
After SD: 0.00878635918722136
Improvement: -97.24%",,1,docker.io/sweperf/sweperf:sympy__sympy-10919,docker.io/sweperf/sweperf_annotate:sympy__sympy-10919,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-10919 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2016-03-27 6:07:56,5c91be2fb9b064579b1459eeb3813f2ea83f5aa2,1
,APPROVED,sympy__sympy-11675,https://github.com/sympy/sympy/pull/11675,"import timeit
import statistics
from sympy.solvers.diophantine import diop_DN

def setup():
    global D, N
    D = 15591784605
    N = -20

def workload():
    global n
    _ = sorted(diop_DN(D, N))

runtimes = timeit.repeat(workload, number=1, repeat=5, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 41.29017873097909
Before SD: 0.17414525268575992
After Mean: 0.051071269181557
After SD: 0.09666295816718806
Improvement: -99.88%",,1,docker.io/sweperf/sweperf:sympy__sympy-11675,docker.io/sweperf/sweperf_annotate:sympy__sympy-11675,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-11675 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2016-09-28 13:26:13,f02a6e98925cdd9c24383aba092847060fa63120,1
,APPROVED,sympy__sympy-11676,https://github.com/sympy/sympy/pull/11676,"import timeit
import statistics
from sympy.physics.mechanics.models import n_link_pendulum_on_cart

from sympy.core.cache import clear_cache

def setup():
    clear_cache()

def workload():
    n_link_pendulum_on_cart(n = 10)
    
runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 2.5486172534991054
Before SD: 0.005764804521787925
After Mean: 2.4423647420015184
After SD: 0.0037665671064239462
Improvement: -4.17%",,8,docker.io/sweperf/sweperf:sympy__sympy-11676,docker.io/sweperf/sweperf_annotate:sympy__sympy-11676,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-11676 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2016-09-28 13:58:36,f02a6e98925cdd9c24383aba092847060fa63120,1
,APPROVED,sympy__sympy-11789,https://github.com/sympy/sympy/pull/11789,"import timeit
import statistics
from sympy.assumptions.satask import satask
from sympy.assumptions import Q
from sympy.abc import x
from sympy import symbols

from sympy.core.cache import clear_cache

def setup():
    global x
    clear_cache()
    x = symbols('x', real=True)

def workload():
    global x
    _ = satask(Q.positive(x**2), Q.real(x))

runtimes = timeit.repeat(workload, number=1, repeat=200, setup=setup)

print(""Mean:"", statistics.mean(runtimes[-100:]))
print(""Std Dev:"", statistics.stdev(runtimes[-100:]))","Before Mean: 0.4616790819779271
Before SD: 0.001106821776818378
After Mean: 0.021577581771998665
After SD: 0.00010448021761237926
Improvement: -95.33%",,7,docker.io/sweperf/sweperf:sympy__sympy-11789,docker.io/sweperf/sweperf_annotate:sympy__sympy-11789,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-11789 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2016-10-31 4:42:57,0e27e649e72b222e900b2d81e47c689585cd7c67,1
,APPROVED,sympy__sympy-12640,https://github.com/sympy/sympy/pull/12640,"import timeit
import statistics
from sympy.matrices import Matrix
from sympy.core.cache import clear_cache

def setup():
    global A, B
    clear_cache()
    A = Matrix([
    [12938, 23894, 39845, 9845, 12345, 8765, 31415, 27182, 16180, 13579],
    [98765, 12345, 87654, 22222, 33333, 44444, 55555, 66666, 77777, 88888],
    [13579, 24680, 98765, 32132, 21321, 99999, 88888, 77777, 20202, 30303],
    [11223, 22334, 33445, 44556, 55667, 66778, 77889, 88990, 99001, 10101],
    [14142, 17320, 22360, 24494, 26457, 28284, 30000, 31622, 33166, 34641],
    [11235, 22360, 33466, 44556, 55677, 66778, 77889, 88990, 99001, 10101],
    [11111, 22222, 33333, 44444, 55555, 66666, 77777, 88888, 99999, 12345],
    [23456, 34567, 45678, 56789, 67890, 78901, 89012, 90123, 12345, 23456],
    [31415, 27182, 16180, 14142, 17320, 22360, 24494, 26457, 28284, 30000],
    [31622, 33166, 34641, 36055, 37416, 38730, 40000, 41231, 42426, 43588],
])
    
    B = Matrix([
    [88888, 77777, 66666, 55555, 44444, 33333, 22222, 11111, 99999, 88888],
    [11111, 22222, 33333, 44444, 55555, 66666, 77777, 88888, 99999, 12345],
    [43210, 54321, 65432, 76543, 87654, 98765, 12345, 23456, 34567, 45678],
    [56789, 67890, 78901, 89012, 90123, 12345, 23456, 34567, 45678, 56789],
    [67890, 78901, 89012, 90123, 12345, 23456, 34567, 45678, 56789, 67890],
    [78901, 89012, 90123, 12345, 23456, 34567, 45678, 56789, 67890, 78901],
    [89012, 90123, 12345, 23456, 34567, 45678, 56789, 67890, 78901, 89012],
    [90123, 12345, 23456, 34567, 45678, 56789, 67890, 78901, 89012, 90123],
    [12345, 23456, 34567, 45678, 56789, 67890, 78901, 89012, 90123, 12345],
    [23456, 34567, 45678, 56789, 67890, 78901, 89012, 90123, 12345, 23456],
])

def workload():
    global A, B
    _ = A * B
    _ = A + B

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.00830197670729831
Before SD: 0.00037998857341221235
After Mean: 0.0033301156014204024
After SD: 0.0003748355136830039
Improvement: -59.89%",,62,docker.io/sweperf/sweperf:sympy__sympy-12640,docker.io/sweperf/sweperf_annotate:sympy__sympy-12640,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-12640 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2017-05-14 0:43:38,7d8917b0b45932d6c495906a7e6ea4b0dc9ed72b,1
,APPROVED,sympy__sympy-12748,https://github.com/sympy/sympy/pull/12748,"import timeit
import statistics
import sympy
import numpy as np

from sympy.core.cache import clear_cache

def setup():
    clear_cache()
    
def workload():
    A = np.random.random((150, 151))
    X = sympy.DeferredVector(""X"")
    expr = sympy.Matrix(A*X[0])
    _ = sympy.lambdify(X, expr, modules=""numpy"")

runtimes = timeit.repeat(workload, number=1, repeat=20, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 5.258927572850371
Before SD: 0.04187975649546657
After Mean: 5.056250182613148
After SD: 0.014638720542846336
Improvement: -3.85%",,5,docker.io/sweperf/sweperf:sympy__sympy-12748,docker.io/sweperf/sweperf_annotate:sympy__sympy-12748,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-12748 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2017-06-15 4:15:16,0e5f2b3f6af7eb9d18896c859f2b4a0c367007e5,1
,APPROVED,sympy__sympy-14772,https://github.com/sympy/sympy/pull/14772,"import timeit
import statistics
from sympy.crypto.crypto import _legendre
from sympy.core.cache import clear_cache


def setup():
    global a, p
    clear_cache()
    a = 87389
    p = 131071
    
def workload():
    global a, p
    _ = _legendre(a, p)

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.039023128198459746
Before SD: 0.0004026830355751641
After Mean: 2.8494163416326045e-06
After SD: 1.0341397418933714e-06
Improvement: -99.99%",,1,docker.io/sweperf/sweperf:sympy__sympy-14772,docker.io/sweperf/sweperf_annotate:sympy__sympy-14772,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-14772 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2018-06-04 8:43:26,cb0ea62fdb5df23a8320032ca356c8280c4404fb,1.1
,APPROVED,sympy__sympy-15379,https://github.com/sympy/sympy/pull/15379,"import timeit
import statistics

import sympy as sy
from sympy import symbols, Mod, ccode

from sympy.core.cache import clear_cache

def setup():
    global x, foo
    clear_cache()
    x = sy.Symbol('x')
    foo = sy.Function('foo')

def workload():
    global x, foo
    sy.ccode(foo(foo(foo(foo(foo(foo(foo(foo(foo(foo(foo(foo(foo(x))))))))))))), user_functions={'foo':'foo'})

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 17.171223294199443
Before SD: 0.06348276892031703
After Mean: 0.11887638459447772
After SD: 0.0010022795863440304
Improvement: -99.31%",,27,docker.io/sweperf/sweperf:sympy__sympy-15379,docker.io/sweperf/sweperf_annotate:sympy__sympy-15379,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-15379 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2018-10-11 19:54:24,813328e6a9daa2655c03828ed3709af2675f3b29,1.4
,APPROVED,sympy__sympy-15453,https://github.com/sympy/sympy/pull/15453,"import timeit
import statistics
from sympy.core.numbers import igcd
from sympy.core.cache import clear_cache

def setup():
    global a, b
    clear_cache()
    a = 99934050340032767287874572817817263890923187128923834765748399847657483926728787457290923187128923834765748399847657483926728787362178876288763847586954376278787878787877128923834765748399847671289238347657483998476
    b = 2003040304042272836217887628876384758695437627839872893764785847332327672878745728178172638909231871289238347657483998476574839267287874572909231871289283621788762887638475836563728926543456728928343765245678927
    
def workload():
    global a, b
    _ = igcd(a , b)

runtimes = timeit.repeat(workload, number=5, repeat=100000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 3.4618315775878728e-06
Before SD: 3.3303457488748156e-07
After Mean: 9.860032447613777e-07
After SD: 1.7986643841717286e-07
Improvement: -71.52%",,36,docker.io/sweperf/sweperf:sympy__sympy-15453,docker.io/sweperf/sweperf_annotate:sympy__sympy-15453,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-15453 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2018-11-04 15:23:22,a762237a53ceddedc8f6ba34ff3cfa6c7d2ace9c,1.4
,APPROVED,sympy__sympy-15736,https://github.com/sympy/sympy/pull/15736,"import timeit
import statistics
from sympy.matrices import matrix_multiply_elementwise
from sympy.matrices import Matrix
from sympy.core.cache import clear_cache

def setup():
    global A, B
    clear_cache()
    A = Matrix([[0, 1, 2], [3, 4, 5]])
    B = Matrix([[1, 10, 100], [100, 10, 1]])

def workload():
    global A, B
    _ = matrix_multiply_elementwise(A, B)

runtimes = timeit.repeat(workload, number=5, repeat=10000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0003376727554015815
Before SD: 6.177135254808352e-06
After Mean: 3.5783038765657696e-05
After SD: 1.952915629448059e-06
Improvement: -89.40%",,2,docker.io/sweperf/sweperf:sympy__sympy-15736,docker.io/sweperf/sweperf_annotate:sympy__sympy-15736,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-15736 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2019-01-04 23:19:08,36374a3f7f1c6440511c1b649e6546c80c36bae7,1.4
,APPROVED,sympy__sympy-15909,https://github.com/sympy/sympy/pull/15909,"import timeit
import statistics
from sympy import trailing
from sympy.core.cache import clear_cache

def setup():
    clear_cache()

def workload():
    for k in range(1, 200):
        ok = trailing(2**k + 2**(k-1))

runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0006220214564818889
Before SD: 6.300135352616848e-06
After Mean: 0.0004475956039968878
After SD: 6.996748824051619e-06
Improvement: -28.04%",,6,docker.io/sweperf/sweperf:sympy__sympy-15909,docker.io/sweperf/sweperf_annotate:sympy__sympy-15909,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-15909 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2019-02-03 8:26:01,3b1895477e50a792e21a0aa7c02d5cf31f03eb6d,1.4
,APPROVED,sympy__sympy-16134,https://github.com/sympy/sympy/pull/16134,"import timeit
import statistics
from sympy import Or
from sympy.abc import a, b, c, d, e, f, g, h, i
from sympy.logic.boolalg import simplify_logic
from sympy.core.cache import clear_cache

def setup():
    clear_cache()

def workload():
    _ = simplify_logic(Or(a,b,c,d,e,f,g,h,i))
    
runtimes = timeit.repeat(workload, number=1, repeat=10, setup = setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 20.40037801901344
Before SD: 0.11225136264623892
After Mean: 0.0007032157096546144
After SD: 0.00016316743388632927
Improvement: -100.00%",,1,docker.io/sweperf/sweperf:sympy__sympy-16134,docker.io/sweperf/sweperf_annotate:sympy__sympy-16134,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-16134 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2019-03-02 12:28:32,2dd1275d6050605f517b030c92e9ef30c75eab45,1.4
,APPROVED,sympy__sympy-17916,https://github.com/sympy/sympy/pull/17916,"import timeit
import statistics
from sympy.ntheory import legendre_symbol
from sympy.core.cache import clear_cache

def setup():
    clear_cache()

def workload():
    _ = legendre_symbol(87345678298376536798, 957496696762772407663)

runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 5.382680322509259e-05
Before SD: 2.7996469688630456e-06
After Mean: 3.311613359255716e-05
After SD: 1.9187142711065243e-06
Improvement: -38.48%",,2,docker.io/sweperf/sweperf:sympy__sympy-17916,docker.io/sweperf/sweperf_annotate:sympy__sympy-17916,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-17916 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2019-11-17 21:13:31,6128b47aa008657715ce5c70b7c3fdd6bd3f1648,1.6
,APPROVED,sympy__sympy-18276,https://github.com/sympy/sympy/pull/18276,"import timeit
import statistics
from sympy import integer_nthroot
from sympy import fibonacci
import sympy.core.power as power

from sympy.core.cache import clear_cache

def setup():
    global a, b
    clear_cache()
    a = 13**985
    b = 13
    
def workload():
    global a, b
    _ = integer_nthroot(a, b)

runtimes = timeit.repeat(workload, number=1, repeat=100000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 3.1912929599056954e-05
Before SD: 2.3691463348880425e-06
After Mean: 5.077585898688994e-06
After SD: 3.5841808798628564e-07
Improvement: -84.09%",,37,docker.io/sweperf/sweperf:sympy__sympy-18276,docker.io/sweperf/sweperf_annotate:sympy__sympy-18276,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-18276 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2020-01-09 13:29:00,c4423ca61ebcc9db91eefcbd2ffef7aa2b07d690,1.6
,APPROVED,sympy__sympy-18591,https://github.com/sympy/sympy/pull/18591,"import timeit
import statistics

from sympy.ntheory import is_mersenne_prime, is_perfect
from sympy.core.cache import clear_cache

m = 2 ** 31 -1
p = 31
per = (2**(p - 1)) * (2**p - 1)

def setup():
    clear_cache()

def workload():
    _ = is_mersenne_prime(m)
    _ = is_perfect(per)

runtimes = timeit.repeat(workload, number=5, repeat=10000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.6576293349498882e-05
Before SD: 7.282231495329356e-07
After Mean: 8.660998166305944e-06
After SD: 6.277982836074145e-07
Improvement: -47.75%",,10,docker.io/sweperf/sweperf:sympy__sympy-18591,docker.io/sweperf/sweperf_annotate:sympy__sympy-18591,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-18591 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2020-02-06 18:10:37,afbffa714654e4c8e8e853b7689d324e7146e40f,1.6
,APPROVED,sympy__sympy-19270,https://github.com/sympy/sympy/pull/19270,"import timeit
import statistics
from sympy import Symbol, exp, Integral
from sympy.core.cache import clear_cache

def setup():
    global x
    clear_cache()
    x = Symbol('x')

def workload():
    global x
    _ = Integral(x**100*exp(x), x).doit(risch=True)

runtimes = timeit.repeat(workload, number=1, repeat=100, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.42419662498985417
Before SD: 0.011138407713483272
After Mean: 0.3144112254003994
After SD: 0.003101815270836665
Improvement: -25.88%",,37,docker.io/sweperf/sweperf:sympy__sympy-19270,docker.io/sweperf/sweperf_annotate:sympy__sympy-19270,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-19270 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2020-05-07 22:25:14,37df6c20f5fd7511e18685de40a4d47928c3ac88,1.7
,APPROVED,sympy__sympy-20228,https://github.com/sympy/sympy/pull/20228,"import timeit
import statistics

from sympy import sympify
from sympy.core.cache import clear_cache

def setup():
    clear_cache()

def workload():
    b = sympify('sign(((a * b) ** 200))')
    
runtimes = timeit.repeat(workload, number=1, repeat=10, setup = setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 5.288782808411634
Before SD: 0.027294335428232876
After Mean: 0.004955980199156329
After SD: 0.006643122767905432
Improvement: -99.91%",,8,docker.io/sweperf/sweperf:sympy__sympy-20228,docker.io/sweperf/sweperf_annotate:sympy__sympy-20228,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-20228 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2020-10-08 5:05:40,c237fe7f4c1a4abcfaef0e79600e26cba4ac0a6d,1.7
,APPROVED,sympy__sympy-20384,https://github.com/sympy/sympy/pull/20384,"import timeit
import statistics
from sympy import *
from sympy.polys.domainmatrix import DomainMatrix
from sympy.core.cache import clear_cache

def setup():
    global p
    clear_cache()
    a, b, c, d, e, f, g, h, i, j = symbols('a:j')

    M = DomainMatrix.from_list_sympy(10, 10, [
    [3 - 4*a,      -2,       0,       0,       0,       0,       0,       0,       0,       0],
    [     -2, 3 - 4*b,      -2,       0,       0,       0,       0,       0,       0,       0],
    [      0,      -2, 3 - 4*c,      -2,       0,       0,       0,       0,       0,       0],
    [      0,       0,      -2, 3 - 4*d,      -2,       0,       0,       0,       0,       0],
    [      0,       0,       0,      -2, 3 - 4*e,      -2,       0,       0,       0,       0],
    [      0,       0,       0,       0,      -2, 3 - 4*f,      -2,       0,       0,       0],
    [      0,       0,       0,       0,       0,      -2, 3 - 4*g,      -2,       0,       0],
    [      0,       0,       0,       0,       0,       0,      -2, 3 - 4*h,      -2,       0],
    [      0,       0,       0,       0,       0,       0,       0,      -2, 3 - 4*i,      -2],
    [      0,       0,       0,       0,       0,       0,       0,       0,      -1, 3 - 4*j]])

    p = M.charpoly()


def workload():
    global p
    _ = pretty(p)

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 14.017159834806808
Before SD: 0.09981948613217487
After Mean: 0.2768480390950572
After SD: 0.000857813144603621
Improvement: -98.02%",,31,docker.io/sweperf/sweperf:sympy__sympy-20384,docker.io/sweperf/sweperf_annotate:sympy__sympy-20384,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-20384 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2020-11-05 18:18:30,ae883bfd31129a2a27d7ff5015980120a0c5966a,1.8
,APPROVED,sympy__sympy-20989,https://github.com/sympy/sympy/pull/20989,"import timeit
import statistics
from sympy import *
from sympy.core.cache import clear_cache

def setup():
    global t
    clear_cache()
    t = Symbol('t')

def workload():
    global t
    _ = integrate((sin(t)**2 + 2*cos(t))*sqrt(3*sin(t)**2 + 1), (t, 0, 2*pi))

runtimes = timeit.repeat(workload, number=1, repeat=3, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","An error occurred:

+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /opt/miniconda3/bin/conda
++++ dirname /opt/miniconda3/bin
+++ PATH=/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate
++ local cmd=activate
++ case ""$cmd"" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case ""$cmd"" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_1=/opt/miniconda3
++ CONDA_PREFIX_1=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /testbed
+ git config --global --add safe.directory /testbed
+ cd /testbed
+ git status
On branch master
nothing to commit, working tree clean
+ git show
commit 3572b1955d089e94d5af5b388b557fc26719ee1b
Merge: d506702bac 72864c7c1d
Author: Oscar Benjamin <oscar.j.benjamin@gmail.com>
Date:   Sun Feb 21 10:54:53 2021 +0000

    Merge pull request #20988 from hyadav2k/20985_poly_domains
    
    added methods and tests for CC

+ git diff 3572b1955d089e94d5af5b388b557fc26719ee1b
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case ""$cmd"" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1='(testbed) '
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case ""$cmd"" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_3=/opt/miniconda3
++ CONDA_PREFIX_3=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ python -m pip install -e .
Obtaining file:///testbed
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: mpmath>=0.19 in /opt/miniconda3/envs/testbed/lib/python3.8/site-packages (from sympy==1.8.dev0) (1.3.0)
Installing collected packages: sympy
  Attempting uninstall: sympy
    Found existing installation: sympy 1.8.dev0
    Uninstalling sympy-1.8.dev0:
      Successfully uninstalled sympy-1.8.dev0
  DEPRECATION: Legacy editable install of sympy==1.8.dev0 from file:///testbed (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457
  Running setup.py develop for sympy
Successfully installed sympy
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
+ echo PERF_START:
PERF_START:
+ python /tmp/workload.py
Mean: 466.23793699099525
Std Dev: 5.318502650122231
/testbed/sympy/external/importtools.py:158: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(modversion) < LooseVersion(min_module_version):
+ echo PERF_END:
PERF_END:
+ python -m cProfile -o /tmp/workload_cprofile.prof /tmp/workload.py


Timeout error: 3600 seconds exceeded.",,53,docker.io/sweperf/sweperf:sympy__sympy-20989,docker.io/sweperf/sweperf_annotate:sympy__sympy-20989,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-20989 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2021-02-21 21:05:28,3572b1955d089e94d5af5b388b557fc26719ee1b,1.8
,APPROVED,sympy__sympy-21006,https://github.com/sympy/sympy/pull/21006,"import timeit
import statistics
from sympy import Matrix
from sympy.core.cache import clear_cache

def setup():
    clear_cache()

def workload():
    _ = Matrix.eye(100, 100)
    _ = Matrix.zeros(100, 100)

runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.02840648787294049
Before SD: 0.00010572124935926911
After Mean: 5.8266899606678634e-05
After SD: 4.173278685476532e-06
Improvement: -99.79%",,17,docker.io/sweperf/sweperf:sympy__sympy-21006,docker.io/sweperf/sweperf_annotate:sympy__sympy-21006,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-21006 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2021-02-25 4:31:45,9107b9d7ec4449b888cfd41a540008c511b5a260,1.8
,APPROVED,sympy__sympy-21169,https://github.com/sympy/sympy/pull/21169,"import timeit
import statistics
from sympy import symbols, sqrt
from sympy import linsolve
from sympy.printing.pretty.pretty import PrettyPrinter
from sympy import pretty

from sympy.core.cache import clear_cache

def setup():
    global s
    clear_cache()
    xs = symbols('x:1000')
    eqs = [x1 + sqrt(2)*x2 for x1, x2 in zip(xs[:-1], xs[1:])]
    eqs.append(xs[-1] - sqrt(3))
    s = linsolve(eqs, xs)

def workload():
    global s
    _ = pretty(s)

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 14.107108374196105
Before SD: 0.03605927275373433
After Mean: 4.100844361493364
After SD: 0.03388947195174079
Improvement: -70.93%",,1,docker.io/sweperf/sweperf:sympy__sympy-21169,docker.io/sweperf/sweperf_annotate:sympy__sympy-21169,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-21169 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2021-03-25 22:32:56,aa22709cb7df2d7503803d4b2c0baa7aa21440b6,1.8
,APPROVED,sympy__sympy-21320,https://github.com/sympy/sympy/pull/21320,"import timeit
import statistics
from sympy.assumptions.ask import Q, ask
from sympy.abc import x
from sympy.core.cache import clear_cache

def setup():
    clear_cache()

def workload():
    ask(Q.even(x), Q.odd(x))

runtimes = timeit.repeat(workload, number=1, repeat=10000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.004462076611816883
Before SD: 0.0005913961864914388
After Mean: 0.0036746462686394806
After SD: 0.0004127240864830518
Improvement: -17.65%",,8,docker.io/sweperf/sweperf:sympy__sympy-21320,docker.io/sweperf/sweperf_annotate:sympy__sympy-21320,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-21320 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2021-04-14 5:15:36,99f04dd6c72cf77f33a3822c2930d0f190e6a378,1.9
,APPROVED,sympy__sympy-21391,https://github.com/sympy/sympy/pull/21391,"import timeit
import statistics
import sympy
from sympy.matrices.dense import randMatrix
from sympy.polys.matrices import DomainMatrix
from sympy import I

def setup():
    global dM
    M = randMatrix(100) + randMatrix(100)*I/3
    dM = DomainMatrix.from_Matrix(M)

def workload():
    global dM
    _ = dM**2
    

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 4.67066150989267
Before SD: 0.008961638299719818
After Mean: 2.090968591714045
After SD: 0.0033828678784479805
Improvement: -55.23%",,40,docker.io/sweperf/sweperf:sympy__sympy-21391,docker.io/sweperf/sweperf_annotate:sympy__sympy-21391,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-21391 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2021-04-26 23:18:41,8ddf9c29e345df987e82f8c5905dd0b32ea0a4b6,1.9
,APPROVED,sympy__sympy-21455,https://github.com/sympy/sympy/pull/21455,"import timeit
import statistics
from sympy.assumptions.ask import Q, ask
from sympy.abc import x

from sympy.core.cache import clear_cache

def setup():
    clear_cache()    

def workload():
    ask(Q.real(x), Q.positive(x))

runtimes = timeit.repeat(workload, number=5, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.011685778205574024
Before SD: 0.0018059058334222169
After Mean: 0.004706873482267838
After SD: 0.0012462291113960048
Improvement: -59.72%",,8,docker.io/sweperf/sweperf:sympy__sympy-21455,docker.io/sweperf/sweperf_annotate:sympy__sympy-21455,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-21455 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2021-05-10 23:44:51,f2e4a7cfe79dafa7d1dea8e9c56c6db4f2d97c0a,1.9
,APPROVED,sympy__sympy-21501,https://github.com/sympy/sympy/pull/21501,"import timeit
import statistics
from sympy.polys.matrices import DomainMatrix
from sympy import Matrix
from sympy.polys.specialpolys import random_poly
from sympy.abc import x, y
from sympy.core.cache import clear_cache

def setup():
    global M, dM
    clear_cache()
    M = Matrix([[random_poly(x, 2, -5, 5)/random_poly(y, 2, -5, 5) for _ in range(4)] for _ in range(4)])
    dM = DomainMatrix.from_Matrix(M)

def workload():
    global dM
    _ = dM.det()

runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 1.3213787127658725
Before SD: 0.6312409648225765
After Mean: 0.07195615640375763
After SD: 0.0035433786159779165
Improvement: -94.55%",,4,docker.io/sweperf/sweperf:sympy__sympy-21501,docker.io/sweperf/sweperf_annotate:sympy__sympy-21501,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-21501 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2021-05-22 1:25:11,65e1ad3d48ca445b91386c39fe18c482d2e48b4e,1.9
,APPROVED,sympy__sympy-21543,https://github.com/sympy/sympy/pull/21543,"import timeit
import statistics
from sympy import symbols, ExpressionDomain, exp, Integral
from sympy.core.cache import clear_cache

def setup():
    global I
    clear_cache()
    z1, z2 = symbols('z1, z2')
    I = Integral(exp(-0.5*(((-1/z1)+1.39)**2+((-1/z2)+1.23)**2))*(1/(z1**2))*(1/(z2**2)),(z1,0,1),(z2,0,1))

def workload():
    global I
    I.doit()

runtimes = timeit.repeat(workload, number=1, repeat=3, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 41.9613222300075
Before SD: 0.7344675026484989
After Mean: 21.191480416001287
After SD: 0.42004022090483933
Improvement: -49.50%",,6,docker.io/sweperf/sweperf:sympy__sympy-21543,docker.io/sweperf/sweperf_annotate:sympy__sympy-21543,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-21543 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2021-05-28 22:14:29,a4327423750065efe9a087a60c20e33b1dba653e,1.9
,APPROVED,sympy__sympy-21954,https://github.com/sympy/sympy/pull/21954,"import timeit
import statistics
from sympy import Rational, Integer
from fractions import Fraction

from sympy.ntheory.generate import sieve
from sympy.core.cache import clear_cache

def setup():
    global p
    clear_cache()
    p = sieve[1:1000]

def workload():
    global p
    ok = [Rational(pi, 1000) for pi in p] 

runtimes = timeit.repeat(workload, number=1, repeat=10000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.003421725934196729
Before SD: 3.189861298690886e-05
After Mean: 0.0009301413780252915
After SD: 2.123216576843886e-05
Improvement: -72.82%",,38,docker.io/sweperf/sweperf:sympy__sympy-21954,docker.io/sweperf/sweperf_annotate:sympy__sympy-21954,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-21954 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2021-08-26 11:23:00,b8156f36f0f3144c5e3b66002b9e8fcbe2ee66c4,1.9
,APPROVED,sympy__sympy-23541,https://github.com/sympy/sympy/pull/23541,"import timeit
import statistics
from sympy.functions.elementary.trigonometric import atan, asin, acos, acot
from sympy.core.cache import clear_cache


def setup():
    global n
    clear_cache()
    n = 0.5
    
def workload():
    global n
    _ = asin(n)
    _ = atan(n)
    _ = acos(n)
    _ = acot(n)

    
runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.007855916065222119
Before SD: 0.002569012464216354
After Mean: 0.007300944060902112
After SD: 0.0007765528863008578
Improvement: -7.06%",,8,docker.io/sweperf/sweperf:sympy__sympy-23541,docker.io/sweperf/sweperf_annotate:sympy__sympy-23541,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-23541 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2022-05-25 21:16:41,6a04cdb14427489fe49974f33a84001a299d3688,1.11
,APPROVED,sympy__sympy-23593,https://github.com/sympy/sympy/pull/23593,"import timeit
import statistics
from sympy.core.singleton import S
from sympy import cos
from sympy.core.cache import clear_cache

def setup():
    global w
    clear_cache()
    w=S.Pi/4

    
def workload():
    global w
    cos.__new__.cache_clear()
    _ = cos(w)
    
runtimes = timeit.repeat(workload, number=5, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.0013450525250518694
Before SD: 0.0025570206084752954
After Mean: 0.0011613466459093615
After SD: 0.0006857272271554819
Improvement: -13.66%",,40,docker.io/sweperf/sweperf:sympy__sympy-23593,docker.io/sweperf/sweperf_annotate:sympy__sympy-23593,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-23593 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2022-06-07 7:01:20,ae598245cb778790d51b403fd9d6b6f850b4e438,1.11
,APPROVED,sympy__sympy-23696,https://github.com/sympy/sympy/pull/23696,"import timeit
import statistics

from sympy.integrals.manualintegrate import manualintegrate
from sympy.core.symbol import symbols
from sympy.core.cache import clear_cache

x, y, z, u, n, a, b, c, d, e = symbols('x y z u n a b c d e')

def setup():
    clear_cache()

def workload():
    manualintegrate(x, x)

runtimes = timeit.repeat(workload, number=1, repeat=1000)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.025365938929957338
Before SD: 0.006857490569633771
After Mean: 0.00010469657491194084
After SD: 0.0015188003262397443
Improvement: -99.59%",,12,docker.io/sweperf/sweperf:sympy__sympy-23696,docker.io/sweperf/sweperf_annotate:sympy__sympy-23696,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-23696 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2022-06-27 21:00:55,71916a99e5b477953dea567110875ae69bd9ffd7,1.11
,APPROVED,sympy__sympy-24313,https://github.com/sympy/sympy/pull/24313,"import timeit
import statistics

from sympy.utilities.iterables import necklaces
from sympy.core.cache import clear_cache


def setup():
    clear_cache()

def workload():
    sum(1 for n in range(12) for k in range(12-n) for p in necklaces(n,k))

runtimes = timeit.repeat(workload, number=1, repeat=5)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 14.830552437808365
Before SD: 0.008240594487451321
After Mean: 0.005018848413601518
After SD: 4.507144885948139e-05
Improvement: -99.97%",,1,docker.io/sweperf/sweperf:sympy__sympy-24313,docker.io/sweperf/sweperf_annotate:sympy__sympy-24313,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-24313 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2022-11-26 12:05:34,8ad4f490fecc269eac69a6976b50f44396f6a1ad,1.12
,APPROVED,sympy__sympy-24485,https://github.com/sympy/sympy/pull/24485,"import timeit
import statistics

from sympy import symbols, Mul
from sympy.core.cache import clear_cache

def setup():
    global m
    clear_cache()
    m = Mul(*symbols('x:1000'))

def workload():
    global m
    m.is_zero

runtimes = timeit.repeat(workload, number=1, repeat=26, setup=setup)[-25:]

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 2.522813156247139e-07
Before SD: 1.817837207430347e-07
After Mean: 2.6491470634937285e-07
After SD: 1.4830256549564637e-07
Improvement: 5.01%",,40,docker.io/sweperf/sweperf:sympy__sympy-24485,docker.io/sweperf/sweperf_annotate:sympy__sympy-24485,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-24485 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2023-01-09 14:36:13,6f0fd470a4f7a582c21d3a610798943817d0a334,1.12
,APPROVED,sympy__sympy-24792,https://github.com/sympy/sympy/pull/24792,"import timeit
import statistics
from sympy.physics.mechanics.models import n_link_pendulum_on_cart

def setup():
    pass

def workload():
    n_link_pendulum_on_cart(20)
    
runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 11.744694142509251
Before SD: 0.035973700859905734
After Mean: 10.103784977307077
After SD: 0.01995747708981513
Improvement: -13.97%",,6,docker.io/sweperf/sweperf:sympy__sympy-24792,docker.io/sweperf/sweperf_annotate:sympy__sympy-24792,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-24792 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2023-02-25 22:12:27,75691e5cbdb3dfda4c8164a217bac6a6434404f6,1.13
,APPROVED,sympy__sympy-24884,https://github.com/sympy/sympy/pull/24884,"import timeit
import statistics


from sympy.core.cache import clear_cache
from sympy.matrices import randMatrix
from sympy.polys.matrices.ddm import DDM
from sympy.core.backend import symbols

def mu(X):
    n = X.shape[0]
    zero = X.domain.zero

    total = zero
    diag_sums = [zero]
    for i in reversed(range(1, n)):
        total -= X[i][i]
        diag_sums.append(total)
    diag_sums = diag_sums[::-1]

    elems = [[zero]*i + [diag_sums[i]] + X_i[i+1:] for i, X_i in enumerate(X)]

    return DDM(elems, X.shape, X.domain)

def make_F_A(A):
    return lambda X: mu(X).matmul(A)

def det_div_free(A):
    Addm = A._rep.to_dense().rep

    n = Addm.shape[0]
    F_A = make_F_A(Addm)

    Fn1 = Addm
    for _ in range(n-1):
        Fn1 = F_A(Fn1)

    detA = Fn1[0][0]
    if n % 2 == 0:
        detA = -detA

    return Addm.domain.to_sympy(detA)

def setup():
    global M
    clear_cache()
    x, y = symbols('x y')
    M = randMatrix(5)*x + randMatrix(5)*y

def workload():
    global M
    ok = det_div_free(M)

runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.12971689976518974
Before SD: 0.0018767189480579304
After Mean: 0.04890170995611697
After SD: 0.0013475409669029556
Improvement: -62.30%",,40,docker.io/sweperf/sweperf:sympy__sympy-24884,docker.io/sweperf/sweperf_annotate:sympy__sympy-24884,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-24884 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2023-03-09 17:26:34,ee255925dca1ac582644b8c88ebfcf89ef9bcf1f,1.13
,APPROVED,sympy__sympy-25452,https://github.com/sympy/sympy/pull/25452,"import timeit
import statistics
from sympy import symbols, Matrix

from sympy.core.cache import clear_cache

def setup():
    global Z

    clear_cache()
    a, b = symbols('a b')
    Z = Matrix([[a, b],
            [b, a + b]])

def workload():
    global Z
    _ = Z.inv()
    
runtimes = timeit.repeat(workload, number=1, repeat=100, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.036097468619118445
Before SD: 0.010251918082859203
After Mean: 0.0013541910500498488
After SD: 0.00015722527241232172
Improvement: -96.25%",,19,docker.io/sweperf/sweperf:sympy__sympy-25452,docker.io/sweperf/sweperf_annotate:sympy__sympy-25452,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-25452 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2023-07-31 14:00:44,c226febc80e48826d4314f63a391b31c4d20cfeb,1.13
,APPROVED,sympy__sympy-25591,https://github.com/sympy/sympy/pull/25591,"import timeit
import statistics
from sympy import Abs, Q
from sympy.assumptions.satask import satask
from sympy.abc import x
from sympy.core.cache import clear_cache

def setup():
    global a, z
    clear_cache()
    a = Q.zero(Abs(x))
    z = Q.zero(x)

def workload():
    global n
    _ = satask(a, z)

runtimes = timeit.repeat(workload, number=5, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.009629856911953538
Before SD: 0.0008745951048580983
After Mean: 0.00744806128035998
After SD: 0.00020607858394187982
Improvement: -22.66%",,8,docker.io/sweperf/sweperf:sympy__sympy-25591,docker.io/sweperf/sweperf_annotate:sympy__sympy-25591,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-25591 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2023-08-24 19:08:14,2f80497c7e83d889748df102e9a0c126fdbaeab5,1.13
,APPROVED,sympy__sympy-25631,https://github.com/sympy/sympy/pull/25631,"import timeit
import statistics
import sympy
from sympy.core.cache import clear_cache

def setup():
    clear_cache()

def workload():
    _ = list(sympy.sieve.totientrange(10**7, 2 * 10**7))

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 5.509917830501218
Before SD: 15.284425933485304
After Mean: 1.8688301483052783
After SD: 3.7848748165700252
Improvement: -66.08%",,1,docker.io/sweperf/sweperf:sympy__sympy-25631,docker.io/sweperf/sweperf_annotate:sympy__sympy-25631,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-25631 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2023-09-05 6:31:24,e998c1af2c1c2acd89fcd0763bd2bce2210baf36,1.13
,APPROVED,sympy__sympy-26057,https://github.com/sympy/sympy/pull/26057,"import timeit
import statistics
from sympy import randMatrix
from sympy.core.cache import clear_cache

def setup():
    global M
    clear_cache()
    M = randMatrix(1000, percent=0.1)

def workload():
    global M
    _ = M.charpoly()

runtimes = timeit.repeat(workload, number=1, repeat=10, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 8.597240168292775
Before SD: 0.24861063665546376
After Mean: 0.29760190031374806
After SD: 0.006885159787575276
Improvement: -96.54%",,8,docker.io/sweperf/sweperf:sympy__sympy-26057,docker.io/sweperf/sweperf_annotate:sympy__sympy-26057,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-26057 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2024-01-10 14:14:10,02eeb233a4078fb5f97a76bafbb36433691b372b,1.13
,APPROVED,sympy__sympy-26063,https://github.com/sympy/sympy/pull/26063,"import timeit
import statistics
from sympy import eye, ones
from sympy.core.cache import clear_cache

def workload():
    global sol

    clear_cache()
    sol = eye(1000).solve(ones(1000, 1))

runtimes = timeit.repeat(workload, number=1, repeat=10)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 8.256950573914219
Before SD: 0.1470575143681679
After Mean: 0.0612585089111235
After SD: 0.0011030999081604333
Improvement: -99.26%",,5,docker.io/sweperf/sweperf:sympy__sympy-26063,docker.io/sweperf/sweperf_annotate:sympy__sympy-26063,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-26063 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2024-01-11 17:18:58,93ceab17149ed2d92e614b1916803624f6577d32,1.13
,APPROVED,sympy__sympy-26367,https://github.com/sympy/sympy/pull/26367,"import timeit
import statistics
from sympy.physics.mechanics.models import n_link_pendulum_on_cart
from sympy.physics.mechanics import partial_velocity
from sympy.physics.vector import ReferenceFrame
from sympy.core.cache import clear_cache

def setup():
    clear_cache()
    global fr, vr, frame
    kanes = n_link_pendulum_on_cart(n=10, cart_force=True, joint_torques=False)

    fr = [f for (_, f) in kanes.forcelist]
    vr = kanes.u
    frame = ReferenceFrame('N')

def workload():
    global fr, vr, frame
    partial_velocity(fr, vr, frame)

runtimes = timeit.repeat(workload, number=1, repeat=100, setup = setup)
print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.020631881590234116
Before SD: 0.00018969004273234217
After Mean: 0.001644876455538906
After SD: 1.5807772512576416e-05
Improvement: -92.03%",,1,docker.io/sweperf/sweperf:sympy__sympy-26367,docker.io/sweperf/sweperf_annotate:sympy__sympy-26367,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-26367 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2024-03-18 13:06:22,a775d74879aab1bc1d8fe2193511880cdbd34cc6,1.13
,APPROVED,sympy__sympy-26710,https://github.com/sympy/sympy/pull/26710,"import timeit
import statistics
import sympy
from sympy.ntheory.generate import _primepi

from sympy.core.cache import clear_cache

def setup():
    global n
    n = 10**6
    clear_cache()

def workload():
    global n
    _ = _primepi(n)    

runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.002725939671508968
Before SD: 3.413436873432262e-05
After Mean: 0.0012591704151127486
After SD: 1.6865301863738536e-05
Improvement: -53.81%",,1,docker.io/sweperf/sweperf:sympy__sympy-26710,docker.io/sweperf/sweperf_annotate:sympy__sympy-26710,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-26710 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2024-06-16 9:41:18,ce4fbc144c757f16bd3e80082ead6375a302de34,1.14
,APPROVED,sympy__sympy-27051,https://github.com/sympy/sympy/pull/27051,"import timeit
import statistics
import sympy
from sympy import prime

from sympy.core.cache import clear_cache

def setup():
    global n
    n = 10  # n < 1000
    clear_cache()

def workload():
    global n
    _ = [prime(i) for i in range(1, n + 1)]

runtimes = timeit.repeat(workload, number=1, repeat=1000, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))","Before Mean: 0.024019444398756605
Before SD: 0.0027965371477302317
After Mean: 7.69662787206471e-06
After SD: 1.5130203839599519e-06
Improvement: -99.97%",,1,docker.io/sweperf/sweperf:sympy__sympy-27051,docker.io/sweperf/sweperf_annotate:sympy__sympy-27051,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-27051 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2024-09-09 12:51:12,a912bdfea081dd08b727118ce8bbc0f45c246730,1.14
,APPROVED,sympy__sympy-27251,https://github.com/sympy/sympy/pull/27251,"import timeit
import statistics

from sympy import *

def setup():
    global a, b
    a = symbols(""a0:100000"")
    b = Add(*a)


def workload():
    global a, b
    b + a[0]

runtimes = timeit.repeat(workload, number=1, repeat=25, setup=setup)

print(""Mean:"", statistics.mean(runtimes))
print(""Std Dev:"", statistics.stdev(runtimes))
","Before Mean: 0.01013284819899127
Before SD: 0.050558778728981214
After Mean: 0.007498048362322152
After SD: 0.03741017952561468
Improvement: -26.00%",,40,docker.io/sweperf/sweperf:sympy__sympy-27251,docker.io/sweperf/sweperf_annotate:sympy__sympy-27251,"docker run --mount type=bind,src=<REPLACE_ME>,dst=/tmp/workload.py docker.io/sweperf/sweperf_annotate:sympy__sympy-27251 /bin/bash -c 'chmod +x /perf.sh && /perf.sh && git apply -q /tmp/patch.diff && /perf.sh' 2>&1 | grep -v '^+' | awk '/PERF_START:/ {inblock=1; next} /PERF_END:/ {inblock=0} inblock'",sympy/sympy,2024-11-12 19:14:38,353047ceb08cf57c2412d06fb8d76cf79e9f7583,1.14
