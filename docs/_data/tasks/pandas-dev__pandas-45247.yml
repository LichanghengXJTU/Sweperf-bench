id: pandas-dev__pandas-45247
status:
  human: APPROVED
  llm: COMING_SOON
comparison:
  llm_better: COMING_SOON
repo:
  org: pandas-dev
  name: pandas
  url: https://github.com/pandas-dev/pandas
  pull_request: https://github.com/pandas-dev/pandas/pull/45247
  base_commit: fa3dfdb41f0a75c937e85059a5983da5e5d5aac6
  created_at: '2022-01-07 14:15:55'
  version: '1.3'
workload:
  language: python
  code: "import timeit\nimport statistics\n\nimport pandas as pd\nimport numpy as\
    \ np\nimport itertools\n\ntry:\n    import pandas._testing as tm\nexcept ImportError:\n\
    \    import pandas.util.testing as tm\n\n\nf_list = [max, min, sum]\nkeys_list\
    \ = [\"jim\", [\"jim\", \"joe\"]]\n\ndef workload():\n    for f, keys in itertools.product(f_list,\
    \ keys_list):\n        df = pd.DataFrame(np.random.randint(1, 50, (1000, 2)),\
    \ columns=[\"jim\", \"joe\"])\n        df[\"jolie\"] = np.random.randn(1000)\n\
    \n        gb = df.groupby(keys)\n\n        fname = f.__name__\n        result\
    \ = gb.apply(f)\n        ngroups = len(df.drop_duplicates(subset=keys))\n\n  \
    \      assert_msg = f\"invalid frame shape: {result.shape} (expected ({ngroups},\
    \ 3))\"\n        assert result.shape == (ngroups, 3), assert_msg\n\n        npfunc\
    \ = getattr(np, fname)  # numpy's equivalent function\n        if f in [max, min]:\n\
    \            warn = FutureWarning\n        else:\n            warn = None\n  \
    \      msg = \"scalar (max|min) over the entire DataFrame\"\n        with tm.assert_produces_warning(warn,\
    \ match=msg, check_stacklevel=False):\n            expected = gb.apply(npfunc)\n\
    \        tm.assert_frame_equal(result, expected)\n\n        with tm.assert_produces_warning(None):\n\
    \            expected2 = gb.apply(lambda x: npfunc(x, axis=0))\n        tm.assert_frame_equal(result,\
    \ expected2)\n\n        if f != sum:\n            expected = gb.agg(fname).reset_index()\n\
    \            expected.set_index(keys, inplace=True, drop=False)\n            tm.assert_frame_equal(result,\
    \ expected, check_dtype=False)\n\n        tm.assert_series_equal(getattr(result,\
    \ fname)(), getattr(df, fname)())\n\nruntimes = timeit.repeat(workload, number=1,\
    \ repeat=5)\n\n# Print runtime mean and std deviation.\nprint(\"Mean:\", statistics.mean(runtimes))\n\
    print(\"Std Dev:\", statistics.stdev(runtimes))\n"
docker:
  base_image: docker.io/sweperf/sweperf:pandas-dev__pandas-45247
  human_image: docker.io/sweperf/sweperf_annotate:pandas-dev__pandas-45247
  llm_image: PLACEHOLDER
  commands:
    run_base: docker run --rm --name bench_{id}_base --mount type=bind,src=<WORKLOAD_PY>,dst=/tmp/workload.py
      {base_image} /bin/bash -lc 'python /tmp/workload.py' 2>&1
    run_human: docker run --rm --name bench_{id}_human --mount type=bind,src=<WORKLOAD_PY>,dst=/tmp/workload.py
      {human_image} /bin/bash -lc 'chmod +x /perf.sh && /perf.sh && python /tmp/workload.py'
      2>&1
    run_llm: echo 'LLM image not available yet for {id}. Please fill docker.llm_image.'
metrics:
  reducer: mean_std
  parse_regex:
    mean: (?i)\bMean:\s*([0-9.]+)
    std: (?i)(Std Dev|SD):\s*([0-9.]+)
notes:
  user_notes: 'Before Mean: 3.9684859600034543

    Before SD: 0.05000569706391111

    After Mean: 1.7148533321043942

    After SD: 0.016324268238135563

    Improvement: -56.79%'
  mike_notes: ''
meta:
  num_covering_tests: '225'
